{
  "torch.nn.functional.conv1d": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "conv1d_symint",
      "file": "aten/src/ATen/native/Convolution.cpp",
      "start_line": 915,
      "end_line": 938,
      "code": "at::Tensor conv1d_symint(\n    const Tensor& input_, const Tensor& weight, const std::optional<Tensor>& bias_opt,\n    SymIntArrayRef stride, SymIntArrayRef padding, SymIntArrayRef dilation, c10::SymInt groups) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> bias_maybe_owned = at::borrow_from_optional_tensor(bias_opt);\n  const Tensor& bias = *bias_maybe_owned;\n\n  TORCH_CHECK(\n    !bias.defined() || bias.dtype() == input_.dtype(),\n    \"Input type (\",\n    input_.dtype().name(),\n    \") and bias type (\",\n    bias.dtype().name(),\n    \") should be the same\");\n\n  auto [input, is_batched] = batchify(input_, /*num_spatial_dims=*/ 1, \"conv1d\");\n  Tensor output;\n  if (at::isComplexType(input_.scalar_type())) {\n    output = complex_convolution(input, weight, bias, stride, padding, dilation, false, {0}, groups);\n  } else {\n    output = at::convolution_symint(input, weight, bias, stride, padding, dilation, false, {0}, groups);\n  }\n  return is_batched ? std::move(output) : output.squeeze(0);\n}\n"
    }
  },
  "torch.nn.functional.conv2d": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "conv2d_symint",
      "file": "aten/src/ATen/native/Convolution.cpp",
      "start_line": 940,
      "end_line": 963,
      "code": "at::Tensor conv2d_symint(\n    const Tensor& input_, const Tensor& weight, const std::optional<Tensor>& bias_opt,\n    SymIntArrayRef stride, SymIntArrayRef padding, SymIntArrayRef dilation, c10::SymInt groups) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> bias_maybe_owned = at::borrow_from_optional_tensor(bias_opt);\n  const Tensor& bias = *bias_maybe_owned;\n\n  TORCH_CHECK(\n    !bias.defined() || bias.dtype() == input_.dtype(),\n    \"Input type (\",\n    input_.dtype().name(),\n    \") and bias type (\",\n    bias.dtype().name(),\n    \") should be the same\");\n\n  auto [input, is_batched] = batchify(input_, /*num_spatial_dims=*/ 2, \"conv2d\");\n  Tensor output;\n  if (at::isComplexType(input_.scalar_type())) {\n    output = complex_convolution(input, weight, bias, stride, padding, dilation, false, {{0, 0}}, groups);\n  } else {\n    output = at::convolution_symint(input, weight, bias, stride, padding, dilation, false, {{0, 0}}, groups);\n  }\n  return is_batched ? std::move(output) : output.squeeze(0);\n}\n"
    }
  },
  "torch.nn.functional.conv3d": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "conv3d_symint",
      "file": "aten/src/ATen/native/Convolution.cpp",
      "start_line": 965,
      "end_line": 988,
      "code": "at::Tensor conv3d_symint(\n    const Tensor& input_, const Tensor& weight, const std::optional<Tensor>& bias_opt,\n    SymIntArrayRef stride, SymIntArrayRef padding, SymIntArrayRef dilation, c10::SymInt groups) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> bias_maybe_owned = at::borrow_from_optional_tensor(bias_opt);\n  const Tensor& bias = *bias_maybe_owned;\n\n  TORCH_CHECK(\n    !bias.defined() || bias.dtype() == input_.dtype(),\n    \"Input type (\",\n    input_.dtype().name(),\n    \") and bias type (\",\n    bias.dtype().name(),\n    \") should be the same\");\n\n  auto [input, is_batched] = batchify(input_, /*num_spatial_dims=*/ 3, \"conv3d\");\n  Tensor output;\n  if (at::isComplexType(input_.scalar_type())) {\n    output = complex_convolution(input, weight, bias, stride, padding, dilation, false, {{0, 0, 0}}, groups);\n  } else {\n    output = at::convolution_symint(input, weight, bias, stride, padding, dilation, false, {{0, 0, 0}}, groups);\n  }\n  return is_batched ? std::move(output) : output.squeeze(0);\n}\n"
    }
  },
  "torch.nn.functional.conv_transpose1d": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "conv_transpose1d_symint",
      "file": "aten/src/ATen/native/Convolution.cpp",
      "start_line": 1116,
      "end_line": 1133,
      "code": "at::Tensor conv_transpose1d_symint(\n    const Tensor& input_, const Tensor& weight, const std::optional<Tensor>& bias_opt,\n    SymIntArrayRef stride, SymIntArrayRef padding, SymIntArrayRef output_padding, c10::SymInt groups, SymIntArrayRef dilation) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> bias_maybe_owned = at::borrow_from_optional_tensor(bias_opt);\n  const Tensor& bias = *bias_maybe_owned;\n\n  auto [input, is_batched] = batchify(input_, /*num_spatial_dims=*/ 1, \"conv_transpose1d\");\n  Tensor output;\n  if (at::isComplexType(input_.scalar_type())) {\n    output = complex_convolution(\n      input, weight, bias, stride, padding, dilation, true, output_padding, groups);\n  } else {\n    output = at::convolution_symint(\n      input, weight, bias, stride, padding, dilation, true, output_padding, groups);\n  }\n  return is_batched ? std::move(output) : output.squeeze(0);\n}\n"
    }
  },
  "torch.nn.functional.conv_transpose2d": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.conv_transpose3d": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.unfold": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 5384,
      "end_line": 5419,
      "code": "def unfold(\n    input: Tensor,\n    kernel_size: BroadcastingList2[int],\n    dilation: BroadcastingList2[int] = 1,\n    padding: BroadcastingList2[int] = 0,\n    stride: BroadcastingList2[int] = 1,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            unfold,\n            (input,),\n            input,\n            kernel_size,\n            dilation=dilation,\n            padding=padding,\n            stride=stride,\n        )\n    return torch._C._nn.im2col(\n        input, _pair(kernel_size), _pair(dilation), _pair(padding), _pair(stride)\n    )\n"
    },
    "cpp": {
      "function": "unfold",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 3771,
      "end_line": 3790,
      "code": "Tensor unfold(const Tensor& self, int64_t d, int64_t size, int64_t step) {\n  // some special handling to deal with allow d == 0 when self.dim() == 0\n  auto ndim = self.dim();\n  d = at::maybe_wrap_dim(d, ndim, /*wrap_scalar=*/true);\n\n  auto sizes = self.sizes().vec();\n  auto strides = self.strides().vec();\n  int64_t max_size = self.dim() == 0 ? 1 : sizes[d];\n  TORCH_CHECK(size <= max_size, \"maximum size for tensor at dimension \", d,\n                                \" is \", max_size, \" but size is \", size);\n  TORCH_CHECK(step > 0, \"step is \", step, \" but must be > 0\");\n  sizes.push_back(size);\n  strides.push_back(self.dim() == 0 ? 1 : strides[d]);\n  // The if handles the self.dim() == 0 case\n  if (d < ndim) {\n    sizes[d] = (sizes[d] - size) / step + 1;\n    strides[d] *= step;\n  }\n  return self.as_strided(sizes, strides);\n}\n"
    }
  },
  "torch.nn.functional.fold": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 5422,
      "end_line": 5455,
      "code": "def fold(\n    input: Tensor,\n    output_size: BroadcastingList2[int],\n    kernel_size: BroadcastingList2[int],\n    dilation: BroadcastingList2[int] = 1,\n    padding: BroadcastingList2[int] = 0,\n    stride: BroadcastingList2[int] = 1,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            fold,\n            (input,),\n            input,\n            output_size,\n            kernel_size,\n            dilation=dilation,\n            padding=padding,\n            stride=stride,\n        )\n    return torch._C._nn.col2im(\n        input,\n        _pair(output_size),\n        _pair(kernel_size),\n        _pair(dilation),\n        _pair(padding),\n        _pair(stride),\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.avg_pool1d": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.avg_pool2d": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "mkldnn_avg_pool2d",
      "file": "aten/src/ATen/native/mkldnn/Pooling.cpp",
      "start_line": 52,
      "end_line": 61,
      "code": "Tensor mkldnn_avg_pool2d(\n    const Tensor& self,\n    IntArrayRef kernel_size,\n    IntArrayRef stride,\n    IntArrayRef padding,\n    bool ceil_mode,\n    bool count_include_pad,\n    std::optional<int64_t> divisor_override) {\n  TORCH_CHECK(false, \"mkldnn_avg_pool2d: ATen not compiled with MKLDNN support\");\n}\n"
    }
  },
  "torch.nn.functional.avg_pool3d": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "mkldnn_avg_pool3d",
      "file": "aten/src/ATen/native/mkldnn/Pooling.cpp",
      "start_line": 74,
      "end_line": 83,
      "code": "Tensor mkldnn_avg_pool3d(\n    const Tensor& self,\n    IntArrayRef kernel_size,\n    IntArrayRef stride,\n    IntArrayRef padding,\n    bool ceil_mode,\n    bool count_include_pad,\n    std::optional<int64_t> divisor_override) {\n  TORCH_CHECK(false, \"mkldnn_avg_pool3d: ATen not compiled with MKLDNN support\");\n}\n"
    }
  },
  "torch.nn.functional.max_pool1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_jit_internal.py",
      "start_line": 614,
      "end_line": 624,
      "code": "def fn(*args, **kwargs):\n    dispatch_flag = default\n    if arg_name in kwargs:\n        dispatch_flag = kwargs[arg_name]\n    elif arg_index < len(args):\n        dispatch_flag = args[arg_index]\n\n    if dispatch_flag:\n        return if_true(*args, **kwargs)\n    else:\n        return if_false(*args, **kwargs)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.max_pool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_jit_internal.py",
      "start_line": 614,
      "end_line": 624,
      "code": "def fn(*args, **kwargs):\n    dispatch_flag = default\n    if arg_name in kwargs:\n        dispatch_flag = kwargs[arg_name]\n    elif arg_index < len(args):\n        dispatch_flag = args[arg_index]\n\n    if dispatch_flag:\n        return if_true(*args, **kwargs)\n    else:\n        return if_false(*args, **kwargs)\n"
    },
    "cpp": {
      "function": "max_pool2d",
      "file": "aten/src/ATen/native/Pooling.cpp",
      "start_line": 140,
      "end_line": 165,
      "code": "Tensor max_pool2d(\n    const Tensor& self,\n    IntArrayRef kernel_size,\n    IntArrayRef stride,\n    IntArrayRef padding,\n    IntArrayRef dilation,\n    bool ceil_mode) {\n  if (self.is_quantized()) {\n    return at::quantized_max_pool2d(self, kernel_size, stride, padding,\n                                    dilation, ceil_mode);\n  }\n  if (self.is_mkldnn()) {\n    return at::mkldnn_max_pool2d(\n        self, kernel_size, stride, padding, dilation, ceil_mode);\n  }\n#if defined(C10_MOBILE)\n  if(xnnpack::use_max_pool2d(self, kernel_size, padding, stride,\n                             dilation, ceil_mode)) {\n    return xnnpack::max_pool2d(\n        self, kernel_size, padding, stride, dilation, ceil_mode);\n  }\n#endif\n  auto output_and_indices = at::max_pool2d_with_indices(\n      self, kernel_size, stride, padding, dilation, ceil_mode);\n  return std::get<0>(output_and_indices);\n}\n"
    }
  },
  "torch.nn.functional.max_pool3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_jit_internal.py",
      "start_line": 614,
      "end_line": 624,
      "code": "def fn(*args, **kwargs):\n    dispatch_flag = default\n    if arg_name in kwargs:\n        dispatch_flag = kwargs[arg_name]\n    elif arg_index < len(args):\n        dispatch_flag = args[arg_index]\n\n    if dispatch_flag:\n        return if_true(*args, **kwargs)\n    else:\n        return if_false(*args, **kwargs)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.max_unpool1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 971,
      "end_line": 1007,
      "code": "def max_unpool1d(\n    input: Tensor,\n    indices: Tensor,\n    kernel_size: BroadcastingList1[int],\n    stride: Optional[BroadcastingList1[int]] = None,\n    padding: BroadcastingList1[int] = 0,\n    output_size: Optional[BroadcastingList1[int]] = None,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            max_unpool1d,\n            (input,),\n            input,\n            indices,\n            kernel_size,\n            stride=stride,\n            padding=padding,\n            output_size=output_size,\n        )\n    kernel_size = _single(kernel_size)\n    if stride is not None:\n        _stride = _single(stride)\n    else:\n        _stride = kernel_size\n    padding = _single(padding)\n    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)\n    if isinstance(output_size, list):\n        output_size = output_size + [1]\n    else:\n        output_size = output_size + (1,)\n    return torch._C._nn.max_unpool2d(\n        input.unsqueeze(-1), indices.unsqueeze(-1), output_size\n    ).squeeze(-1)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.max_unpool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1010,
      "end_line": 1040,
      "code": "def max_unpool2d(\n    input: Tensor,\n    indices: Tensor,\n    kernel_size: BroadcastingList2[int],\n    stride: Optional[BroadcastingList2[int]] = None,\n    padding: BroadcastingList2[int] = 0,\n    output_size: Optional[BroadcastingList2[int]] = None,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            max_unpool2d,\n            (input,),\n            input,\n            indices,\n            kernel_size,\n            stride=stride,\n            padding=padding,\n            output_size=output_size,\n        )\n    kernel_size = _pair(kernel_size)\n    if stride is not None:\n        _stride = _pair(stride)\n    else:\n        _stride = kernel_size\n    padding = _pair(padding)\n    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)\n    return torch._C._nn.max_unpool2d(input, indices, output_size)\n"
    },
    "cpp": {
      "function": "max_unpooling2d_forward_cpu",
      "file": "aten/src/ATen/native/MaxUnpooling.cpp",
      "start_line": 69,
      "end_line": 76,
      "code": "Tensor max_unpooling2d_forward_cpu(\n    const Tensor& self,\n    const Tensor& indices,\n    IntArrayRef output_size) {\n  auto output = at::empty({0}, self.options());\n  at::native::max_unpooling2d_forward_out_cpu(self, indices, output_size, output);\n  return output;\n}\n"
    }
  },
  "torch.nn.functional.max_unpool3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1043,
      "end_line": 1073,
      "code": "def max_unpool3d(\n    input: Tensor,\n    indices: Tensor,\n    kernel_size: BroadcastingList3[int],\n    stride: Optional[BroadcastingList3[int]] = None,\n    padding: BroadcastingList3[int] = 0,\n    output_size: Optional[BroadcastingList3[int]] = None,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            max_unpool3d,\n            (input,),\n            input,\n            indices,\n            kernel_size,\n            stride=stride,\n            padding=padding,\n            output_size=output_size,\n        )\n    kernel_size = _triple(kernel_size)\n    if stride is not None:\n        _stride = _triple(stride)\n    else:\n        _stride = kernel_size\n    padding = _triple(padding)\n    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)\n    return torch._C._nn.max_unpool3d(input, indices, output_size, _stride, padding)\n"
    },
    "cpp": {
      "function": "max_unpooling3d_forward_cpu",
      "file": "aten/src/ATen/native/MaxUnpooling.cpp",
      "start_line": 195,
      "end_line": 205,
      "code": "Tensor max_unpooling3d_forward_cpu(\n    const Tensor& self,\n    const Tensor& indices,\n    IntArrayRef output_size,\n    IntArrayRef stride,\n    IntArrayRef padding) {\n  auto output = at::empty({0}, self.options());\n  at::native::max_unpooling3d_forward_out_cpu(\n      self, indices, output_size, stride, padding, output);\n  return output;\n}\n"
    }
  },
  "torch.nn.functional.lp_pool1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1150,
      "end_line": 1183,
      "code": "def lp_pool1d(\n    input: Tensor,\n    norm_type: Union[int, float],\n    kernel_size: int,\n    stride: Optional[BroadcastingList1[int]] = None,\n    ceil_mode: bool = False,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            lp_pool1d,\n            (input,),\n            input,\n            norm_type,\n            kernel_size,\n            stride=stride,\n            ceil_mode=ceil_mode,\n        )\n    if stride is not None:\n        out = avg_pool1d(input.pow(norm_type), kernel_size, stride, 0, ceil_mode)\n    else:\n        out = avg_pool1d(\n            input.pow(norm_type), kernel_size, padding=0, ceil_mode=ceil_mode\n        )\n\n    return (\n        (torch.sign(out) * relu(torch.abs(out))).mul(kernel_size).pow(1.0 / norm_type)\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.lp_pool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1114,
      "end_line": 1147,
      "code": "def lp_pool2d(\n    input: Tensor,\n    norm_type: Union[int, float],\n    kernel_size: BroadcastingList2[int],\n    stride: Optional[BroadcastingList2[int]] = None,\n    ceil_mode: bool = False,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            lp_pool2d,\n            (input,),\n            input,\n            norm_type,\n            kernel_size,\n            stride=stride,\n            ceil_mode=ceil_mode,\n        )\n    kw, kh = _pair(kernel_size)\n    if stride is not None:\n        out = avg_pool2d(input.pow(norm_type), kernel_size, stride, 0, ceil_mode)\n    else:\n        out = avg_pool2d(\n            input.pow(norm_type), kernel_size, padding=0, ceil_mode=ceil_mode\n        )\n\n    return (torch.sign(out) * relu(torch.abs(out))).mul(kw * kh).pow(1.0 / norm_type)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.adaptive_max_pool1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_jit_internal.py",
      "start_line": 614,
      "end_line": 624,
      "code": "def fn(*args, **kwargs):\n    dispatch_flag = default\n    if arg_name in kwargs:\n        dispatch_flag = kwargs[arg_name]\n    elif arg_index < len(args):\n        dispatch_flag = args[arg_index]\n\n    if dispatch_flag:\n        return if_true(*args, **kwargs)\n    else:\n        return if_false(*args, **kwargs)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.adaptive_max_pool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_jit_internal.py",
      "start_line": 614,
      "end_line": 624,
      "code": "def fn(*args, **kwargs):\n    dispatch_flag = default\n    if arg_name in kwargs:\n        dispatch_flag = kwargs[arg_name]\n    elif arg_index < len(args):\n        dispatch_flag = args[arg_index]\n\n    if dispatch_flag:\n        return if_true(*args, **kwargs)\n    else:\n        return if_false(*args, **kwargs)\n"
    },
    "cpp": {
      "function": "adaptive_max_pool2d_out_cpu",
      "file": "aten/src/ATen/native/AdaptiveMaxPooling2d.cpp",
      "start_line": 73,
      "end_line": 76,
      "code": "TORCH_IMPL_FUNC(adaptive_max_pool2d_out_cpu)\n(const Tensor& input, IntArrayRef output_size, const Tensor& output, const Tensor& indices) {\n  adaptive_max_pool2d_kernel(kCPU, output, indices, input, output_size);\n}\n"
    }
  },
  "torch.nn.functional.adaptive_max_pool3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_jit_internal.py",
      "start_line": 614,
      "end_line": 624,
      "code": "def fn(*args, **kwargs):\n    dispatch_flag = default\n    if arg_name in kwargs:\n        dispatch_flag = kwargs[arg_name]\n    elif arg_index < len(args):\n        dispatch_flag = args[arg_index]\n\n    if dispatch_flag:\n        return if_true(*args, **kwargs)\n    else:\n        return if_false(*args, **kwargs)\n"
    },
    "cpp": {
      "function": "adaptive_max_pool3d_out_cpu",
      "file": "aten/src/ATen/native/AdaptiveMaxPooling3d.cpp",
      "start_line": 257,
      "end_line": 348,
      "code": "TORCH_IMPL_FUNC(adaptive_max_pool3d_out_cpu)\n(const Tensor& input, IntArrayRef output_size, const Tensor& output, const Tensor& indices) {\n  int dimD = 0;\n  int dimT = 1;\n  int dimH = 2;\n  int dimW = 3;\n  int64_t sizeB = 1;\n  int64_t sizeD = 0;\n  int64_t isizeT = 0;\n  int64_t isizeH = 0;\n  int64_t isizeW = 0;\n\n  int64_t istrideB = 0;\n  int64_t istrideD = 0;\n  int64_t istrideT = 0;\n  int64_t istrideH = 0;\n  int64_t istrideW = 0;\n\n  if (input.ndimension() == 5) {\n    istrideB = input.stride(0);\n    sizeB = input.size(0);\n    dimD++;\n    dimT++;\n    dimH++;\n    dimW++;\n  }\n\n  /* sizes */\n  sizeD = input.size(dimD);\n  isizeT = input.size(dimT);\n  isizeH = input.size(dimH);\n  isizeW = input.size(dimW);\n  /* strides */\n  istrideD = input.stride(dimD);\n  istrideT = input.stride(dimT);\n  istrideH = input.stride(dimH);\n  istrideW = input.stride(dimW);\n\n  int64_t osizeT = output_size[0];\n  int64_t osizeH = output_size[1];\n  int64_t osizeW = output_size[2];\n\n  if (input.ndimension() == 4) {\n    AT_DISPATCH_FLOATING_TYPES_AND(kBFloat16,\n        input.scalar_type(), \"adaptive_max_pool3d_cpu\", [&] {\n          auto input_data = input.const_data_ptr<scalar_t>();\n          auto output_data = output.data_ptr<scalar_t>();\n          auto indices_data = indices.data_ptr<int64_t>();\n\n          adaptive_max_pool3d_single_out_frame<scalar_t>(\n              input_data,\n              output_data,\n              indices_data,\n              sizeD,\n              isizeT,\n              isizeH,\n              isizeW,\n              osizeT,\n              osizeH,\n              osizeW,\n              istrideD,\n              istrideT,\n              istrideH,\n              istrideW);\n        });\n  } else {\n    AT_DISPATCH_FLOATING_TYPES_AND(kBFloat16,\n        input.scalar_type(), \"adaptive_max_pool3d_cpu\", [&] {\n          auto input_data = input.const_data_ptr<scalar_t>();\n          auto output_data = output.data_ptr<scalar_t>();\n          auto indices_data = indices.data_ptr<int64_t>();\n\n          adaptive_max_pool3d_out_frame<scalar_t>(\n              input_data,\n              output_data,\n              indices_data,\n              sizeB,\n              sizeD,\n              isizeT,\n              isizeH,\n              isizeW,\n              osizeT,\n              osizeH,\n              osizeW,\n              istrideB,\n              istrideD,\n              istrideT,\n              istrideH,\n              istrideW);\n        });\n  }\n}\n"
    }
  },
  "torch.nn.functional.adaptive_avg_pool1d": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.adaptive_avg_pool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1370,
      "end_line": 1382,
      "code": "def adaptive_avg_pool2d(input: Tensor, output_size: BroadcastingList2[int]) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(adaptive_avg_pool2d, (input,), input, output_size)\n    _output_size = _list_with_default(output_size, input.size())\n    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)\n"
    },
    "cpp": {
      "function": "adaptive_avg_pool2d_symint",
      "file": "aten/src/ATen/native/AdaptiveAveragePooling.cpp",
      "start_line": 109,
      "end_line": 140,
      "code": "  Tensor adaptive_avg_pool2d_symint(at::Tensor const& input, SymIntArrayRef output_size) {\n    TORCH_CHECK(output_size.size() == 2, \"adaptive_avg_pool2d: output_size must be 2\");\n    TORCH_CHECK(\n        (output_size[0] >= 0 && output_size[1] >= 0),\n        \"adaptive_avg_pool2d: elements of output_size must be greater than or equal to 0 \",\n        \"but received {\", output_size[0], \", \", output_size[1], \"}\");\n\n    if (input.is_mkldnn()) {\n      return at::mkldnn_adaptive_avg_pool2d(input, C10_AS_INTARRAYREF_SLOW(output_size));\n    }\n\n    if (!input.is_quantized() && output_size[0] == 1 && output_size[1] == 1) {\n      // in this case, adaptive pooling is just computing mean over hw\n      // dimensions, which can be done more efficiently\n      #if defined(C10_MOBILE) && defined(USE_XNNPACK)\n      if (xnnpack::use_global_average_pool(input)) {\n        return xnnpack::global_average_pool(input);\n      }\n      #endif\n\n      Tensor out = input.mean({-1, -2}, /* keepdim = */ true);\n      if (input.suggest_memory_format() == at::MemoryFormat::ChannelsLast) {\n        // assert ndim == 4, since ndim = 3 doesn't give channels_last\n        const auto n = input.sym_size(0);\n        const auto c = input.sym_size(1);\n        out.as_strided__symint({n, c, 1, 1}, {c, 1, c, c});\n      }\n      return out;\n    } else {\n      return _adaptive_avg_pool2d_symint(input, output_size);\n    }\n  }\n"
    }
  },
  "torch.nn.functional.adaptive_avg_pool3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1385,
      "end_line": 1397,
      "code": "def adaptive_avg_pool3d(input: Tensor, output_size: BroadcastingList3[int]) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(adaptive_avg_pool3d, (input,), input, output_size)\n    _output_size = _list_with_default(output_size, input.size())\n    return torch._C._nn.adaptive_avg_pool3d(input, _output_size)\n"
    },
    "cpp": {
      "function": "adaptive_avg_pool3d_symint",
      "file": "aten/src/ATen/native/AdaptiveAveragePooling3d.cpp",
      "start_line": 309,
      "end_line": 330,
      "code": "Tensor adaptive_avg_pool3d_symint(Tensor const& input, SymIntArrayRef output_size) {\n  TORCH_CHECK(output_size.size() == 3, \"adaptive_avg_pool3d: output_size must be 3\");\n  TORCH_CHECK(\n        (output_size[0] >= 0 && output_size[1] >= 0 && output_size[2] >= 0),\n        \"adaptive_avg_pool3d: elements of output_size must be greater than or equal to 0 \",\n        \"but received {\", output_size[0], \", \", output_size[1], \",\", output_size[2], \"}\");\n\n  if (output_size[0] == 1 && output_size[1] == 1 && output_size[2] == 1) {\n    // in this case, adaptive pooling is just computing mean over hw\n    // dimensions, which can be done more efficiently\n    Tensor out = input.mean({-1, -2, -3}, /* keepdim = */ true);\n    if (input.suggest_memory_format() == at::MemoryFormat::ChannelsLast3d) {\n      // assert ndim == 5, since ndim = 4 doesn't give channels_last\n      const auto n = input.sym_size(0);\n      const auto c = input.sym_size(1);\n      out.as_strided__symint({n, c, 1, 1, 1}, {c, 1, c, c, c});\n    }\n    return out;\n  } else {\n    return _adaptive_avg_pool3d_symint(input, output_size);\n  }\n}\n"
    }
  },
  "torch.nn.functional.threshold": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1657,
      "end_line": 1675,
      "code": "def _threshold(\n    input: Tensor,\n    threshold: float,\n    value: float,\n    inplace: bool = False,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            _threshold, (input,), input, threshold, value, inplace=inplace\n        )\n    if inplace:\n        result = _VF.threshold_(input, threshold, value)\n    else:\n        result = _VF.threshold(input, threshold, value)\n    return result\n"
    },
    "cpp": {
      "function": "threshold_quantized_cpu",
      "file": "aten/src/ATen/native/quantized/cpu/qthreshold.cpp",
      "start_line": 33,
      "end_line": 42,
      "code": "Tensor threshold_quantized_cpu(\n    const Tensor& qx,\n    const Scalar& threshold,\n    const Scalar& value) {\n  Tensor qy;\n  AT_DISPATCH_QINT_TYPES(qx.scalar_type(), \"threshold\", [&]() {\n    qy = quantized_threshold_impl(qx, threshold, value);\n  });\n  return qy;\n}\n"
    }
  },
  "torch.nn.functional.threshold_": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "threshold_out",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 681,
      "end_line": 683,
      "code": "TORCH_IMPL_FUNC(threshold_out)(const Tensor& self, const Scalar& threshold, const Scalar& value, const Tensor& result) {\n  threshold_stub(device_type(), *this, threshold, value);\n}\n"
    }
  },
  "torch.nn.functional.relu": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1693,
      "end_line": 1705,
      "code": "def relu(input: Tensor, inplace: bool = False) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_unary(input):\n        return handle_torch_function(relu, (input,), input, inplace=inplace)\n    if inplace:\n        result = torch.relu_(input)\n    else:\n        result = torch.relu(input)\n    return result\n"
    },
    "cpp": {
      "function": "relu",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 511,
      "end_line": 514,
      "code": "Tensor relu(const Tensor & self) {\n  TORCH_CHECK(self.scalar_type() != at::kBool, \"Boolean inputs not supported for relu\");\n  return at::clamp_min(self, 0);\n}\n"
    }
  },
  "torch.nn.functional.relu_": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "relu_",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 516,
      "end_line": 519,
      "code": "Tensor & relu_(Tensor & self) {\n  TORCH_CHECK(self.scalar_type() != at::kBool, \"Boolean inputs not supported for relu\");\n  return at::clamp_min_(self, 0);\n}\n"
    }
  },
  "torch.nn.functional.hardtanh": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1745,
      "end_line": 1767,
      "code": "def hardtanh(\n    input: Tensor,\n    min_val: float = -1.0,\n    max_val: float = 1.0,\n    inplace: bool = False,\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            hardtanh, (input,), input, min_val=min_val, max_val=max_val, inplace=inplace\n        )\n    if min_val > max_val:\n        raise ValueError(\"min_val cannot be greater than max_val\")\n    if inplace:\n        result = torch._C._nn.hardtanh_(input, min_val, max_val)\n    else:\n        result = torch._C._nn.hardtanh(input, min_val, max_val)\n    return result\n"
    },
    "cpp": {
      "function": "hardtanh",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 433,
      "end_line": 436,
      "code": "Tensor hardtanh(const Tensor& self, const Scalar& min, const Scalar& max) {\n  Tensor result = at::empty_like(self);\n  return at::hardtanh_out(result, self, min, max);\n}\n"
    }
  },
  "torch.nn.functional.hardtanh_": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "hardtanh_",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 457,
      "end_line": 459,
      "code": "Tensor& hardtanh_(Tensor& self, const Scalar& min, const Scalar& max) {\n  return at::hardtanh_out(self, self, min, max);\n}\n"
    }
  },
  "torch.nn.functional.hardswish": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2403,
      "end_line": 2425,
      "code": "def hardswish(input: Tensor, inplace: bool = False) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(hardswish, (input,), input, inplace=inplace)\n    if inplace:\n        return torch._C._nn.hardswish_(input)\n    return torch._C._nn.hardswish(input)\n"
    },
    "cpp": {
      "function": "hardswish",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 474,
      "end_line": 484,
      "code": "Tensor hardswish(const Tensor& self) {\n  #if defined(C10_MOBILE) && defined(USE_XNNPACK)\n  if (xnnpack::use_hardswish(self)) {\n    return xnnpack::hardswish(self);\n  }\n  #endif\n  Tensor result;\n  auto iter = TensorIterator::unary_op(result, self);\n  hardswish_stub(iter.device_type(), iter);\n  return iter.output();\n}\n"
    }
  },
  "torch.nn.functional.relu6": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1780,
      "end_line": 1793,
      "code": "def relu6(input: Tensor, inplace: bool = False) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_unary(input):\n        return handle_torch_function(relu6, (input,), input, inplace=inplace)\n    if inplace:\n        result = torch._C._nn.relu6_(input)\n    else:\n        result = torch._C._nn.relu6(input)\n    return result\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.elu": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1796,
      "end_line": 1807,
      "code": "def elu(input: Tensor, alpha: float = 1.0, inplace: bool = False) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(elu, (input,), input, alpha=alpha, inplace=inplace)\n    if inplace:\n        result = torch._C._nn.elu_(input, alpha)\n    else:\n        result = torch._C._nn.elu(input, alpha)\n    return result\n"
    },
    "cpp": {
      "function": "elu_out",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 270,
      "end_line": 274,
      "code": "TORCH_IMPL_FUNC(elu_out) (\n  const Tensor& self, const Scalar& alpha, const Scalar& scale, const Scalar& input_scale, const Tensor& result\n) {\n  elu_stub(device_type(), *this, alpha, scale, input_scale);\n}\n"
    }
  },
  "torch.nn.functional.elu_": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "elu_out",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 270,
      "end_line": 274,
      "code": "TORCH_IMPL_FUNC(elu_out) (\n  const Tensor& self, const Scalar& alpha, const Scalar& scale, const Scalar& input_scale, const Tensor& result\n) {\n  elu_stub(device_type(), *this, alpha, scale, input_scale);\n}\n"
    }
  },
  "torch.nn.functional.selu": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1820,
      "end_line": 1836,
      "code": "def selu(input: Tensor, inplace: bool = False) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_unary(input):\n        return handle_torch_function(selu, (input,), input, inplace=inplace)\n    if inplace:\n        result = torch.selu_(input)\n    else:\n        result = torch.selu(input)\n    return result\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.celu": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1849,
      "end_line": 1869,
      "code": "def celu(\n    input: Tensor,\n    alpha: float = 1.0,\n    inplace: bool = False,\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            celu, (input,), input, alpha=alpha, inplace=inplace\n        )\n    if inplace:\n        result = torch.celu_(input, alpha)\n    else:\n        result = torch.celu(input, alpha)\n    return result\n"
    },
    "cpp": {
      "function": "celu",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 537,
      "end_line": 542,
      "code": "Tensor celu(const Tensor & self, const Scalar& alpha) {\n  TORCH_CHECK(alpha.to<double>() != 0,\n      \"ZeroDivisionError: alpha cannot be 0 for CELU\");\n  double inv_alpha = 1. / alpha.to<double>();\n  return at::elu(self, alpha, Scalar(1.0), Scalar(inv_alpha));\n}\n"
    }
  },
  "torch.nn.functional.leaky_relu": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1882,
      "end_line": 1903,
      "code": "def leaky_relu(\n    input: Tensor,\n    negative_slope: float = 0.01,\n    inplace: bool = False,\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            leaky_relu, (input,), input, negative_slope=negative_slope, inplace=inplace\n        )\n    if inplace:\n        result = torch._C._nn.leaky_relu_(input, negative_slope)\n    else:\n        result = torch._C._nn.leaky_relu(input, negative_slope)\n    return result\n"
    },
    "cpp": {
      "function": "leaky_relu_quantized_cpu",
      "file": "aten/src/ATen/native/quantized/cpu/qrelu.cpp",
      "start_line": 138,
      "end_line": 147,
      "code": "Tensor leaky_relu_quantized_cpu(const Tensor& self, const Scalar& negval) {\n  const auto qx = self.contiguous(self.suggest_memory_format());\n  auto qy = at::_empty_affine_quantized(qx.sizes(),\n      at::device(kCPU).dtype(self.scalar_type()),\n      qx.q_scale(),\n      qx.q_zero_point(),\n      self.suggest_memory_format());\n  qrelu_leaky_stub(self.device().type(), qy, qx, negval);\n  return qy;\n}\n"
    }
  },
  "torch.nn.functional.leaky_relu_": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "leaky_relu_quantized_cpu_",
      "file": "aten/src/ATen/native/quantized/cpu/qrelu.cpp",
      "start_line": 149,
      "end_line": 152,
      "code": "Tensor& leaky_relu_quantized_cpu_(Tensor& self, const Scalar& negval) {\n  qrelu_leaky_stub(self.device().type(), self, self, negval);\n  return self;\n}\n"
    }
  },
  "torch.nn.functional.prelu": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.rrelu": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1937,
      "end_line": 1964,
      "code": "def rrelu(\n    input: Tensor,\n    lower: float = 1.0 / 8,\n    upper: float = 1.0 / 3,\n    training: bool = False,\n    inplace: bool = False,\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            rrelu,\n            (input,),\n            input,\n            lower=lower,\n            upper=upper,\n            training=training,\n            inplace=inplace,\n        )\n    if inplace:\n        result = torch.rrelu_(input, lower, upper, training)\n    else:\n        result = torch.rrelu(input, lower, upper, training)\n    return result\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.rrelu_": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.glu": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1718,
      "end_line": 1742,
      "code": "def glu(input: Tensor, dim: int = -1) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_unary(input):\n        return handle_torch_function(glu, (input,), input, dim=dim)\n    if input.dim() == 0:\n        raise RuntimeError(\n            \"glu does not support scalars because halving size must be even\"\n        )\n    return torch._C._nn.glu(input, dim)\n"
    },
    "cpp": {
      "function": "glu_out",
      "file": "aten/src/ATen/native/GatedLinearUnit.cpp",
      "start_line": 50,
      "end_line": 52,
      "code": "TORCH_IMPL_FUNC(glu_out) (const Tensor& self, int64_t dim, const Tensor& out) {\n  glu_stub(device_type(), *this);\n}\n"
    }
  },
  "torch.nn.functional.gelu": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "mkldnn_gelu",
      "file": "aten/src/ATen/native/mkldnn/Gelu.cpp",
      "start_line": 17,
      "end_line": 19,
      "code": "Tensor mkldnn_gelu(const Tensor& input, c10::string_view approximate) {\n  TORCH_CHECK(false, \"mkldnn_gelu: ATen not compiled with MKLDNN support\");\n}\n"
    }
  },
  "torch.nn.functional.logsigmoid": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.hardshrink": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "hardshrink_out",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 350,
      "end_line": 354,
      "code": "TORCH_IMPL_FUNC(hardshrink_out) (\n  const Tensor & self, const Scalar& lambd, const Tensor& result\n) {\n  hardshrink_stub(device_type(), *this, lambd);\n}\n"
    }
  },
  "torch.nn.functional.tanhshrink": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2018,
      "end_line": 2027,
      "code": "def tanhshrink(input):  # noqa: D400,D402\n    if has_torch_function_unary(input):\n        return handle_torch_function(tanhshrink, (input,), input)\n    return input - input.tanh()\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.softsign": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2030,
      "end_line": 2039,
      "code": "def softsign(input):  # noqa: D400,D402\n    if has_torch_function_unary(input):\n        return handle_torch_function(softsign, (input,), input)\n    return input / (input.abs() + 1)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.softplus": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "softplus_out",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 306,
      "end_line": 310,
      "code": "TORCH_IMPL_FUNC(softplus_out) (\n  const Tensor& self, const Scalar& beta, const Scalar& threshold, const Tensor& result\n) {\n  softplus_stub(device_type(), *this, beta, threshold);\n}\n"
    }
  },
  "torch.nn.functional.softmin": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2070,
      "end_line": 2100,
      "code": "def softmin(\n    input: Tensor,\n    dim: Optional[int] = None,\n    _stacklevel: int = 3,\n    dtype: Optional[DType] = None,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            softmin, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype\n        )\n    if dim is None:\n        dim = _get_softmax_dim(\"softmin\", input.dim(), _stacklevel)\n    if dtype is None:\n        ret = (-input).softmax(dim)\n    else:\n        ret = (-input).softmax(dim, dtype=dtype)\n    return ret\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.softmax": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2103,
      "end_line": 2143,
      "code": "def softmax(\n    input: Tensor,\n    dim: Optional[int] = None,\n    _stacklevel: int = 3,\n    dtype: Optional[DType] = None,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            softmax, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype\n        )\n    if dim is None:\n        dim = _get_softmax_dim(\"softmax\", input.dim(), _stacklevel)\n    if dtype is None:\n        ret = input.softmax(dim)\n    else:\n        ret = input.softmax(dim, dtype=dtype)\n    return ret\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.softshrink": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "softshrink_out",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 362,
      "end_line": 366,
      "code": "TORCH_IMPL_FUNC(softshrink_out) (\n  const Tensor & self, const Scalar& lambd, const Tensor& result\n) {\n  softshrink_stub(device_type(), *this, lambd);\n}\n"
    }
  },
  "torch.nn.functional.gumbel_softmax": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2146,
      "end_line": 2217,
      "code": "def gumbel_softmax(\n    logits: Tensor,\n    tau: float = 1,\n    hard: bool = False,\n    eps: float = 1e-10,\n    dim: int = -1,\n) -> Tensor:\n    if has_torch_function_unary(logits):\n        return handle_torch_function(\n            gumbel_softmax, (logits,), logits, tau=tau, hard=hard, eps=eps, dim=dim\n        )\n    if eps != 1e-10:\n        warnings.warn(\"`eps` parameter is deprecated and has no effect.\")\n\n    gumbels = (\n        -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format)\n        .exponential_()\n        .log()\n    )  # ~Gumbel(0,1)\n    gumbels = (logits + gumbels) / tau  # ~Gumbel(logits,tau)\n    y_soft = gumbels.softmax(dim)\n\n    if hard:\n        # Straight through.\n        index = y_soft.max(dim, keepdim=True)[1]\n        y_hard = torch.zeros_like(\n            logits, memory_format=torch.legacy_contiguous_format\n        ).scatter_(dim, index, 1.0)\n        ret = y_hard - y_soft.detach() + y_soft\n    else:\n        # Reparametrization trick.\n        ret = y_soft\n    return ret\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.log_softmax": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2220,
      "end_line": 2251,
      "code": "def log_softmax(\n    input: Tensor,\n    dim: Optional[int] = None,\n    _stacklevel: int = 3,\n    dtype: Optional[DType] = None,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            log_softmax, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype\n        )\n    if dim is None:\n        dim = _get_softmax_dim(\"log_softmax\", input.dim(), _stacklevel)\n    if dtype is None:\n        ret = input.log_softmax(dim)\n    else:\n        ret = input.log_softmax(dim, dtype=dtype)\n    return ret\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.tanh": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2266,
      "end_line": 2274,
      "code": "def tanh(input):  # noqa: D400,D402\n    return input.tanh()\n"
    },
    "cpp": {
      "function": "tanh_quantized_cpu",
      "file": "aten/src/ATen/native/quantized/cpu/qtanh.cpp",
      "start_line": 92,
      "end_line": 102,
      "code": "Tensor tanh_quantized_cpu(const Tensor& qx) {\n#ifdef USE_PYTORCH_QNNPACK\n  if (at::globalContext().qEngine() == at::QEngine::QNNPACK &&\n      qx.scalar_type() == kQUInt8) {\n    return qnnpack_tanh(qx);\n  }\n#endif  // USE_PYTORCH_QNNPACK\n  Tensor qy;\n  qtanh_stub(qx.device().type(), qx, qy);\n  return qy;\n}\n"
    }
  },
  "torch.nn.functional.sigmoid": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2277,
      "end_line": 2284,
      "code": "def sigmoid(input):  # noqa: D400,D402\n    return input.sigmoid()\n"
    },
    "cpp": {
      "function": "sigmoid_quantized_cpu",
      "file": "aten/src/ATen/native/quantized/cpu/qsigmoid.cpp",
      "start_line": 100,
      "end_line": 128,
      "code": "Tensor sigmoid_quantized_cpu(const Tensor& qx) {\n#ifdef USE_PYTORCH_QNNPACK\n  if (at::globalContext().qEngine() == at::QEngine::QNNPACK &&\n      qx.scalar_type() == kQUInt8) {\n    constexpr double output_scale = 1.0f / 256.0f;\n    constexpr int64_t output_zero_point = 0;\n    return qnnpack_sigmoid(qx, output_scale, output_zero_point);\n  }\n#endif  // USE_PYTORCH_QNNPACK\n  Tensor qy;\n  AT_DISPATCH_QINT_TYPES(qx.scalar_type(), \"qsigmoid\", [&]() {\n    // Naive implementation: uses dequantize/execute/quantize routine\n    // - Output scale is set to 1.0 / 2^(BIT_NUM)\n    // - For signed types output zero point is set to 0\n    // - For unsigned types output zero point is set to (qmax + qmin) / 2.0\n    // See https://stackoverflow.com/a/34448562/3606192 for potential\n    // optimizations\n    double output_scale = 0.00390625;  // 1.0 / 2^8\n    int64_t output_zero_point = 0;\n    // NOLINTNEXTLINE(clang-analyzer-core.NullDereference)\n    if (SCALAR_TYPE == at::kQInt32) {\n      output_scale = 2.3283064365386963e-10;  // 1.0 / 2^32\n    } else if (SCALAR_TYPE == at::kQInt8) {\n      output_zero_point = -128;\n    }\n    qsigmoid_stub(qx.device().type(), qx, qy, output_scale, output_zero_point);\n  });\n  return qy;\n}\n"
    }
  },
  "torch.nn.functional.hardsigmoid": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2287,
      "end_line": 2306,
      "code": "def hardsigmoid(input: Tensor, inplace: bool = False) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(hardsigmoid, (input,), input, inplace=inplace)\n    if inplace:\n        return torch._C._nn.hardsigmoid_(input)\n    return torch._C._nn.hardsigmoid(input)\n"
    },
    "cpp": {
      "function": "hardsigmoid_quantized_cpu",
      "file": "aten/src/ATen/native/quantized/cpu/qhardsigmoid.cpp",
      "start_line": 90,
      "end_line": 100,
      "code": "Tensor hardsigmoid_quantized_cpu(const Tensor& qx) {\n#ifdef USE_PYTORCH_QNNPACK\n  if (at::globalContext().qEngine() == at::QEngine::QNNPACK &&\n      qx.scalar_type() == kQUInt8) {\n    return qnnpack_hardsigmoid(qx);\n  }\n#endif  // USE_PYTORCH_QNNPACK\n  Tensor qy;\n  qhardsigmoid_stub(qx.device().type(), qx, qy);\n  return qy;\n}\n"
    }
  },
  "torch.nn.functional.silu": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2358,
      "end_line": 2380,
      "code": "def silu(input: Tensor, inplace: bool = False) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(silu, (input,), input, inplace=inplace)\n    if inplace:\n        return torch._C._nn.silu_(input)\n    return torch._C._nn.silu(input)\n"
    },
    "cpp": {
      "function": "NestedTensor_silu",
      "file": "aten/src/ATen/native/nested/NestedTensorUnaryOps.cpp",
      "start_line": 150,
      "end_line": 152,
      "code": "Tensor NestedTensor_silu(const Tensor& self){\n  return map_nt(self, at::silu);\n}\n"
    }
  },
  "torch.nn.functional.batch_norm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2781,
      "end_line": 2822,
      "code": "def batch_norm(\n    input: Tensor,\n    running_mean: Optional[Tensor],\n    running_var: Optional[Tensor],\n    weight: Optional[Tensor] = None,\n    bias: Optional[Tensor] = None,\n    training: bool = False,\n    momentum: float = 0.1,\n    eps: float = 1e-5,\n) -> Tensor:\n    if has_torch_function_variadic(input, running_mean, running_var, weight, bias):\n        return handle_torch_function(\n            batch_norm,\n            (input, running_mean, running_var, weight, bias),\n            input,\n            running_mean,\n            running_var,\n            weight=weight,\n            bias=bias,\n            training=training,\n            momentum=momentum,\n            eps=eps,\n        )\n    if training:\n        _verify_batch_size(input.size())\n\n    return torch.batch_norm(\n        input,\n        weight,\n        bias,\n        running_mean,\n        running_var,\n        training,\n        momentum,\n        eps,\n        torch.backends.cudnn.enabled,\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.instance_norm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2836,
      "end_line": 2876,
      "code": "def instance_norm(\n    input: Tensor,\n    running_mean: Optional[Tensor] = None,\n    running_var: Optional[Tensor] = None,\n    weight: Optional[Tensor] = None,\n    bias: Optional[Tensor] = None,\n    use_input_stats: bool = True,\n    momentum: float = 0.1,\n    eps: float = 1e-5,\n) -> Tensor:\n    if has_torch_function_variadic(input, running_mean, running_var, weight, bias):\n        return handle_torch_function(\n            instance_norm,\n            (input, running_mean, running_var, weight, bias),\n            input,\n            running_mean=running_mean,\n            running_var=running_var,\n            weight=weight,\n            bias=bias,\n            use_input_stats=use_input_stats,\n            momentum=momentum,\n            eps=eps,\n        )\n    if use_input_stats:\n        _verify_spatial_size(input.size())\n    return torch.instance_norm(\n        input,\n        weight,\n        bias,\n        running_mean,\n        running_var,\n        use_input_stats,\n        momentum,\n        eps,\n        torch.backends.cudnn.enabled,\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.layer_norm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2879,
      "end_line": 2902,
      "code": "def layer_norm(\n    input: Tensor,\n    normalized_shape: List[int],\n    weight: Optional[Tensor] = None,\n    bias: Optional[Tensor] = None,\n    eps: float = 1e-5,\n) -> Tensor:\n    if has_torch_function_variadic(input, weight, bias):\n        return handle_torch_function(\n            layer_norm,\n            (input, weight, bias),\n            input,\n            normalized_shape,\n            weight=weight,\n            bias=bias,\n            eps=eps,\n        )\n    return torch.layer_norm(\n        input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled\n    )\n"
    },
    "cpp": {
      "function": "layer_norm_symint",
      "file": "aten/src/ATen/native/layer_norm.cpp",
      "start_line": 187,
      "end_line": 199,
      "code": "Tensor layer_norm_symint(\n    const Tensor& input,\n    c10::SymIntArrayRef normalized_shape, const std::optional<Tensor>& weight_opt /* optional */, const std::optional<Tensor>& bias_opt /* optional */,\n    double eps,\n    bool /* cudnn_enable, deprecated */) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> weight_maybe_owned = at::borrow_from_optional_tensor(weight_opt);\n  const Tensor& weight = *weight_maybe_owned;\n  c10::MaybeOwned<Tensor> bias_maybe_owned = at::borrow_from_optional_tensor(bias_opt);\n  const Tensor& bias = *bias_maybe_owned;\n\n  return std::get<0>(at::native_layer_norm_symint(input, normalized_shape, weight, bias, eps));\n}\n"
    }
  },
  "torch.nn.functional.local_response_norm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2960,
      "end_line": 2999,
      "code": "def local_response_norm(\n    input: Tensor,\n    size: int,\n    alpha: float = 1e-4,\n    beta: float = 0.75,\n    k: float = 1.0,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            local_response_norm, (input,), input, size, alpha=alpha, beta=beta, k=k\n        )\n    dim = input.dim()\n    if dim < 3:\n        raise ValueError(\n            f\"Expected 3D or higher dimensionality                          input (got {dim} dimensions)\"\n        )\n\n    if input.numel() == 0:\n        return input\n\n    div = input.mul(input)\n    if dim == 3:\n        div = div.unsqueeze(1)\n        div = pad(div, (0, 0, size // 2, (size - 1) // 2))\n        div = avg_pool2d(div, (size, 1), stride=1).squeeze(1)\n    else:\n        sizes = input.size()\n        div = div.view(sizes[0], 1, sizes[1], sizes[2], -1)\n        div = pad(div, (0, 0, 0, 0, size // 2, (size - 1) // 2))\n        div = avg_pool3d(div, (size, 1, 1), stride=1).squeeze(1)\n        div = div.view(sizes)\n    div = div.mul(alpha).add(k).pow(beta)\n    return input / div\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.normalize": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 5343,
      "end_line": 5377,
      "code": "def normalize(\n    input: Tensor,\n    p: float = 2.0,\n    dim: int = 1,\n    eps: float = 1e-12,\n    out: Optional[Tensor] = None,\n) -> Tensor:\n    if has_torch_function_variadic(input, out):\n        return handle_torch_function(\n            normalize, (input, out), input, p=p, dim=dim, eps=eps, out=out\n        )\n    if out is None:\n        denom = input.norm(p, dim, keepdim=True).clamp_min(eps).expand_as(input)\n        return input / denom\n    else:\n        denom = input.norm(p, dim, keepdim=True).clamp_min_(eps).expand_as(input)\n        return torch.div(input, denom, out=out)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.linear": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "linear",
      "file": "aten/src/ATen/native/Linear.cpp",
      "start_line": 73,
      "end_line": 122,
      "code": "Tensor linear(const Tensor& input, const Tensor& weight, const std::optional<Tensor>& bias_opt) {\n  // _matmul_impl checks this again later, but _flatten_nd_linear does not work on scalars inputs,\n  // so let's try to catch this here already\n  const auto input_dim = input.dim();\n  const auto weight_dim = weight.dim();\n  TORCH_CHECK(input_dim != 0 && weight_dim != 0,\n              \"both arguments to linear need to be at least 1D, but they are \",\n              input_dim, \"D and \", weight_dim, \"D\");\n\n  // See [Note: hacky wrapper removal for optional tensor]\n  auto bias = bias_opt.has_value()\n    ? c10::MaybeOwned<Tensor>::borrowed(*bias_opt)\n    : c10::MaybeOwned<Tensor>::owned(std::in_place);\n  if (input.is_mkldnn()) {\n    return at::mkldnn_linear(input, weight, *bias);\n  }\n#if defined(C10_MOBILE)\n  if (xnnpack::use_linear(input, weight, *bias)) {\n    return xnnpack::linear(input, weight, *bias);\n  }\n#endif\n  if (input_dim == 2 && bias->defined()) {\n    // Fused op is marginally faster.\n    return at::addmm(*bias, input, weight.t());\n  }\n  if (bias->defined() && !input.is_xla()) {\n    // Also hit the fused path for contiguous 3D input, if not using xla\n    // backend. Reshaping/flattening has some performance implications on xla.\n    if (input.is_contiguous() && input_dim == 3) {\n      return _flatten_nd_linear(input, weight, *bias);\n    } else if (input.is_contiguous() && input.layout() == c10::kStrided && weight.layout() == c10::kStrided && bias->dim() == 1) {\n      return _flatten_nd_linear(input, weight, *bias);\n    } else if (parseLinearFlatten3d() && input_dim == 3) {\n      // If user forces flattening via env var\n      const Tensor input_cont = input.contiguous();\n      return _flatten_nd_linear(input_cont, weight, *bias);\n    }\n  }\n  auto output = at::matmul(input, weight.t());\n  if (bias->defined()) {\n    // for composite compliance use out-of-place version of `add`\n    if (isTensorSubclassLike(*bias) ||\n        bias->_fw_grad(/*level*/ 0).defined()) {\n      output = at::add(output, *bias);\n    } else {\n      output.add_(*bias);\n    }\n  }\n  return output;\n}\n"
    }
  },
  "torch.nn.functional.bilinear": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.dropout": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1401,
      "end_line": 1426,
      "code": "def dropout(\n    input: Tensor,\n    p: float = 0.5,\n    training: bool = True,\n    inplace: bool = False,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            dropout, (input,), input, p=p, training=training, inplace=inplace\n        )\n    if p < 0.0 or p > 1.0:\n        raise ValueError(f\"dropout probability has to be between 0 and 1, but got {p}\")\n    return (\n        _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.alpha_dropout": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1429,
      "end_line": 1449,
      "code": "def alpha_dropout(\n    input: Tensor,\n    p: float = 0.5,\n    training: bool = False,\n    inplace: bool = False,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            alpha_dropout, (input,), input, p=p, training=training, inplace=inplace\n        )\n    if p < 0.0 or p > 1.0:\n        raise ValueError(f\"dropout probability has to be between 0 and 1, but got {p}\")\n    return (\n        _VF.alpha_dropout_(input, p, training)\n        if inplace\n        else _VF.alpha_dropout(input, p, training)\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.feature_alpha_dropout": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1614,
      "end_line": 1654,
      "code": "def feature_alpha_dropout(\n    input: Tensor,\n    p: float = 0.5,\n    training: bool = False,\n    inplace: bool = False,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            feature_alpha_dropout,\n            (input,),\n            input,\n            p=p,\n            training=training,\n            inplace=inplace,\n        )\n    if p < 0.0 or p > 1.0:\n        raise ValueError(f\"dropout probability has to be between 0 and 1, but got {p}\")\n    return (\n        _VF.feature_alpha_dropout_(input, p, training)\n        if inplace\n        else _VF.feature_alpha_dropout(input, p, training)\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.dropout2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1503,
      "end_line": 1559,
      "code": "def dropout2d(\n    input: Tensor,\n    p: float = 0.5,\n    training: bool = True,\n    inplace: bool = False,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            dropout2d, (input,), input, p=p, training=training, inplace=inplace\n        )\n    if p < 0.0 or p > 1.0:\n        raise ValueError(f\"dropout probability has to be between 0 and 1, but got {p}\")\n    inp_dim = input.dim()\n    if inp_dim not in (3, 4):\n        warn_msg = (\n            f\"dropout2d: Received a {inp_dim}-D input to dropout2d, which is deprecated \"\n            \"and will result in an error in a future release. To retain the behavior \"\n            \"and silence this warning, please use dropout instead. Note that dropout2d \"\n            \"exists to provide channel-wise dropout on inputs with 2 spatial dimensions, \"\n            \"a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\"\n        )\n        warnings.warn(warn_msg)\n\n    # TODO: Properly support no-batch-dim inputs. For now, these are NOT supported; passing\n    # a 3D input will perform dropout1d behavior instead. This was done historically and the\n    # behavior is maintained here for now.\n    # See https://github.com/pytorch/pytorch/issues/77081\n    if inp_dim == 3:\n        warnings.warn(\n            \"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n            \"1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C \"\n            \"is the channel dim. This behavior will change in a future release to interpret the \"\n            \"input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D \"\n            \"channel-wise dropout behavior, please switch to using dropout1d instead.\"\n        )\n\n    result = (\n        _VF.feature_dropout_(input, p, training)\n        if inplace\n        else _VF.feature_dropout(input, p, training)\n    )\n\n    return result\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.dropout3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 1562,
      "end_line": 1611,
      "code": "def dropout3d(\n    input: Tensor,\n    p: float = 0.5,\n    training: bool = True,\n    inplace: bool = False,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            dropout3d, (input,), input, p=p, training=training, inplace=inplace\n        )\n    if p < 0.0 or p > 1.0:\n        raise ValueError(f\"dropout probability has to be between 0 and 1, but got {p}\")\n    inp_dim = input.dim()\n    if inp_dim not in (4, 5):\n        warn_msg = (\n            f\"dropout3d: Received a {inp_dim}-D input to dropout3d, which is deprecated \"\n            \"and will result in an error in a future release. To retain the behavior \"\n            \"and silence this warning, please use dropout instead. Note that dropout3d \"\n            \"exists to provide channel-wise dropout on inputs with 3 spatial dimensions, \"\n            \"a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\"\n        )\n        warnings.warn(warn_msg)\n\n    is_batched = inp_dim == 5\n    if not is_batched:\n        input = input.unsqueeze_(0) if inplace else input.unsqueeze(0)\n\n    result = (\n        _VF.feature_dropout_(input, p, training)\n        if inplace\n        else _VF.feature_dropout(input, p, training)\n    )\n\n    if not is_batched:\n        result = result.squeeze_(0) if inplace else result.squeeze(0)\n    return result\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.embedding": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2437,
      "end_line": 2551,
      "code": "def embedding(\n    input: Tensor,\n    weight: Tensor,\n    padding_idx: Optional[int] = None,\n    max_norm: Optional[float] = None,\n    norm_type: float = 2.0,\n    scale_grad_by_freq: bool = False,\n    sparse: bool = False,\n) -> Tensor:\n    if has_torch_function_variadic(input, weight):\n        return handle_torch_function(\n            embedding,\n            (input, weight),\n            input,\n            weight,\n            padding_idx=padding_idx,\n            max_norm=max_norm,\n            norm_type=norm_type,\n            scale_grad_by_freq=scale_grad_by_freq,\n            sparse=sparse,\n        )\n    if padding_idx is not None:\n        if padding_idx > 0:\n            assert padding_idx < weight.size(\n                0\n            ), \"Padding_idx must be within num_embeddings\"\n        elif padding_idx < 0:\n            assert padding_idx >= -weight.size(\n                0\n            ), \"Padding_idx must be within num_embeddings\"\n            padding_idx = weight.size(0) + padding_idx\n    else:\n        padding_idx = -1\n    if max_norm is not None:\n        # Note [embedding_renorm contiguous]\n        # `embedding_renorm_` will call .contiguous() on input anyways, so we\n        # call it here and take advantage of the improved locality in the\n        # `embedding` call below too.\n        input = input.contiguous()\n        # Note [embedding_renorm set_grad_enabled]\n        # XXX: equivalent to\n        # with torch.no_grad():\n        #   torch.embedding_renorm_\n        # remove once script supports set_grad_enabled\n        _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n"
    },
    "cpp": {
      "function": "embedding_symint",
      "file": "aten/src/ATen/native/Embedding.cpp",
      "start_line": 37,
      "end_line": 54,
      "code": "Tensor embedding_symint(const Tensor & weight, const Tensor & indices,\n                        c10::SymInt padding_idx, bool scale_grad_by_freq, bool sparse) {\n  TORCH_CHECK(weight.dim() == 2,  \"'weight' must be 2-D\");\n  auto indices_arg = TensorArg(indices, \"indices\", 1);\n  checkScalarTypes(\"embedding\", indices_arg, {kLong, kInt});\n\n  // TODO: use tensor.index() after improving perf\n  if (indices.dim() == 1) {\n    return weight.index_select(0, indices);\n  }\n\n  auto size = indices.sym_sizes().vec();\n  for (const auto& d : weight.sym_sizes().slice(1)) {\n    size.push_back(d);\n  }\n\n  return weight.index_select(0, indices.reshape(-1)).view_symint(size);\n}\n"
    }
  },
  "torch.nn.functional.embedding_bag": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 2554,
      "end_line": 2755,
      "code": "def embedding_bag(\n    input: Tensor,\n    weight: Tensor,\n    offsets: Optional[Tensor] = None,\n    max_norm: Optional[float] = None,\n    norm_type: float = 2,\n    scale_grad_by_freq: bool = False,\n    mode: str = \"mean\",\n    sparse: bool = False,\n    per_sample_weights: Optional[Tensor] = None,\n    include_last_offset: bool = False,\n    padding_idx: Optional[int] = None,\n) -> Tensor:\n    if has_torch_function_variadic(input, weight, offsets, per_sample_weights):\n        return handle_torch_function(\n            embedding_bag,\n            (input, weight, offsets, per_sample_weights),\n            input,\n            weight,\n            offsets=offsets,\n            max_norm=max_norm,\n            norm_type=norm_type,\n            scale_grad_by_freq=scale_grad_by_freq,\n            mode=mode,\n            sparse=sparse,\n            per_sample_weights=per_sample_weights,\n            include_last_offset=include_last_offset,\n            padding_idx=padding_idx,\n        )\n    # Check for backward compatibility.\n    # Used to be embedding_bag(weight, input, ...)\n    # Now is     embedding_bag(input, weight, ...)\n    if weight.dtype == torch.long and input.is_floating_point():\n        warnings.warn(\n            \"Argument order of nn.functional.embedding_bag was changed. \"\n            \"Usage `embedding_bag(weight, input, ...)` is deprecated, \"\n            \"and should now be `embedding_bag(input, weight, ...)`.\"\n        )\n        weight, input = input, weight\n\n    if per_sample_weights is not None and input.size() != per_sample_weights.size():\n        raise ValueError(\n            f\"embedding_bag: If per_sample_weights ({per_sample_weights.shape}) is not None, \"\n            f\"then it must have the same shape as the input ({input.shape})\"\n        )\n\n    if not weight.dim() == 2:\n        raise ValueError(\n            f\"weight has to be a 2D Tensor, but got Tensor of dimension {weight.dim()}\"\n        )\n\n    if input.dim() == 2:\n        if offsets is not None:\n            type_str = \"<unknown>\"\n            # TODO: Remove this once script supports type() calls\n            if not torch.jit.is_scripting():\n                type_str = str(type(offsets))\n            raise ValueError(\n                \"if input is 2D, then offsets has to be None\"\n                \", as input is treated is a mini-batch of\"\n                \" fixed length sequences. However, found \"\n                f\"offsets of type {type_str}\"\n            )\n        offsets = torch.arange(\n            0, input.numel(), input.size(1), dtype=input.dtype, device=input.device\n        )\n\n        input = input.reshape(-1)\n        if per_sample_weights is not None:\n            per_sample_weights = per_sample_weights.reshape(-1)\n    elif input.dim() == 1:\n        if offsets is None:\n            raise ValueError(\"offsets has to be a 1D Tensor but got None\")\n        if offsets.dim() != 1:\n            raise ValueError(\"offsets has to be a 1D Tensor\")\n    else:\n        raise ValueError(\n            f\"input has to be 1D or 2D Tensor, but got Tensor of dimension {input.dim()}\"\n        )\n    if mode == \"sum\":\n        mode_enum = 0\n    elif mode == \"mean\":\n        mode_enum = 1\n    elif mode == \"max\":\n        mode_enum = 2\n\n        if scale_grad_by_freq:\n            raise ValueError(\n                \"max mode does not support scaling the gradient by the frequency\"\n            )\n\n        if sparse:\n            raise ValueError(\"max mode does not support sparse weights\")\n\n    else:\n        raise ValueError(\"mode has to be one of sum, mean or max\")\n\n    if max_norm is not None:\n        # XXX: equivalent to\n        # with torch.no_grad():\n        #   torch.nembedding_renorm_\n        # remove once script supports set_grad_enabled\n        _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\n\n    if per_sample_weights is not None and mode != \"sum\":\n        raise NotImplementedError(\n            \"embedding_bag: per_sample_weights was not None. \"\n            \"per_sample_weights is only supported for mode='sum' \"\n            f\"(got mode='{mode}'). Please open a feature request on GitHub.\"\n        )\n\n    ret, _, _, _ = torch.embedding_bag(\n        weight,\n        input,\n        offsets,\n        scale_grad_by_freq,\n        mode_enum,\n        sparse,\n        per_sample_weights,\n        include_last_offset,\n        padding_idx,\n    )\n    return ret\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.one_hot": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.pairwise_distance": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.cosine_similarity": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.pdist": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.binary_cross_entropy": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3489,
      "end_line": 3554,
      "code": "def binary_cross_entropy(\n    input: Tensor,\n    target: Tensor,\n    weight: Optional[Tensor] = None,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:\n    if has_torch_function_variadic(input, target, weight):\n        return handle_torch_function(\n            binary_cross_entropy,\n            (input, target, weight),\n            input,\n            target,\n            weight=weight,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if size_average is not None or reduce is not None:\n        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n    else:\n        reduction_enum = _Reduction.get_enum(reduction)\n    if target.size() != input.size():\n        raise ValueError(\n            f\"Using a target size ({target.size()}) that is different to the input size ({input.size()}) is deprecated. \"\n            \"Please ensure they have the same size.\"\n        )\n\n    if weight is not None:\n        new_size = _infer_size(target.size(), weight.size())\n        weight = weight.expand(new_size)\n\n    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)\n"
    },
    "cpp": {
      "function": "binary_cross_entropy_cpu",
      "file": "aten/src/ATen/native/Loss.cpp",
      "start_line": 253,
      "end_line": 261,
      "code": "Tensor binary_cross_entropy_cpu(const Tensor& input, const Tensor& target, const std::optional<Tensor>& weight_opt, int64_t reduction) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> weight_maybe_owned = at::borrow_from_optional_tensor(weight_opt);\n  const Tensor& weight = *weight_maybe_owned;\n\n    Tensor loss = at::empty_like(input);\n    return at::native::binary_cross_entropy_out_cpu(\n        input, target, weight, reduction, loss);\n}\n"
    }
  },
  "torch.nn.functional.binary_cross_entropy_with_logits": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3557,
      "end_line": 3630,
      "code": "def binary_cross_entropy_with_logits(\n    input: Tensor,\n    target: Tensor,\n    weight: Optional[Tensor] = None,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n    pos_weight: Optional[Tensor] = None,\n) -> Tensor:\n    if has_torch_function_variadic(input, target, weight, pos_weight):\n        return handle_torch_function(\n            binary_cross_entropy_with_logits,\n            (input, target, weight, pos_weight),\n            input,\n            target,\n            weight=weight,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n            pos_weight=pos_weight,\n        )\n    if size_average is not None or reduce is not None:\n        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n    else:\n        reduction_enum = _Reduction.get_enum(reduction)\n\n    if not (target.size() == input.size()):\n        raise ValueError(\n            f\"Target size ({target.size()}) must be the same as input size ({input.size()})\"\n        )\n\n    return torch.binary_cross_entropy_with_logits(\n        input, target, weight, pos_weight, reduction_enum\n    )\n"
    },
    "cpp": {
      "function": "binary_cross_entropy_with_logits",
      "file": "aten/src/ATen/native/Loss.cpp",
      "start_line": 362,
      "end_line": 383,
      "code": "Tensor binary_cross_entropy_with_logits(const Tensor& input, const Tensor& target, const std::optional<Tensor>& weight_opt, const std::optional<Tensor>& pos_weight_opt, int64_t reduction) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> weight_maybe_owned = at::borrow_from_optional_tensor(weight_opt);\n  const Tensor& weight = *weight_maybe_owned;\n  c10::MaybeOwned<Tensor> pos_weight_maybe_owned = at::borrow_from_optional_tensor(pos_weight_opt);\n  const Tensor& pos_weight = *pos_weight_maybe_owned;\n\n  auto log_sigmoid_input = at::log_sigmoid(input);\n  if (pos_weight.defined()) {\n      // pos_weight need to be broadcasted, thus mul(target) is not inplace.\n      auto log_weight = (pos_weight - 1).mul(target).add_(1);\n      log_sigmoid_input.mul_(log_weight);\n  }\n\n  Tensor loss = (1 - target).mul_(input).sub_(log_sigmoid_input);\n\n  if (weight.defined()) {\n      loss.mul_(weight);\n  }\n\n  return apply_loss_reduction(loss, reduction);\n}\n"
    }
  },
  "torch.nn.functional.poisson_nll_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3153,
      "end_line": 3217,
      "code": "def poisson_nll_loss(\n    input: Tensor,\n    target: Tensor,\n    log_input: bool = True,\n    full: bool = False,\n    size_average: Optional[bool] = None,\n    eps: float = 1e-8,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:\n    if has_torch_function_variadic(input, target):\n        return handle_torch_function(\n            poisson_nll_loss,\n            (input, target),\n            input,\n            target,\n            log_input=log_input,\n            full=full,\n            size_average=size_average,\n            eps=eps,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if size_average is not None or reduce is not None:\n        reduction = _Reduction.legacy_get_string(size_average, reduce)\n    if reduction != \"none\" and reduction != \"mean\" and reduction != \"sum\":\n        ret = input\n        raise ValueError(reduction + \" is not a valid value for reduction\")\n\n    ret = torch.poisson_nll_loss(\n        input, target, log_input, full, eps, _Reduction.get_enum(reduction)\n    )\n    return ret\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.cosine_embedding_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3968,
      "end_line": 3997,
      "code": "def cosine_embedding_loss(\n    input1: Tensor,\n    input2: Tensor,\n    target: Tensor,\n    margin: float = 0,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_variadic(input1, input2, target):\n        return handle_torch_function(\n            cosine_embedding_loss,\n            (input1, input2, target),\n            input1,\n            input2,\n            target,\n            margin=margin,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if size_average is not None or reduce is not None:\n        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n    else:\n        reduction_enum = _Reduction.get_enum(reduction)\n    return torch.cosine_embedding_loss(input1, input2, target, margin, reduction_enum)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.cross_entropy": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3389,
      "end_line": 3486,
      "code": "def cross_entropy(\n    input: Tensor,\n    target: Tensor,\n    weight: Optional[Tensor] = None,\n    size_average: Optional[bool] = None,\n    ignore_index: int = -100,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n    label_smoothing: float = 0.0,\n) -> Tensor:\n    if has_torch_function_variadic(input, target, weight):\n        return handle_torch_function(\n            cross_entropy,\n            (input, target, weight),\n            input,\n            target,\n            weight=weight,\n            size_average=size_average,\n            ignore_index=ignore_index,\n            reduce=reduce,\n            reduction=reduction,\n            label_smoothing=label_smoothing,\n        )\n    if size_average is not None or reduce is not None:\n        reduction = _Reduction.legacy_get_string(size_average, reduce)\n    return torch._C._nn.cross_entropy_loss(\n        input,\n        target,\n        weight,\n        _Reduction.get_enum(reduction),\n        ignore_index,\n        label_smoothing,\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.ctc_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3005,
      "end_line": 3077,
      "code": "def ctc_loss(\n    log_probs: Tensor,\n    targets: Tensor,\n    input_lengths: Tensor,\n    target_lengths: Tensor,\n    blank: int = 0,\n    reduction: str = \"mean\",\n    zero_infinity: bool = False,\n) -> Tensor:\n    if has_torch_function_variadic(log_probs, targets, input_lengths, target_lengths):\n        return handle_torch_function(\n            ctc_loss,\n            (log_probs, targets, input_lengths, target_lengths),\n            log_probs,\n            targets,\n            input_lengths,\n            target_lengths,\n            blank=blank,\n            reduction=reduction,\n            zero_infinity=zero_infinity,\n        )\n    return torch.ctc_loss(\n        log_probs,\n        targets,\n        input_lengths,\n        target_lengths,\n        blank,\n        _Reduction.get_enum(reduction),\n        zero_infinity,\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.hinge_embedding_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3834,
      "end_line": 3861,
      "code": "def hinge_embedding_loss(\n    input: Tensor,\n    target: Tensor,\n    margin: float = 1.0,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_variadic(input, target):\n        return handle_torch_function(\n            hinge_embedding_loss,\n            (input, target),\n            input,\n            target,\n            margin=margin,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if size_average is not None or reduce is not None:\n        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n    else:\n        reduction_enum = _Reduction.get_enum(reduction)\n    return torch.hinge_embedding_loss(input, target, margin, reduction_enum)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.kl_div": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3306,
      "end_line": 3386,
      "code": "def kl_div(\n    input: Tensor,\n    target: Tensor,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n    log_target: bool = False,\n) -> Tensor:\n    if has_torch_function_variadic(input, target):\n        return handle_torch_function(\n            kl_div,\n            (input, target),\n            input,\n            target,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n            log_target=log_target,\n        )\n    if size_average is not None or reduce is not None:\n        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n    else:\n        if reduction == \"mean\":\n            warnings.warn(\n                \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n                \"'batchmean' divides only by the batch size, and aligns with the KL div math definition.\"\n                \"'mean' will be changed to behave the same as 'batchmean' in the next major release.\"\n            )\n\n        # special case for batchmean\n        if reduction == \"batchmean\":\n            reduction_enum = _Reduction.get_enum(\"sum\")\n        else:\n            reduction_enum = _Reduction.get_enum(reduction)\n\n    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)\n\n    if reduction == \"batchmean\" and input.dim() != 0:\n        reduced = reduced / input.size()[0]\n\n    return reduced\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.l1_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3720,
      "end_line": 3756,
      "code": "def l1_loss(\n    input: Tensor,\n    target: Tensor,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_variadic(input, target):\n        return handle_torch_function(\n            l1_loss,\n            (input, target),\n            input,\n            target,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if not (target.size() == input.size()):\n        warnings.warn(\n            f\"Using a target size ({target.size()}) that is different to the input size ({input.size()}). \"\n            \"This will likely lead to incorrect results due to broadcasting. \"\n            \"Please ensure they have the same size.\",\n            stacklevel=2,\n        )\n    if size_average is not None or reduce is not None:\n        reduction = _Reduction.legacy_get_string(size_average, reduce)\n\n    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n    return torch._C._nn.l1_loss(\n        expanded_input, expanded_target, _Reduction.get_enum(reduction)\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.mse_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3759,
      "end_line": 3794,
      "code": "def mse_loss(\n    input: Tensor,\n    target: Tensor,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_variadic(input, target):\n        return handle_torch_function(\n            mse_loss,\n            (input, target),\n            input,\n            target,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if not (target.size() == input.size()):\n        warnings.warn(\n            f\"Using a target size ({target.size()}) that is different to the input size ({input.size()}). \"\n            \"This will likely lead to incorrect results due to broadcasting. \"\n            \"Please ensure they have the same size.\",\n            stacklevel=2,\n        )\n    if size_average is not None or reduce is not None:\n        reduction = _Reduction.legacy_get_string(size_average, reduce)\n\n    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n    return torch._C._nn.mse_loss(\n        expanded_input, expanded_target, _Reduction.get_enum(reduction)\n    )\n"
    },
    "cpp": {
      "function": "mse_loss_out",
      "file": "aten/src/ATen/native/Loss.cpp",
      "start_line": 128,
      "end_line": 142,
      "code": "TORCH_IMPL_FUNC(mse_loss_out)\n(const Tensor& input, const Tensor& target, int64_t reduction, const Tensor& result) {\n  if (reduction != Reduction::None) {\n    Tensor loss;\n    auto iter = TensorIterator::borrowing_binary_op(loss, input, target);\n    mse_stub(iter.device_type(), iter);\n    if (reduction == Reduction::Mean) {\n      at::mean_out(const_cast<Tensor&>(result), iter.output(), IntArrayRef{});\n    } else {\n      at::sum_out(const_cast<Tensor&>(result), iter.output(), IntArrayRef{});\n    }\n  } else {\n    mse_stub(device_type(), *this);\n  }\n}\n"
    }
  },
  "torch.nn.functional.margin_ranking_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3797,
      "end_line": 3831,
      "code": "def margin_ranking_loss(\n    input1: Tensor,\n    input2: Tensor,\n    target: Tensor,\n    margin: float = 0,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_variadic(input1, input2, target):\n        return handle_torch_function(\n            margin_ranking_loss,\n            (input1, input2, target),\n            input1,\n            input2,\n            target,\n            margin=margin,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if size_average is not None or reduce is not None:\n        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n    else:\n        reduction_enum = _Reduction.get_enum(reduction)\n    if input1.dim() != input2.dim() or input1.dim() != target.dim():\n        raise RuntimeError(\n            f\"margin_ranking_loss : All input tensors should have same dimension but got sizes: \"\n            f\"input1: {input1.size()}, input2: {input2.size()}, target: {target.size()} \"\n        )\n    return torch.margin_ranking_loss(input1, input2, target, margin, reduction_enum)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.multilabel_margin_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3864,
      "end_line": 3889,
      "code": "def multilabel_margin_loss(\n    input: Tensor,\n    target: Tensor,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_variadic(input, target):\n        return handle_torch_function(\n            multilabel_margin_loss,\n            (input, target),\n            input,\n            target,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if size_average is not None or reduce is not None:\n        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n    else:\n        reduction_enum = _Reduction.get_enum(reduction)\n    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.multilabel_soft_margin_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3921,
      "end_line": 3965,
      "code": "def multilabel_soft_margin_loss(\n    input: Tensor,\n    target: Tensor,\n    weight: Optional[Tensor] = None,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_variadic(input, target, weight):\n        return handle_torch_function(\n            multilabel_soft_margin_loss,\n            (input, target, weight),\n            input,\n            target,\n            weight=weight,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if size_average is not None or reduce is not None:\n        reduction = _Reduction.legacy_get_string(size_average, reduce)\n\n    loss = -(target * logsigmoid(input) + (1 - target) * logsigmoid(-input))\n\n    if weight is not None:\n        loss = loss * weight\n\n    class_dim = input.dim() - 1\n    C = input.size(class_dim)\n    loss = loss.sum(dim=class_dim) / C  # only return N loss values\n\n    if reduction == \"none\":\n        ret = loss\n    elif reduction == \"mean\":\n        ret = loss.mean()\n    elif reduction == \"sum\":\n        ret = loss.sum()\n    else:\n        ret = input\n        raise ValueError(reduction + \" is not valid\")\n    return ret\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.multi_margin_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 4000,
      "end_line": 4039,
      "code": "def multi_margin_loss(\n    input: Tensor,\n    target: Tensor,\n    p: int = 1,\n    margin: float = 1.0,\n    weight: Optional[Tensor] = None,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_variadic(input, target, weight):\n        return handle_torch_function(\n            multi_margin_loss,\n            (input, target, weight),\n            input,\n            target,\n            p=p,\n            margin=margin,\n            weight=weight,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if size_average is not None or reduce is not None:\n        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n    else:\n        reduction_enum = _Reduction.get_enum(reduction)\n    if p != 1 and p != 2:\n        raise ValueError(\"only p == 1 and p == 2 supported\")\n    if weight is not None:\n        if weight.dim() != 1:\n            raise ValueError(\"weight must be one-dimensional\")\n\n    return torch._C._nn.multi_margin_loss(\n        input, target, p, margin, weight, reduction_enum\n    )\n"
    },
    "cpp": {
      "function": "multi_margin_loss_cpu",
      "file": "aten/src/ATen/native/LossMultiMargin.cpp",
      "start_line": 264,
      "end_line": 275,
      "code": "Tensor multi_margin_loss_cpu(\n    const Tensor& input,\n    const Tensor& target,\n    const Scalar& p,\n    const Scalar& margin,\n    const std::optional<Tensor>& weight,\n    int64_t reduction) {\n  auto output = at::empty({0}, input.options());\n  multi_margin_loss_out_cpu_template(\n      output, input, target, p.toInt(), margin, weight, reduction);\n  return output;\n}\n"
    }
  },
  "torch.nn.functional.nll_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3084,
      "end_line": 3150,
      "code": "def nll_loss(\n    input: Tensor,\n    target: Tensor,\n    weight: Optional[Tensor] = None,\n    size_average: Optional[bool] = None,\n    ignore_index: int = -100,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:\n    if has_torch_function_variadic(input, target, weight):\n        return handle_torch_function(\n            nll_loss,\n            (input, target, weight),\n            input,\n            target,\n            weight=weight,\n            size_average=size_average,\n            ignore_index=ignore_index,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if size_average is not None or reduce is not None:\n        reduction = _Reduction.legacy_get_string(size_average, reduce)\n    return torch._C._nn.nll_loss_nd(\n        input, target, weight, _Reduction.get_enum(reduction), ignore_index\n    )\n"
    },
    "cpp": {
      "function": "nll_loss_symint",
      "file": "aten/src/ATen/native/LossNLL.cpp",
      "start_line": 670,
      "end_line": 676,
      "code": "Tensor nll_loss_symint(const Tensor & self, const Tensor & target, const std::optional<Tensor>& weight_opt, int64_t reduction, c10::SymInt ignore_index) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> weight_maybe_owned = at::borrow_from_optional_tensor(weight_opt);\n  const Tensor& weight = *weight_maybe_owned;\n\n  return std::get<0>(at::nll_loss_forward_symint(self, target, weight, reduction, std::move(ignore_index)));\n}\n"
    }
  },
  "torch.nn.functional.smooth_l1_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3633,
      "end_line": 3678,
      "code": "def smooth_l1_loss(\n    input: Tensor,\n    target: Tensor,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n    beta: float = 1.0,\n) -> Tensor:\n    if has_torch_function_variadic(input, target):\n        return handle_torch_function(\n            smooth_l1_loss,\n            (input, target),\n            input,\n            target,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n            beta=beta,\n        )\n    if not (target.size() == input.size()):\n        warnings.warn(\n            f\"Using a target size ({target.size()}) that is different to the input size ({input.size()}). \"\n            \"This will likely lead to incorrect results due to broadcasting. \"\n            \"Please ensure they have the same size.\",\n            stacklevel=2,\n        )\n    if size_average is not None or reduce is not None:\n        reduction = _Reduction.legacy_get_string(size_average, reduce)\n\n    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n\n    if beta == 0.0:\n        return torch._C._nn.l1_loss(\n            expanded_input, expanded_target, _Reduction.get_enum(reduction)\n        )\n    else:\n        return torch._C._nn.smooth_l1_loss(\n            expanded_input, expanded_target, _Reduction.get_enum(reduction), beta\n        )\n"
    },
    "cpp": {
      "function": "smooth_l1_loss_out",
      "file": "aten/src/ATen/native/Loss.cpp",
      "start_line": 112,
      "end_line": 126,
      "code": "TORCH_IMPL_FUNC(smooth_l1_loss_out)\n(const Tensor& input, const Tensor& target, int64_t reduction, double beta, const Tensor& result) {\n  if (reduction != Reduction::None) {\n    Tensor loss;\n    auto iter = TensorIterator::borrowing_binary_op(loss, input, target);\n    smooth_l1_stub(iter.device_type(), iter, beta);\n    if (reduction == Reduction::Mean) {\n      at::mean_out(const_cast<Tensor&>(result), iter.output(), IntArrayRef{});\n    } else {\n      at::sum_out(const_cast<Tensor&>(result), iter.output(), IntArrayRef{});\n    }\n  } else {\n    smooth_l1_stub(device_type(), *this, beta);\n  }\n}\n"
    }
  },
  "torch.nn.functional.soft_margin_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 3892,
      "end_line": 3918,
      "code": "def soft_margin_loss(\n    input: Tensor,\n    target: Tensor,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:  # noqa: D400,D402\n    if has_torch_function_variadic(input, target):\n        return handle_torch_function(\n            soft_margin_loss,\n            (input, target),\n            input,\n            target,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if size_average is not None or reduce is not None:\n        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n    else:\n        reduction_enum = _Reduction.get_enum(reduction)\n    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)\n"
    },
    "cpp": {
      "function": "soft_margin_loss",
      "file": "aten/src/ATen/native/Loss.cpp",
      "start_line": 432,
      "end_line": 439,
      "code": "Tensor soft_margin_loss(\n    const Tensor& input,\n    const Tensor& target,\n    int64_t reduction) {\n  auto output = at::empty({0}, input.options());\n  at::soft_margin_loss_out(output, input, target, reduction);\n  return output;\n}\n"
    }
  },
  "torch.nn.functional.triplet_margin_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 5224,
      "end_line": 5263,
      "code": "def triplet_margin_loss(\n    anchor: Tensor,\n    positive: Tensor,\n    negative: Tensor,\n    margin: float = 1.0,\n    p: float = 2,\n    eps: float = 1e-6,\n    swap: bool = False,\n    size_average: Optional[bool] = None,\n    reduce: Optional[bool] = None,\n    reduction: str = \"mean\",\n) -> Tensor:\n    if has_torch_function_variadic(anchor, positive, negative):\n        return handle_torch_function(\n            triplet_margin_loss,\n            (anchor, positive, negative),\n            anchor,\n            positive,\n            negative,\n            margin=margin,\n            p=p,\n            eps=eps,\n            swap=swap,\n            size_average=size_average,\n            reduce=reduce,\n            reduction=reduction,\n        )\n    if size_average is not None or reduce is not None:\n        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n    else:\n        reduction_enum = _Reduction.get_enum(reduction)\n    if margin <= 0:\n        raise ValueError(f\"margin must be greater than 0, got {margin}\")\n    return torch.triplet_margin_loss(\n        anchor, positive, negative, margin, p, eps, swap, reduction_enum\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.triplet_margin_with_distance_loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 5266,
      "end_line": 5340,
      "code": "def triplet_margin_with_distance_loss(\n    anchor: Tensor,\n    positive: Tensor,\n    negative: Tensor,\n    *,\n    distance_function: Optional[Callable[[Tensor, Tensor], Tensor]] = None,\n    margin: float = 1.0,\n    swap: bool = False,\n    reduction: str = \"mean\",\n) -> Tensor:\n    if torch.jit.is_scripting():\n        raise NotImplementedError(\n            \"F.triplet_margin_with_distance_loss does not support JIT scripting: \"\n            \"functions requiring Callables cannot be scripted.\"\n        )\n\n    if has_torch_function_variadic(anchor, positive, negative):\n        return handle_torch_function(\n            triplet_margin_with_distance_loss,\n            (anchor, positive, negative),\n            anchor,\n            positive,\n            negative,\n            distance_function=distance_function,\n            margin=margin,\n            swap=swap,\n            reduction=reduction,\n        )\n\n    # Check validity of reduction mode\n    if reduction not in (\"mean\", \"sum\", \"none\"):\n        raise ValueError(f\"{reduction} is not a valid value for reduction\")\n\n    # Check validity of margin\n    if margin <= 0:\n        raise ValueError(f\"margin must be greater than 0, got {margin}\")\n\n    # Check dimensions\n    a_dim = anchor.ndim\n    p_dim = positive.ndim\n    n_dim = negative.ndim\n    if not (a_dim == p_dim and p_dim == n_dim):\n        raise RuntimeError(\n            f\"The anchor, positive, and negative tensors are expected to have \"\n            f\"the same number of dimensions, but got: anchor {a_dim}D, \"\n            f\"positive {p_dim}D, and negative {n_dim}D inputs\"\n        )\n\n    # Calculate loss\n    if distance_function is None:\n        distance_function = torch.pairwise_distance\n\n    dist_pos = distance_function(anchor, positive)\n    dist_neg = distance_function(anchor, negative)\n    # The distance swap is described in the paper \"Learning shallow\n    # convolutional feature descriptors with triplet losses\" by V. Balntas, E.\n    # Riba et al.  If True, and if the positive example is closer to the\n    # negative example than the anchor is, swaps the positive example and the\n    # anchor in the loss computation.\n    if swap:\n        dist_swap = distance_function(positive, negative)\n        dist_neg = torch.minimum(dist_neg, dist_swap)\n    loss = torch.clamp_min(margin + dist_pos - dist_neg, 0)\n\n    # Apply reduction\n    if reduction == \"sum\":\n        return torch.sum(loss)\n    elif reduction == \"mean\":\n        return torch.mean(loss)\n    else:  # reduction == \"none\"\n        return loss\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.pixel_shuffle": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "pixel_shuffle_cpu",
      "file": "aten/src/ATen/native/PixelShuffle.cpp",
      "start_line": 23,
      "end_line": 45,
      "code": "Tensor pixel_shuffle_cpu(const Tensor& self, int64_t upscale_factor) {\n  check_pixel_shuffle_shapes(self, upscale_factor);\n\n  // Format: (B1, ..., Bn), C, H, W\n  std::vector<int64_t> output_sizes(self.sizes().begin(), self.sizes().end() - 3);\n  output_sizes.insert(output_sizes.end(),\n      {self.size(-3) / upscale_factor / upscale_factor,\n       self.size(-2) * upscale_factor,\n       self.size(-1) * upscale_factor});\n\n  auto output = at::empty({0}, self.options());\n  auto memory_format = self.suggest_memory_format();\n  output.resize_(output_sizes, memory_format);\n\n  if (output.numel() == 0) {\n    return output;\n  }\n\n  auto input = self.contiguous(memory_format);\n\n  pixel_shuffle_kernel(kCPU, output, input, upscale_factor);\n  return output;\n}\n"
    }
  },
  "torch.nn.functional.pixel_unshuffle": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "pixel_unshuffle_cpu",
      "file": "aten/src/ATen/native/PixelShuffle.cpp",
      "start_line": 47,
      "end_line": 73,
      "code": "Tensor pixel_unshuffle_cpu(const Tensor& self, int64_t downscale_factor) {\n  check_pixel_unshuffle_shapes(self, downscale_factor);\n\n  if (self.numel() == 0) {\n    return self.clone();\n  }\n\n  // Format: (B1, ..., Bn), C, H, W\n  std::vector<int64_t> output_sizes(self.sizes().begin(), self.sizes().end() - 3);\n  output_sizes.insert(output_sizes.end(),\n      {self.size(-3) * downscale_factor * downscale_factor,\n       self.size(-2) / downscale_factor,\n       self.size(-1) / downscale_factor});\n\n  auto output = at::empty({0}, self.options());\n  auto memory_format = self.suggest_memory_format();\n  output.resize_(output_sizes, memory_format);\n\n  if (output.numel() == 0) {\n    return output;\n  }\n\n  auto input = self.contiguous(memory_format);\n\n  pixel_unshuffle_kernel(kCPU, output, input, downscale_factor);\n  return output;\n}\n"
    }
  },
  "torch.nn.functional.pad": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 5015,
      "end_line": 5096,
      "code": "def pad(\n    input: Tensor,\n    pad: List[int],\n    mode: str = \"constant\",\n    value: Optional[float] = None,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            torch.nn.functional.pad, (input,), input, pad, mode=mode, value=value\n        )\n    if not torch.jit.is_scripting():\n        if torch.are_deterministic_algorithms_enabled() and (\n            input.is_cuda or input.is_xpu\n        ):\n            if mode == \"replicate\":\n                # Use slow decomp whose backward will be in terms of index_put.\n                # importlib is required because the import cannot be top level\n                # (cycle) and cannot be nested (TS doesn't support)\n                return importlib.import_module(\n                    \"torch._decomp.decompositions\"\n                )._replication_pad(input, pad)\n    return torch._C._nn.pad(input, pad, mode, value)\n"
    },
    "cpp": {
      "function": "pad_symint",
      "file": "aten/src/ATen/native/PadNd.cpp",
      "start_line": 231,
      "end_line": 246,
      "code": "Tensor pad_symint(const Tensor &self, c10::SymIntArrayRef pad, c10::string_view mode, std::optional<double> value) {\n  const auto mode_enum = [&] {\n    if (mode == \"reflect\") {\n      return at::padding_mode::reflect;\n    } else if (mode == \"constant\") {\n      return at::padding_mode::constant;\n    } else if (mode == \"replicate\") {\n      return at::padding_mode::replicate;\n    } else if (mode == \"circular\") {\n      return at::padding_mode::circular;\n    }\n    C10_THROW_ERROR(NotImplementedError,\n                    c10::str(\"Unrecognised padding mode \", mode));\n  }();\n  return at::native::_pad_enum_symint(self, pad, static_cast<int64_t>(mode_enum), value);\n}\n"
    }
  },
  "torch.nn.functional.interpolate": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 4340,
      "end_line": 4615,
      "code": "def interpolate(  # noqa: F811\n    input: Tensor,\n    size: Optional[int] = None,\n    scale_factor: Optional[List[float]] = None,\n    mode: str = \"nearest\",\n    align_corners: Optional[bool] = None,\n    recompute_scale_factor: Optional[bool] = None,\n    antialias: bool = False,\n) -> Tensor:  # noqa: B950\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            interpolate,\n            (input,),\n            input,\n            size=size,\n            scale_factor=scale_factor,\n            mode=mode,\n            align_corners=align_corners,\n            recompute_scale_factor=recompute_scale_factor,\n            antialias=antialias,\n        )\n\n    if mode in (\"nearest\", \"area\", \"nearest-exact\"):\n        if align_corners is not None:\n            raise ValueError(\n                \"align_corners option can only be set with the \"\n                \"interpolating modes: linear | bilinear | bicubic | trilinear\"\n            )\n    else:\n        if align_corners is None:\n            align_corners = False\n\n    dim = input.dim() - 2  # Number of spatial dimensions.\n\n    # Process size and scale_factor.  Validate that exactly one is set.\n    # Validate its length if it is a list, or expand it if it is a scalar.\n    # After this block, exactly one of output_size and scale_factors will\n    # be non-None, and it will be a list (or tuple).\n    if size is not None and scale_factor is not None:\n        raise ValueError(\"only one of size or scale_factor should be defined\")\n    elif size is not None:\n        assert scale_factor is None\n        scale_factors = None\n        if isinstance(size, (list, tuple)):\n            if len(size) != dim:\n                raise ValueError(\n                    \"Input and output must have the same number of spatial dimensions, but got \"\n                    f\"input with spatial dimensions of {list(input.shape[2:])} and output size of {size}. \"\n                    \"Please provide input tensor in (N, C, d1, d2, ...,dK) format and \"\n                    \"output size in (o1, o2, ...,oK) format.\"\n                )\n            if not torch.jit.is_scripting():\n                if not all(_is_integer(x) for x in size):\n                    raise TypeError(\n                        \"expected size to be one of int or Tuple[int] or Tuple[int, int] or \"\n                        f\"Tuple[int, int, int], but got size with types {[type(x) for x in size]}\"\n                    )\n            output_size = size\n        else:\n            output_size = [size for _ in range(dim)]\n    elif scale_factor is not None:\n        assert size is None\n        output_size = None\n        if isinstance(scale_factor, (list, tuple)):\n            if len(scale_factor) != dim:\n                raise ValueError(\n                    \"Input and scale_factor must have the same number of spatial dimensions, but \"\n                    f\"got input with spatial dimensions of {list(input.shape[2:])} and \"\n                    f\"scale_factor of shape {scale_factor}. \"\n                    \"Please provide input tensor in (N, C, d1, d2, ...,dK) format and \"\n                    \"scale_factor in (s1, s2, ...,sK) format.\"\n                )\n            scale_factors = scale_factor\n        else:\n            scale_factors = [scale_factor for _ in range(dim)]\n    else:\n        raise ValueError(\"either size or scale_factor should be defined\")\n\n    if (\n        recompute_scale_factor is not None\n        and recompute_scale_factor\n        and size is not None\n    ):\n        raise ValueError(\n            \"recompute_scale_factor is not meaningful with an explicit size.\"\n        )\n\n    # \"area\" mode always requires an explicit size rather than scale factor.\n    # Re-use the recompute_scale_factor code path.\n    if mode == \"area\" and output_size is None:\n        recompute_scale_factor = True\n\n    if recompute_scale_factor is not None and recompute_scale_factor:\n        # We compute output_size here, then un-set scale_factors.\n        # The C++ code will recompute it based on the (integer) output size.\n        assert scale_factors is not None\n        if not torch.jit.is_scripting() and torch._C._get_tracing_state():\n            # make scale_factor a tensor in tracing so constant doesn't get baked in\n            output_size = [\n                (\n                    torch.floor(\n                        (\n                            input.size(i + 2).float()\n                            * torch.tensor(scale_factors[i], dtype=torch.float32)\n                        ).float()\n                    )\n                )\n                for i in range(dim)\n            ]\n        elif torch.jit.is_scripting():\n            output_size = [\n                int(math.floor(float(input.size(i + 2)) * scale_factors[i]))\n                for i in range(dim)\n            ]\n        else:\n            output_size = [\n                _sym_int(input.size(i + 2) * scale_factors[i]) for i in range(dim)\n            ]\n        scale_factors = None\n\n    if antialias and not (mode in (\"bilinear\", \"bicubic\") and input.ndim == 4):\n        raise ValueError(\n            \"Anti-alias option is restricted to bilinear and bicubic modes and requires a 4-D tensor as input\"\n        )\n\n    if input.dim() == 3 and mode == \"nearest\":\n        return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)\n    if input.dim() == 4 and mode == \"nearest\":\n        return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)\n    if input.dim() == 5 and mode == \"nearest\":\n        return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)\n\n    if input.dim() == 3 and mode == \"nearest-exact\":\n        return torch._C._nn._upsample_nearest_exact1d(input, output_size, scale_factors)\n    if input.dim() == 4 and mode == \"nearest-exact\":\n        return torch._C._nn._upsample_nearest_exact2d(input, output_size, scale_factors)\n    if input.dim() == 5 and mode == \"nearest-exact\":\n        return torch._C._nn._upsample_nearest_exact3d(input, output_size, scale_factors)\n\n    if input.dim() == 3 and mode == \"area\":\n        assert output_size is not None\n        return adaptive_avg_pool1d(input, output_size)\n    if input.dim() == 4 and mode == \"area\":\n        assert output_size is not None\n        return adaptive_avg_pool2d(input, output_size)\n    if input.dim() == 5 and mode == \"area\":\n        assert output_size is not None\n        return adaptive_avg_pool3d(input, output_size)\n\n    if input.dim() == 3 and mode == \"linear\":\n        assert align_corners is not None\n        return torch._C._nn.upsample_linear1d(\n            input, output_size, align_corners, scale_factors\n        )\n    if input.dim() == 4 and mode == \"bilinear\":\n        assert align_corners is not None\n        if antialias:\n            return torch._C._nn._upsample_bilinear2d_aa(\n                input, output_size, align_corners, scale_factors\n            )\n        # Two levels are necessary to prevent TorchScript from touching\n        # are_deterministic_algorithms_enabled.\n        if not torch.jit.is_scripting():\n            if torch.are_deterministic_algorithms_enabled() and (\n                input.is_cuda or input.is_xpu\n            ):\n                # Use slow decomp whose backward will be in terms of index_put\n                # importlib is required because the import cannot be top level\n                # (cycle) and cannot be nested (TS doesn't support)\n                return importlib.import_module(\n                    \"torch._decomp.decompositions\"\n                )._upsample_linear_vec(input, output_size, align_corners, scale_factors)\n        return torch._C._nn.upsample_bilinear2d(\n            input, output_size, align_corners, scale_factors\n        )\n    if input.dim() == 5 and mode == \"trilinear\":\n        assert align_corners is not None\n        return torch._C._nn.upsample_trilinear3d(\n            input, output_size, align_corners, scale_factors\n        )\n    if input.dim() == 4 and mode == \"bicubic\":\n        assert align_corners is not None\n        if antialias:\n            return torch._C._nn._upsample_bicubic2d_aa(\n                input, output_size, align_corners, scale_factors\n            )\n        return torch._C._nn.upsample_bicubic2d(\n            input, output_size, align_corners, scale_factors\n        )\n\n    if input.dim() == 3 and mode == \"bilinear\":\n        raise NotImplementedError(\"Got 3D input, but bilinear mode needs 4D input\")\n    if input.dim() == 3 and mode == \"trilinear\":\n        raise NotImplementedError(\"Got 3D input, but trilinear mode needs 5D input\")\n    if input.dim() == 4 and mode == \"linear\":\n        raise NotImplementedError(\"Got 4D input, but linear mode needs 3D input\")\n    if input.dim() == 4 and mode == \"trilinear\":\n        raise NotImplementedError(\"Got 4D input, but trilinear mode needs 5D input\")\n    if input.dim() == 5 and mode == \"linear\":\n        raise NotImplementedError(\"Got 5D input, but linear mode needs 3D input\")\n    if input.dim() == 5 and mode == \"bilinear\":\n        raise NotImplementedError(\"Got 5D input, but bilinear mode needs 4D input\")\n\n    raise NotImplementedError(\n        \"Input Error: Only 3D, 4D and 5D input Tensors supported\"\n        f\" (got {input.dim()}D) for the modes: nearest | linear | bilinear | bicubic | trilinear | area | nearest-exact\"\n        f\" (got {mode})\"\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.upsample": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 4199,
      "end_line": 4269,
      "code": "def upsample(  # noqa: F811\n    input,\n    size=None,\n    scale_factor=None,\n    mode=\"nearest\",\n    align_corners=None,\n):\n    warnings.warn(\n        \"`nn.functional.upsample` is deprecated. \"\n        \"Use `nn.functional.interpolate` instead.\",\n        stacklevel=2,\n    )\n    return interpolate(input, size, scale_factor, mode, align_corners)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.upsample_nearest": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 4640,
      "end_line": 4665,
      "code": "def upsample_nearest(input, size=None, scale_factor=None):  # noqa: F811\n    # DeprecationWarning is ignored by default\n    warnings.warn(\n        \"`nn.functional.upsample_nearest` is deprecated. \"\n        \"Use `nn.functional.interpolate` instead.\",\n        stacklevel=2,\n    )\n    return interpolate(input, size, scale_factor, mode=\"nearest\")\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.upsample_bilinear": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 4708,
      "end_line": 4733,
      "code": "def upsample_bilinear(input, size=None, scale_factor=None):  # noqa: F811\n    # DeprecationWarning is ignored by default\n    warnings.warn(\n        \"`nn.functional.upsample_bilinear` is deprecated. \"\n        \"Use `nn.functional.interpolate` instead.\",\n        stacklevel=2,\n    )\n    return interpolate(input, size, scale_factor, mode=\"bilinear\", align_corners=True)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.grid_sample": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 4754,
      "end_line": 4910,
      "code": "def grid_sample(\n    input: Tensor,\n    grid: Tensor,\n    mode: str = \"bilinear\",\n    padding_mode: str = \"zeros\",\n    align_corners: Optional[bool] = None,\n) -> Tensor:\n    if has_torch_function_variadic(input, grid):\n        return handle_torch_function(\n            grid_sample,\n            (input, grid),\n            input,\n            grid,\n            mode=mode,\n            padding_mode=padding_mode,\n            align_corners=align_corners,\n        )\n    if mode != \"bilinear\" and mode != \"nearest\" and mode != \"bicubic\":\n        raise ValueError(\n            f\"nn.functional.grid_sample(): expected mode to be 'bilinear', 'nearest' or 'bicubic', but got: '{mode}'\"\n        )\n    if (\n        padding_mode != \"zeros\"\n        and padding_mode != \"border\"\n        and padding_mode != \"reflection\"\n    ):\n        raise ValueError(\n            \"nn.functional.grid_sample(): expected padding_mode \"\n            \"to be 'zeros', 'border', or 'reflection', \"\n            f\"but got: '{padding_mode}'\"\n        )\n\n    if mode == \"bilinear\":\n        mode_enum = 0\n    elif mode == \"nearest\":\n        mode_enum = 1\n    else:  # mode == 'bicubic'\n        mode_enum = 2\n\n    if padding_mode == \"zeros\":\n        padding_mode_enum = 0\n    elif padding_mode == \"border\":\n        padding_mode_enum = 1\n    else:  # padding_mode == 'reflection'\n        padding_mode_enum = 2\n\n    if align_corners is None:\n        warnings.warn(\n            \"Default grid_sample and affine_grid behavior has changed \"\n            \"to align_corners=False since 1.3.0. Please specify \"\n            \"align_corners=True if the old behavior is desired. \"\n            \"See the documentation of grid_sample for details.\"\n        )\n        align_corners = False\n\n    return torch.grid_sampler(input, grid, mode_enum, padding_mode_enum, align_corners)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.functional.affine_grid": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\functional.py",
      "start_line": 4913,
      "end_line": 5012,
      "code": "def affine_grid(\n    theta: Tensor,\n    size: List[int],\n    align_corners: Optional[bool] = None,\n) -> Tensor:\n    if has_torch_function_unary(theta):\n        return handle_torch_function(\n            affine_grid, (theta,), theta, size, align_corners=align_corners\n        )\n    if align_corners is None:\n        warnings.warn(\n            \"Default grid_sample and affine_grid behavior has changed \"\n            \"to align_corners=False since 1.3.0. Please specify \"\n            \"align_corners=True if the old behavior is desired. \"\n            \"See the documentation of grid_sample for details.\"\n        )\n        align_corners = False\n\n    # enforce floating point dtype on theta\n    if not theta.is_floating_point():\n        raise ValueError(\n            f\"Expected theta to have floating point type, but got {theta.dtype}\"\n        )\n    # check that shapes and sizes match\n    if len(size) == 4:\n        if theta.dim() != 3 or theta.shape[-2] != 2 or theta.shape[-1] != 3:\n            raise ValueError(\n                f\"Expected a batch of 2D affine matrices of shape Nx2x3 for size {size}. Got {theta.shape}.\"\n            )\n        spatial_size = size[-2:]  # spatial dimension sizes\n    elif len(size) == 5:\n        if theta.dim() != 3 or theta.shape[-2] != 3 or theta.shape[-1] != 4:\n            raise ValueError(\n                f\"Expected a batch of 3D affine matrices of shape Nx3x4 for size {size}. Got {theta.shape}.\"\n            )\n        spatial_size = size[-3:]  # spatial dimension sizes\n    else:\n        raise NotImplementedError(\n            \"affine_grid only supports 4D and 5D sizes, \"\n            \"for 2D and 3D affine transforms, respectively. \"\n            f\"Got size {size}.\"\n        )\n    # check for empty span\n    if align_corners and min(spatial_size) == 1:\n        warnings.warn(\n            \"Since version 1.3.0, affine_grid behavior has changed \"\n            \"for unit-size grids when align_corners=True. \"\n            \"This is not an intended use case of affine_grid. \"\n            \"See the documentation of affine_grid for details.\"\n        )\n    elif min(size) <= 0:\n        raise ValueError(f\"Expected non-zero, positive output size. Got {size}\")\n\n    return torch.affine_grid_generator(theta, size, align_corners)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.is_tensor": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\__init__.py",
      "start_line": 1004,
      "end_line": 1021,
      "code": "def is_tensor(obj: _Any, /) -> _TypeGuard[\"torch.Tensor\"]:\n    return isinstance(obj, torch.Tensor)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.is_storage": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\__init__.py",
      "start_line": 1024,
      "end_line": 1030,
      "code": "def is_storage(obj: _Any, /) -> _TypeGuard[_Union[\"TypedStorage\", \"UntypedStorage\"]]:\n    return type(obj) in _storage_classes\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.is_complex": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.is_floating_point": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.is_nonzero": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.set_default_dtype": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\__init__.py",
      "start_line": 1147,
      "end_line": 1197,
      "code": "def set_default_dtype(d: \"torch.dtype\", /) -> None:\n    _C._set_default_dtype(d)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.get_default_dtype": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.set_default_tensor_type": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\__init__.py",
      "start_line": 1116,
      "end_line": 1144,
      "code": "def set_default_tensor_type(t: _Union[_Type[\"torch.Tensor\"], str], /) -> None:\n    if isinstance(t, str):\n        t = _import_dotted_name(t)\n    _C._set_default_tensor_type(t)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.numel": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "_has_same_storage_numel",
      "file": "aten/src/ATen/native/AutogradComposite.cpp",
      "start_line": 90,
      "end_line": 92,
      "code": "bool _has_same_storage_numel(const at::Tensor& base, const at::Tensor& other) {\n  return base.storage().sym_nbytes() / base.itemsize() == other.storage().sym_nbytes() / other.itemsize();\n}\n"
    }
  },
  "torch.set_printoptions": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_tensor_str.py",
      "start_line": 25,
      "end_line": 95,
      "code": "def set_printoptions(\n    precision=None,\n    threshold=None,\n    edgeitems=None,\n    linewidth=None,\n    profile=None,\n    sci_mode=None,\n):\n    if profile is not None:\n        if profile == \"default\":\n            PRINT_OPTS.precision = 4\n            PRINT_OPTS.threshold = 1000\n            PRINT_OPTS.edgeitems = 3\n            PRINT_OPTS.linewidth = 80\n        elif profile == \"short\":\n            PRINT_OPTS.precision = 2\n            PRINT_OPTS.threshold = 1000\n            PRINT_OPTS.edgeitems = 2\n            PRINT_OPTS.linewidth = 80\n        elif profile == \"full\":\n            PRINT_OPTS.precision = 4\n            PRINT_OPTS.threshold = inf\n            PRINT_OPTS.edgeitems = 3\n            PRINT_OPTS.linewidth = 80\n\n    if precision is not None:\n        PRINT_OPTS.precision = precision\n    if threshold is not None:\n        PRINT_OPTS.threshold = threshold\n    if edgeitems is not None:\n        PRINT_OPTS.edgeitems = edgeitems\n    if linewidth is not None:\n        PRINT_OPTS.linewidth = linewidth\n    PRINT_OPTS.sci_mode = sci_mode\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.set_flush_denormal": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.rand": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "rand",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 868,
      "end_line": 874,
      "code": "Tensor rand(IntArrayRef size,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  return native::rand(size, static_cast<std::optional<Generator>>(std::nullopt), dtype, layout, device, pin_memory);\n}\n"
    }
  },
  "torch.rand_like": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "rand_like",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 897,
      "end_line": 909,
      "code": "Tensor rand_like(\n    const Tensor& self,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory,\n    std::optional<c10::MemoryFormat> optional_memory_format) {\n  // See [Note: hacky wrapper removal for TensorOptions]\n  TensorOptions options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n\n  auto result = at::empty_like(self, options, optional_memory_format);\n  return result.uniform_(0, 1, std::nullopt);\n}\n"
    }
  },
  "torch.randn": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "randn",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1017,
      "end_line": 1023,
      "code": "Tensor randn(IntArrayRef size,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  return native::randn(size, static_cast<std::optional<Generator>>(std::nullopt), dtype, layout, device, pin_memory);\n}\n"
    }
  },
  "torch.randn_like": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "randn_like",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1065,
      "end_line": 1077,
      "code": "Tensor randn_like(\n    const Tensor& self,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory,\n    std::optional<c10::MemoryFormat> optional_memory_format) {\n  // See [Note: hacky wrapper removal for TensorOptions]\n  TensorOptions options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n\n  auto result = at::empty_like(self, options, optional_memory_format);\n  return result.normal_(0, 1, std::nullopt);\n}\n"
    }
  },
  "torch.randint": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "randint",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 913,
      "end_line": 919,
      "code": "Tensor randint(int64_t high, IntArrayRef size,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  return native::randint(high, size, std::nullopt /* generator*/, dtype, layout, device, pin_memory);\n}\n"
    }
  },
  "torch.randint_like": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "randint_like",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 984,
      "end_line": 997,
      "code": "Tensor randint_like(\n    const Tensor& self,\n    int64_t high,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory,\n    std::optional<c10::MemoryFormat> optional_memory_format) {\n  // See [Note: hacky wrapper removal for TensorOptions]\n  TensorOptions options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n\n  auto result = at::empty_like(self, options, optional_memory_format);\n  return result.random_(0, high, std::nullopt);\n}\n"
    }
  },
  "torch.randperm": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "randperm",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1107,
      "end_line": 1113,
      "code": "Tensor randperm(int64_t n,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  return native::randperm(n, std::nullopt, dtype, layout, device, pin_memory);\n}\n"
    }
  },
  "torch.empty": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "empty_names",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 257,
      "end_line": 278,
      "code": "Tensor empty_names(\n    IntArrayRef size,\n    std::optional<DimnameList> names,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory,\n    std::optional<MemoryFormat> optional_memory_format) {\n  // See [Note: hacky wrapper removal for TensorOptions]\n  TensorOptions options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n\n  if (!names.has_value()) {\n    return at::empty(size, options, optional_memory_format);\n  }\n  TORCH_CHECK(options.layout() == Layout::Strided,\n      \"NYI: named tensors only support strided layout\");\n  TORCH_CHECK(options.device().is_cpu() || options.device().is_cuda() || options.device().is_xpu() || options.device().is_privateuseone(),\n      \"NYI: named tensors only support CPU, CUDA, XPU or \", c10::get_privateuse1_backend(), \" tensors.\");\n  auto result = at::empty(size, options, optional_memory_format);\n  internal_set_names_inplace(result, names);\n  return result;\n}\n"
    }
  },
  "torch.tensor": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.sparse_coo_tensor": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "sparse_coo_tensor",
      "file": "aten/src/ATen/native/sparse/SparseTensor.cpp",
      "start_line": 262,
      "end_line": 271,
      "code": "Tensor sparse_coo_tensor(IntArrayRef size,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  // See [Note: hacky wrapper removal for TensorOptions]\n  TensorOptions options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n\n  return at::_sparse_coo_tensor_with_dims(size.size(), 0, size, options.layout(at::kSparse));\n}\n"
    }
  },
  "torch.as_tensor": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.as_strided": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "as_strided_tensorimpl",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 1175,
      "end_line": 1182,
      "code": "Tensor as_strided_tensorimpl(const Tensor& self, IntArrayRef size, IntArrayRef stride, std::optional<int64_t> storage_offset_) {\n  TORCH_INTERNAL_ASSERT(!self.is_mps(), \"as_strided_tensorimpl does not work with MPS; call self.as_strided(...) instead\");\n  auto storage_offset = storage_offset_.value_or(self.storage_offset());\n  auto result = at::detail::make_tensor<TensorImpl>(\n      c10::TensorImpl::VIEW, Storage(self.storage()), self.key_set(), self.dtype());\n  setStrided(result, size, stride, storage_offset);\n  return result;\n}\n"
    }
  },
  "torch.from_numpy": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.zeros": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "zeros_symint",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1306,
      "end_line": 1319,
      "code": "Tensor zeros_symint(SymIntArrayRef size,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  Layout layout_ = layout.value_or(Layout::Strided);\n  if (at::sparse_csr::is_sparse_compressed(layout_)) {\n    return zeros_sparse_compressed_symint(size, dtype, layout_, device, pin_memory);\n  }\n  // See [Note: hacky wrapper removal for TensorOptions]\n  TensorOptions options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n  auto result = at::empty_symint(size, options);\n  return result.zero_();\n}\n"
    }
  },
  "torch.zeros_like": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "zeros_like",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1365,
      "end_line": 1412,
      "code": "Tensor zeros_like(\n    const Tensor& self,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory,\n    std::optional<c10::MemoryFormat> optional_memory_format) {\n  // See [Note: hacky wrapper removal for TensorOptions]\n  auto other_options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n  // Prefer values passed in explicitly, but default to value from self.\n  auto options = self.options().merge_in(other_options);\n\n  if (options.layout() == kSparse) {\n    TORCH_CHECK(\n        !(optional_memory_format.has_value()),\n        \"memory format option is only supported by strided tensors\");\n    auto res = at::empty({0}, self.options().merge_in(options)); // to be resized\n\n    if (self.is_sparse()) {\n      res.sparse_resize_and_clear_(\n          self.sizes(), self.sparse_dim(), self.dense_dim());\n    } else if (at::sparse_csr::is_sparse_compressed(self)) {\n      res.sparse_resize_and_clear_(\n          self.sizes(), self.sizes().size() - self.dense_dim(), self.dense_dim());\n    } else {\n      res.sparse_resize_and_clear_(self.sizes(), self.sizes().size(), 0);\n    }\n    res._coalesced_(true);\n\n    return res;\n  } else if (at::sparse_csr::is_sparse_compressed(options.layout())) {\n    int64_t nnz = 0;\n    int64_t dense_dim = (self.layout() == kStrided ? self.dim() - 2: self.dense_dim());\n    DimVector blocksize{};\n    if (self.layout() == kSparseBsr || self.layout() == kSparseBsc) {\n      blocksize.append(at::sparse_csr::getBlockSize(self));\n    }\n    ScalarType index_dtype = at::sparse_csr::getIndexDtype(self);\n    auto res = at::native::sparse_compressed_tensor_with_dims(\n      nnz, dense_dim, self.sizes(), blocksize, index_dtype,\n      typeMetaToScalarType(options.dtype()), options.layout(), options.device(), options.pinned_memory());\n    auto [compressed_indices, plain_indices] = at::sparse_csr::getCompressedPlainIndices(res);\n    compressed_indices.zero_();\n    return res;\n  }\n  auto result = at::empty_like(self, options, optional_memory_format);\n  return result.zero_();\n}\n"
    }
  },
  "torch.ones": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "ones",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 804,
      "end_line": 810,
      "code": "Tensor ones(IntArrayRef size,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  return native::full(size, /*fill_value=*/1., dtype, layout, device, pin_memory);\n}\n"
    }
  },
  "torch.ones_like": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "ones_like",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 816,
      "end_line": 825,
      "code": "Tensor ones_like(\n    const Tensor& self,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory,\n    std::optional<c10::MemoryFormat> optional_memory_format) {\n  auto result = at::empty_like(self, dtype, layout, device, pin_memory, optional_memory_format);\n  return result.fill_(1.);\n}\n"
    }
  },
  "torch.arange": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "arange",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 135,
      "end_line": 141,
      "code": "Tensor arange(const Scalar& end,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  return native::arange(/*start=*/0, end, dtype, layout, device, pin_memory);\n}\n"
    }
  },
  "torch.range": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "range",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1152,
      "end_line": 1165,
      "code": "Tensor range(\n    const Scalar& start,\n    const Scalar& end,\n    const Scalar& step,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  // See [Note: hacky wrapper removal for TensorOptions]\n  TensorOptions options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n\n  Tensor result = at::empty({0}, options);\n  return at::range_out(result, start, end, step);\n}\n"
    }
  },
  "torch.linspace": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "linspace",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 684,
      "end_line": 699,
      "code": "Tensor linspace(\n    const Scalar& start,\n    const Scalar& end,\n    int64_t steps,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  // See [Note: hacky wrapper removal for TensorOptions]\n  TensorOptions options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n\n  TORCH_CHECK(steps >= 0, \"number of steps must be non-negative\");\n  auto result_options = linspace_logspace_infer_options(start, end, options, \"torch.linspace()\");\n  Tensor result = at::empty({steps}, result_options);\n  return at::linspace_out(result, start, end, steps);\n}\n"
    }
  },
  "torch.logspace": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "logspace",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 742,
      "end_line": 758,
      "code": "Tensor logspace(\n    const Scalar& start,\n    const Scalar& end,\n    int64_t steps,\n    double base,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  // See [Note: hacky wrapper removal for TensorOptions]\n  TensorOptions options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n\n  TORCH_CHECK(steps >= 0, \"number of steps must be non-negative\");\n  auto result_options = linspace_logspace_infer_options(start, end, options, \"torch.logspace()\");\n  Tensor result = at::empty({steps}, result_options);\n  return at::logspace_out(result, start, end, steps, base);\n}\n"
    }
  },
  "torch.eye": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "eye",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 532,
      "end_line": 539,
      "code": "Tensor eye(int64_t n,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  // the default value of `m` equals to `n`\n  return at::eye(n, n, dtype, layout, device, pin_memory);\n}\n"
    }
  },
  "torch.empty_like": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "empty_like",
      "file": "<empty>",
      "start_line": -1,
      "end_line": -1,
      "code": ""
    }
  },
  "torch.empty_strided": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "empty_strided_cpu",
      "file": "aten/src/ATen/EmptyTensor.cpp",
      "start_line": 289,
      "end_line": 295,
      "code": "TensorBase empty_strided_cpu(IntArrayRef size, IntArrayRef stride,\n                             ScalarType dtype, bool pin_memory) {\n  auto allocator = at::detail::GetCPUAllocatorMaybePinned(pin_memory);\n  constexpr c10::DispatchKeySet cpu_ks(c10::DispatchKey::CPU);\n  return at::detail::empty_strided_generic(\n      size, stride, allocator, cpu_ks, dtype);\n}\n"
    }
  },
  "torch.full": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "full",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 608,
      "end_line": 621,
      "code": "Tensor full(IntArrayRef size, const Scalar& fill_value,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  // See [Note: hacky wrapper removal for TensorOptions]\n  TensorOptions options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n\n  TORCH_CHECK(options.layout() != kSparse,\n    \"full(...) is not implemented for sparse layout\");\n\n  auto result = at::empty(size, infer_full_options(fill_value, options));\n  return result.fill_(fill_value);\n}\n"
    }
  },
  "torch.full_like": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "full_like",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 631,
      "end_line": 644,
      "code": "Tensor full_like(\n    const Tensor& self,\n    const Scalar& fill_value,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory,\n    std::optional<c10::MemoryFormat> optional_memory_format) {\n  // See [Note: hacky wrapper removal for TensorOptions]\n  TensorOptions options = TensorOptions().dtype(dtype).layout(layout).device(device).pinned_memory(pin_memory);\n\n  auto result = at::empty_like(self, options, optional_memory_format);\n  return result.fill_(fill_value);\n}\n"
    }
  },
  "torch.quantize_per_tensor": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "quantize_per_tensor",
      "file": "aten/src/ATen/native/quantized/QTensor.cpp",
      "start_line": 57,
      "end_line": 64,
      "code": "Tensor quantize_per_tensor(\n    const Tensor& self,\n    double scale,\n    int64_t zero_point,\n    ScalarType dtype) {\n  auto quantizer = make_per_tensor_affine_quantizer(scale, zero_point, dtype);\n  return quantizer->quantize(self);\n}\n"
    }
  },
  "torch.quantize_per_channel": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "quantize_per_channel",
      "file": "aten/src/ATen/native/quantized/QTensor.cpp",
      "start_line": 91,
      "end_line": 99,
      "code": "Tensor quantize_per_channel(\n    const Tensor& self,\n    const Tensor& scales,\n    const Tensor& zero_points,\n    int64_t axis,\n    ScalarType dtype) {\n  auto quantizer = make_per_channel_affine_quantizer(scales, zero_points, axis, dtype);\n  return quantizer->quantize(self);\n}\n"
    }
  },
  "torch.dequantize": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "dequantize_cpu_or_cuda",
      "file": "aten/src/ATen/native/quantized/QTensor.cpp",
      "start_line": 101,
      "end_line": 103,
      "code": "Tensor dequantize_cpu_or_cuda(const Tensor& self) {\n  return self.to(at::kFloat);\n}\n"
    }
  },
  "torch.complex": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "complex",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 218,
      "end_line": 224,
      "code": "Tensor complex(const Tensor& real, const Tensor& imag) {\n  complex_check_floating(real, imag);\n  c10::TensorOptions options = real.options();\n  options = options.dtype(toComplexType(real.scalar_type()));\n  Tensor result = at::empty(0, options);\n  return at::complex_out(result, real, imag);\n}\n"
    }
  },
  "torch.imag": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.polar": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "polar",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 238,
      "end_line": 244,
      "code": "Tensor polar(const Tensor& abs, const Tensor& angle) {\n  complex_check_floating(abs, angle);\n  c10::TensorOptions options = abs.options();\n  options = options.dtype(toComplexType(abs.scalar_type()));\n  Tensor result = at::empty(0, options);\n  return at::polar_out(result, abs, angle);\n}\n"
    }
  },
  "torch.angle": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "angle",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 568,
      "end_line": 576,
      "code": "Tensor angle(const Tensor& self) {\n  if (self.is_complex()) {\n    const auto float_type = c10::toRealValueType(self.scalar_type());\n    Tensor result = at::empty({0}, self.options().dtype(float_type));\n    return at::angle_out(result, self);\n  }\n\n  return unary_op_impl_float(self, angle_stub);\n}\n"
    }
  },
  "torch.heaviside": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "heaviside_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 1539,
      "end_line": 1543,
      "code": "TORCH_IMPL_FUNC(heaviside_out) (\n  const Tensor& self, const Tensor& other, const Tensor& result\n) {\n  heaviside_stub(device_type(), *this);\n}\n"
    }
  },
  "torch.cat": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "cat_sparse",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 854,
      "end_line": 860,
      "code": "Tensor cat_sparse(const ITensorListRef& tensors, int64_t dim) {\n  auto materialized = tensors.materialize();\n  auto maybe_outnames = namedinference::compute_cat_outnames(materialized);\n  auto result = cat_sparse_impl(materialized, at::legacy_cat_wrap_dim(dim, materialized));\n  namedinference::propagate_names_if_nonempty(result, maybe_outnames);\n  return result;\n}\n"
    }
  },
  "torch.chunk": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "chunk",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 937,
      "end_line": 957,
      "code": "std::vector<Tensor> chunk(const Tensor& self, int64_t chunks, int64_t dim) {\n  TORCH_CHECK(self.dim() > 0,\n           \"chunk expects at least a 1-dimensional tensor\");\n  TORCH_CHECK(chunks > 0,\n           \"chunk expects `chunks` to be greater than 0, got: \", chunks);\n\n  const auto dim_size = self.sym_size(dim);\n  auto split_size = (dim_size + chunks - 1) / chunks;\n\n  // We need to call split_with_sizes in the case where split_size and dimension size are 0, because\n  // a call to split would discard the number of chunks (because we can have an arbitrary number of\n  // 0-sized chunks adding up to 0).  So, call split_with_sizes with the correct number of chunks,\n  // eventually we will do this for all cases.\n  if (split_size == 0 && dim_size == 0) {\n    std::vector<c10::SymInt> split_sizes(chunks, split_size);\n    split_sizes[chunks - 1] = split_size - (split_size * chunks - dim_size);\n    return self.split_with_sizes_symint(split_sizes, dim);\n  } else {\n    return self.split_symint(std::move(split_size), dim);\n  }\n}\n"
    }
  },
  "torch.column_stack": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.dstack": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.gather": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "gather_out",
      "file": "aten/src/ATen/native/NamedTensor.cpp",
      "start_line": 338,
      "end_line": 340,
      "code": "Tensor& gather_out(const Tensor& self, Dimname dim, const Tensor& index, bool sparse_grad, Tensor& result) {\n  reportNYIDimnameOverload(\"gather\");\n}\n"
    }
  },
  "torch.hstack": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.index_select": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "index_select_cpu_",
      "file": "aten/src/ATen/native/TensorAdvancedIndexing.cpp",
      "start_line": 1463,
      "end_line": 1466,
      "code": "Tensor index_select_cpu_(const Tensor & self, int64_t dim, const Tensor & index) {\n  Tensor result = at::empty({0}, self.options());\n  return at::native::index_select_out_cpu_(self, dim, index, result);\n}\n"
    }
  },
  "torch.masked_select": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "masked_select_cpu",
      "file": "aten/src/ATen/native/TensorAdvancedIndexing.cpp",
      "start_line": 2130,
      "end_line": 2133,
      "code": "Tensor masked_select_cpu(const Tensor & self, const Tensor & mask) {\n  Tensor result = at::empty({0}, self.options());\n  return at::native::masked_select_out_cpu(self, mask, result);\n}\n"
    }
  },
  "torch.movedim": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.moveaxis": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.narrow": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "narrow_symint",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 1389,
      "end_line": 1403,
      "code": "Tensor narrow_symint(const Tensor& self, int64_t dim, SymInt start, SymInt length) {\n  TORCH_CHECK(self.dim() > 0, \"narrow() cannot be applied to a 0-dim tensor.\");\n  TORCH_SYM_CHECK(length.sym_ge(0), \"narrow(): length must be non-negative.\");\n  auto cur_size = self.sym_size(dim);\n  TORCH_CHECK_INDEX(\n    ((-cur_size).sym_le(start).sym_and(start.sym_le(cur_size))).expect_true(__FILE__, __LINE__),\n    \"start out of range (expected to be in range of [\", -cur_size, \", \", cur_size, \"], but got \", start, \")\"\n  )\n  if (start < 0) {\n    start = start + cur_size;\n  }\n  TORCH_SYM_CHECK(start.sym_le(cur_size - length),\n           \"start (\", start, \") + length (\", length, \") exceeds dimension size (\", cur_size, \").\");\n  return at::slice_symint(self, dim, start, start + length, 1);\n}\n"
    }
  },
  "torch.nonzero": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "nonzero_cpu",
      "file": "aten/src/ATen/native/TensorAdvancedIndexing.cpp",
      "start_line": 2447,
      "end_line": 2451,
      "code": "Tensor nonzero_cpu(const Tensor& self) {\n  auto result = at::empty({0}, self.options().dtype(kLong));\n  nonzero_out_cpu(self, result);\n  return result;\n}\n"
    }
  },
  "torch.reshape": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "reshape_symint",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 1620,
      "end_line": 1662,
      "code": "Tensor reshape_symint(const Tensor& self, c10::SymIntArrayRef proposed_shape) {\n  if (self.is_sparse()) {\n    TORCH_CHECK(false, \"reshape is not implemented for sparse tensors\");\n  }\n\n  if (self.is_contiguous() && !self.is_mkldnn()) {\n    return self.view_symint(proposed_shape);\n  }\n\n  c10::SymDimVector shape = infer_size_dv(proposed_shape, self.sym_numel());\n\n  if (self.is_mkldnn()) {\n    return at::_mkldnn_reshape(self, C10_AS_INTARRAYREF_SLOW(shape));\n  }\n\n  // `computeStride` returns the proper strides to use if this\n  // `reshape` can be just a view.\n  auto stride = at::detail::computeStride(self.sym_sizes(), self.sym_strides(), shape);\n\n  // NB: Even though we have viewable geometry and the target strides here,\n  //     we do not just call `as_strided` on `self` because the backward\n  //     for `as_strided` is not as efficient as that of `view` (since the\n  //     former is meant to handle general cases).\n  //\n  //     Similarly we don't call `view` because it duplicates some of the work\n  //     we've already done, and instead call our internal/private operator\n  //     `_reshape_alias` that essentially does the same thing as `view` and\n  //     `as_strided` without any of the extra overhead.\n  if (stride.has_value()) {\n    // Temporary check to revert to the old behavior/view in cases where the\n    // device is not supported (e.g. for XLA the operation is not supported\n    // so we use `view` instead).\n    //\n    // We need to do the checks here instead of in `native_functions.yaml`\n    // to preserve backwards compatibility.\n    if (!self.is_xla() && !self.is_lazy() && !self.is_ipu() && !at::isTensorSubclassLike(self)) {\n      return self._reshape_alias_symint(shape, stride.value());\n    } else {\n      return self.view_symint(shape);\n    }\n  }\n  return at::_unsafe_view_symint(self.clone(at::MemoryFormat::Contiguous), shape);\n}\n"
    }
  },
  "torch.row_stack": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.vstack": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.scatter": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "slice_scatter",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 4002,
      "end_line": 4009,
      "code": "at::Tensor slice_scatter(const at::Tensor& self, const at::Tensor& src, int64_t dim, std::optional<int64_t> start, std::optional<int64_t> end, int64_t step) {\n    // See Note [*_scatter ops preserve strides]\n    auto output = clone_preserve_strides(self);\n    auto slice = output.slice(dim, start, end, step);\n    TORCH_CHECK(slice.sizes() == src.sizes(), \"expected src to have a size equal to the slice of self. src size = \", src.sizes(), \", slice size = \", slice.sizes());\n    slice.copy_(src);\n    return output;\n}\n"
    }
  },
  "torch.scatter_add": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "scatter_add",
      "file": "aten/src/ATen/native/NamedTensor.cpp",
      "start_line": 374,
      "end_line": 376,
      "code": "Tensor scatter_add(const Tensor& self, Dimname dim, const Tensor& index, const Tensor& source) {\n  reportNYIDimnameOverload(\"scatter_add\");\n}\n"
    }
  },
  "torch.split": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 155,
      "end_line": 207,
      "code": "def split(\n    tensor: Tensor,\n    split_size_or_sections: Union[int, List[int]],\n    dim: int = 0,\n) -> Tuple[Tensor, ...]:\n    if has_torch_function_unary(tensor):\n        return handle_torch_function(\n            split, (tensor,), tensor, split_size_or_sections, dim=dim\n        )\n    # Overwriting reason:\n    # This dispatches to two ATen functions depending on the type of\n    # split_size_or_sections. The branching code is in _tensor.py, which we\n    # call here.\n    return tensor.split(split_size_or_sections, dim)\n"
    },
    "cpp": {
      "function": "tensor_split_sections_symint",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 959,
      "end_line": 977,
      "code": "std::vector<Tensor> tensor_split_sections_symint(const Tensor& self, c10::SymInt sym_sections, int64_t dim) {\n  TORCH_CHECK(self.dim() > 0, \"tensor_split expected at least a 1-dimensional tensor, but got a tensor with \", self.dim(),\" dims\");\n  int64_t dim_ = maybe_wrap_dim(dim, self.dim());\n  // NB: intentional, sections specifies number of output tensors, which\n  // cannot be polymorphic\n  int64_t sections = sym_sections.guard_int(__FILE__, __LINE__);\n  TORCH_CHECK(sections > 0, \"number of sections must be larger than 0, got \", sections);\n  const auto dim_size = self.sym_size(dim_);\n  std::vector<Tensor> splits(sections);\n  auto min_split_size = dim_size / sections;\n  auto num_splits_one_extra = dim_size % sections;\n  c10::SymInt start_idx = 0;\n  for (const auto split_idx : c10::irange(sections)) {\n    auto split_size = (num_splits_one_extra > split_idx) ? (min_split_size + 1) : min_split_size;\n    splits[split_idx] = at::slice_symint(self, dim_, start_idx, start_idx + split_size);\n    start_idx += split_size;\n  }\n  return splits;\n}\n"
    }
  },
  "torch.squeeze": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "squeeze",
      "file": "aten/src/ATen/native/NamedTensor.cpp",
      "start_line": 392,
      "end_line": 394,
      "code": "Tensor squeeze(const Tensor& self, Dimname dim) {\n  return at::squeeze(self, dimname_to_position(self, dim));\n}\n"
    }
  },
  "torch.stack": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "stack",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 2759,
      "end_line": 2772,
      "code": "Tensor stack(TensorList tensors, int64_t dim) {\n  TORCH_CHECK(!tensors.empty(),\n           \"stack expects a non-empty TensorList\");\n  auto wrapped_dim = maybe_wrap_dim(dim, tensors[0].ndimension()+1);\n  if (wrapped_dim < tensors[0].ndimension() && !tensors[0].is_sparse()) {\n    check_stack_inputs(tensors, wrapped_dim);\n    auto result_sizes = tensors[0].sizes().vec();\n    result_sizes.insert(result_sizes.begin() + wrapped_dim, tensors.size());\n    auto out = at::cat(tensors, wrapped_dim);\n    return out.view(result_sizes); // one can always split a dimension with view\n  } else { //dim = tensors[0].ndimension() cannot be efficiently handled by view\n    return at::cat(get_stack_inputs(tensors, dim), dim);\n  }\n}\n"
    }
  },
  "torch.swapaxes": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.transpose": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "conv_transpose1d_symint",
      "file": "aten/src/ATen/native/Convolution.cpp",
      "start_line": 1116,
      "end_line": 1133,
      "code": "at::Tensor conv_transpose1d_symint(\n    const Tensor& input_, const Tensor& weight, const std::optional<Tensor>& bias_opt,\n    SymIntArrayRef stride, SymIntArrayRef padding, SymIntArrayRef output_padding, c10::SymInt groups, SymIntArrayRef dilation) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> bias_maybe_owned = at::borrow_from_optional_tensor(bias_opt);\n  const Tensor& bias = *bias_maybe_owned;\n\n  auto [input, is_batched] = batchify(input_, /*num_spatial_dims=*/ 1, \"conv_transpose1d\");\n  Tensor output;\n  if (at::isComplexType(input_.scalar_type())) {\n    output = complex_convolution(\n      input, weight, bias, stride, padding, dilation, true, output_padding, groups);\n  } else {\n    output = at::convolution_symint(\n      input, weight, bias, stride, padding, dilation, true, output_padding, groups);\n  }\n  return is_batched ? std::move(output) : output.squeeze(0);\n}\n"
    }
  },
  "torch.swapdims": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.t": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "t",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 3162,
      "end_line": 3165,
      "code": "Tensor t(const Tensor & self) {\n  check_t(self, \"t()\");\n  return self.transpose(0, self.dim() < 2 ? 0 : 1);\n}\n"
    }
  },
  "torch.take": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "take",
      "file": "aten/src/ATen/native/TensorAdvancedIndexing.cpp",
      "start_line": 861,
      "end_line": 865,
      "code": "Tensor take(const Tensor& self, const Tensor& index) {\n    auto out = at::empty(index.sizes(), self.options());\n    at::native::take_out(self, index, out);\n    return out;\n}\n"
    }
  },
  "torch.tensor_split": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "tensor_split_sections_symint",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 959,
      "end_line": 977,
      "code": "std::vector<Tensor> tensor_split_sections_symint(const Tensor& self, c10::SymInt sym_sections, int64_t dim) {\n  TORCH_CHECK(self.dim() > 0, \"tensor_split expected at least a 1-dimensional tensor, but got a tensor with \", self.dim(),\" dims\");\n  int64_t dim_ = maybe_wrap_dim(dim, self.dim());\n  // NB: intentional, sections specifies number of output tensors, which\n  // cannot be polymorphic\n  int64_t sections = sym_sections.guard_int(__FILE__, __LINE__);\n  TORCH_CHECK(sections > 0, \"number of sections must be larger than 0, got \", sections);\n  const auto dim_size = self.sym_size(dim_);\n  std::vector<Tensor> splits(sections);\n  auto min_split_size = dim_size / sections;\n  auto num_splits_one_extra = dim_size % sections;\n  c10::SymInt start_idx = 0;\n  for (const auto split_idx : c10::irange(sections)) {\n    auto split_size = (num_splits_one_extra > split_idx) ? (min_split_size + 1) : min_split_size;\n    splits[split_idx] = at::slice_symint(self, dim_, start_idx, start_idx + split_size);\n    start_idx += split_size;\n  }\n  return splits;\n}\n"
    }
  },
  "torch.tile": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "tile_symint",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 1552,
      "end_line": 1567,
      "code": "Tensor tile_symint(const Tensor& self, SymIntArrayRef reps){\n  // If self.size() > len(reps), reps is promoted to self.size() by pre-pending\n  // 1s to it to keep the same behaviour as `numpy.tile`.\n  // Thus for a tensor of shape (2, 3, 4, 5), a dims of (2, 2) is treated\n  // as (1, 1, 2, 2).\n  const int64_t size_diff = self.dim() - static_cast<int64_t>(reps.size());\n  if (size_diff > 0){\n    std::vector<c10::SymInt> new_reps(size_diff, 1);\n    for (const auto i : c10::irange(reps.size())) {\n      new_reps.emplace_back(reps[i]);\n    }\n    return self.repeat_symint(SymIntArrayRef(new_reps));\n  }\n  // `torch.tile` is equivalent to the already implemented `torch.Tensor.repeat`\n  return self.repeat_symint(reps);\n}\n"
    }
  },
  "torch.unbind": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "unbind",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 3580,
      "end_line": 3588,
      "code": "std::vector<Tensor> unbind(const Tensor &self, int64_t dim) {\n  dim = maybe_wrap_dim(dim, self.dim());\n  int64_t size = self.size(dim);\n  std::vector<Tensor> tensors(size);\n  for (const auto i : c10::irange(size)) {\n    tensors[i] = self.select(dim, i);\n  }\n  return tensors;\n}\n"
    }
  },
  "torch.unsqueeze": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "unsqueeze",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 3380,
      "end_line": 3384,
      "code": "Tensor unsqueeze(const Tensor& self, int64_t dim) {\n  dim = maybe_wrap_dim(dim, self.dim() + 1);\n  auto g = inferUnsqueezeGeometry_symint(self, dim);\n  return self.as_strided_symint(g.sizes, g.strides);\n}\n"
    }
  },
  "torch.where": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "where",
      "file": "aten/src/ATen/native/TensorCompare.cpp",
      "start_line": 547,
      "end_line": 553,
      "code": "Tensor where(const Tensor& condition, const Tensor& self, const Tensor& other) {\n  auto device = out_device(condition, self, other);\n  auto result_type = at::native::result_type(self, other);\n  Tensor ret = at::empty({0}, self.options().dtype(result_type).device(device));\n  at::native::where_self_out(condition, self, other, ret);\n  return ret;\n}\n"
    }
  },
  "torch.Generator": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "affine_grid_generator",
      "file": "aten/src/ATen/native/AffineGridGenerator.cpp",
      "start_line": 89,
      "end_line": 100,
      "code": "Tensor affine_grid_generator(const Tensor& theta, IntArrayRef size, bool align_corners) {\n  TORCH_CHECK(\n      size.size() == 4 || size.size() == 5,\n      \"AffineGridGenerator needs 4d (spatial) or 5d (volumetric) inputs.\");\n  if (size.size() == 4) {\n    return affine_grid_generator_4D(\n        theta, size[0], size[1], size[2], size[3], align_corners);\n  } else {\n    return affine_grid_generator_5D(\n        theta, size[0], size[1], size[2], size[3], size[4], align_corners);\n  }\n}\n"
    }
  },
  "torch.seed": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\random.py",
      "start_line": 63,
      "end_line": 85,
      "code": "def seed() -> int:\n    seed = default_generator.seed()\n    import torch.cuda\n\n    if not torch.cuda._is_in_bad_fork():\n        torch.cuda.manual_seed_all(seed)\n\n    import torch.mps\n\n    if not torch.mps._is_in_bad_fork():\n        torch.mps.manual_seed(seed)\n\n    import torch.xpu\n\n    if not torch.xpu._is_in_bad_fork():\n        torch.xpu.manual_seed_all(seed)\n\n    _seed_custom_device(seed)\n\n    return seed\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.manual_seed": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_compile.py",
      "start_line": 32,
      "end_line": 60,
      "code": "def manual_seed(seed) -> torch._C.Generator:\n    seed = int(seed)\n    import torch.cuda\n\n    if not torch.cuda._is_in_bad_fork():\n        torch.cuda.manual_seed_all(seed)\n\n    import torch.mps\n\n    if not torch.mps._is_in_bad_fork():\n        torch.mps.manual_seed(seed)\n\n    import torch.xpu\n\n    if not torch.xpu._is_in_bad_fork():\n        torch.xpu.manual_seed_all(seed)\n\n    _seed_custom_device(seed)\n\n    return default_generator.manual_seed(seed)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.initial_seed": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\random.py",
      "start_line": 113,
      "end_line": 119,
      "code": "def initial_seed() -> int:\n    return default_generator.initial_seed()\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.get_rng_state": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\random.py",
      "start_line": 22,
      "end_line": 29,
      "code": "def get_rng_state() -> torch.Tensor:\n    return default_generator.get_state()\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.set_rng_state": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\random.py",
      "start_line": 10,
      "end_line": 19,
      "code": "def set_rng_state(new_state: torch.Tensor) -> None:\n    default_generator.set_state(new_state)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.bernoulli": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "bernoulli",
      "file": "aten/src/ATen/native/Distributions.cpp",
      "start_line": 158,
      "end_line": 162,
      "code": "Tensor bernoulli(const Tensor& self, std::optional<Generator> gen) {\n  Tensor result = at::empty_like(self, LEGACY_CONTIGUOUS_MEMORY_FORMAT);\n  result.bernoulli_(self, std::move(gen));\n  return result;\n}\n"
    }
  },
  "torch.multinomial": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "multinomial",
      "file": "aten/src/ATen/native/Distributions.cpp",
      "start_line": 627,
      "end_line": 635,
      "code": "Tensor multinomial(\n    const Tensor& self,\n    int64_t n_sample,\n    bool with_replacement,\n    std::optional<Generator> gen) {\n  Tensor result = at::empty({0}, self.options().dtype(kLong));\n  native::multinomial_out(self, n_sample, with_replacement, std::move(gen), result);\n  return result;\n}\n"
    }
  },
  "torch.normal": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "log_normal_",
      "file": "aten/src/ATen/native/Distributions.cpp",
      "start_line": 191,
      "end_line": 193,
      "code": "Tensor& log_normal_(Tensor& self, double mean, double std, std::optional<Generator> gen) {\n  return at::native::templates::log_normal_impl_<LogNormalStub, Generator>(self, mean, std, std::move(gen));\n}\n"
    }
  },
  "torch.poisson": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "_s_poisson_cpu",
      "file": "aten/src/ATen/native/Distributions.cpp",
      "start_line": 451,
      "end_line": 466,
      "code": "Tensor _s_poisson_cpu(const Tensor& lambda, std::optional<Generator> gen) {\n  Tensor ret = at::zeros(lambda.sizes(), lambda.options());\n  auto iter = TensorIteratorConfig()\n    .add_output(ret)\n    .add_input(lambda)\n    .build();\n  AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::BFloat16, at::ScalarType::Half, ret.scalar_type(), \"poisson_cpu\", [&] {\n    CPUGeneratorImpl* generator = get_generator_or_default<CPUGeneratorImpl>(gen, detail::getDefaultCPUGenerator());\n    // See Note [Acquire lock when using random generators]\n    std::lock_guard<std::mutex> lock(generator->mutex_);\n    cpu_serial_kernel(iter, [generator](scalar_t lambda_val) -> scalar_t{\n      return static_cast<scalar_t>(sample_poisson(static_cast<double>(lambda_val), generator));\n    });\n  });\n  return ret;\n}\n"
    }
  },
  "torch.quasirandom.SobolEngine": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\quasirandom.py",
      "start_line": 7,
      "end_line": 217,
      "code": "class SobolEngine:\n\n    MAXBIT = 30\n    MAXDIM = 21201\n\n    def __init__(self, dimension, scramble=False, seed=None):\n        if dimension > self.MAXDIM or dimension < 1:\n            raise ValueError(\n                \"Supported range of dimensionality \"\n                f\"for SobolEngine is [1, {self.MAXDIM}]\"\n            )\n\n        self.seed = seed\n        self.scramble = scramble\n        self.dimension = dimension\n\n        cpu = torch.device(\"cpu\")\n\n        self.sobolstate = torch.zeros(\n            dimension, self.MAXBIT, device=cpu, dtype=torch.long\n        )\n        torch._sobol_engine_initialize_state_(self.sobolstate, self.dimension)\n\n        if not self.scramble:\n            self.shift = torch.zeros(self.dimension, device=cpu, dtype=torch.long)\n        else:\n            self._scramble()\n\n        self.quasi = self.shift.clone(memory_format=torch.contiguous_format)\n        self._first_point = (self.quasi / 2**self.MAXBIT).reshape(1, -1)\n        self.num_generated = 0\n\n    def draw(\n        self,\n        n: int = 1,\n        out: Optional[torch.Tensor] = None,\n        dtype: Optional[torch.dtype] = None,\n    ) -> torch.Tensor:\n        r\"\"\"\n        Function to draw a sequence of :attr:`n` points from a Sobol sequence.\n        Note that the samples are dependent on the previous samples. The size\n        of the result is :math:`(n, dimension)`.\n\n        Args:\n            n (Int, optional): The length of sequence of points to draw.\n                               Default: 1\n            out (Tensor, optional): The output tensor\n            dtype (:class:`torch.dtype`, optional): the desired data type of the\n                                                    returned tensor.\n                                                    Default: ``None``\n        \"\"\"\n        if dtype is None:\n            dtype = torch.get_default_dtype()\n\n        if self.num_generated == 0:\n            if n == 1:\n                result = self._first_point.to(dtype)\n            else:\n                result, self.quasi = torch._sobol_engine_draw(\n                    self.quasi,\n                    n - 1,\n                    self.sobolstate,\n                    self.dimension,\n                    self.num_generated,\n                    dtype=dtype,\n                )\n                result = torch.cat((self._first_point.to(dtype), result), dim=-2)\n        else:\n            result, self.quasi = torch._sobol_engine_draw(\n                self.quasi,\n                n,\n                self.sobolstate,\n                self.dimension,\n                self.num_generated - 1,\n                dtype=dtype,\n            )\n\n        self.num_generated += n\n\n        if out is not None:\n            out.resize_as_(result).copy_(result)\n            return out\n\n        return result\n\n    def draw_base2(\n        self,\n        m: int,\n        out: Optional[torch.Tensor] = None,\n        dtype: Optional[torch.dtype] = None,\n    ) -> torch.Tensor:\n        r\"\"\"\n        Function to draw a sequence of :attr:`2**m` points from a Sobol sequence.\n        Note that the samples are dependent on the previous samples. The size\n        of the result is :math:`(2**m, dimension)`.\n\n        Args:\n            m (Int): The (base2) exponent of the number of points to draw.\n            out (Tensor, optional): The output tensor\n            dtype (:class:`torch.dtype`, optional): the desired data type of the\n                                                    returned tensor.\n                                                    Default: ``None``\n        \"\"\"\n        n = 2**m\n        total_n = self.num_generated + n\n        if not (total_n & (total_n - 1) == 0):\n            raise ValueError(\n                \"The balance properties of Sobol' points require \"\n                f\"n to be a power of 2. {self.num_generated} points have been \"\n                f\"previously generated, then: n={self.num_generated}+2**{m}={total_n}. \"\n                \"If you still want to do this, please use \"\n                \"'SobolEngine.draw()' instead.\"\n            )\n        return self.draw(n=n, out=out, dtype=dtype)\n\n    def reset(self):\n        r\"\"\"\n        Function to reset the ``SobolEngine`` to base state.\n        \"\"\"\n        self.quasi.copy_(self.shift)\n        self.num_generated = 0\n        return self\n\n    def fast_forward(self, n):\n        r\"\"\"\n        Function to fast-forward the state of the ``SobolEngine`` by\n        :attr:`n` steps. This is equivalent to drawing :attr:`n` samples\n        without using the samples.\n\n        Args:\n            n (Int): The number of steps to fast-forward by.\n        \"\"\"\n        if self.num_generated == 0:\n            torch._sobol_engine_ff_(\n                self.quasi, n - 1, self.sobolstate, self.dimension, self.num_generated\n            )\n        else:\n            torch._sobol_engine_ff_(\n                self.quasi, n, self.sobolstate, self.dimension, self.num_generated - 1\n            )\n        self.num_generated += n\n        return self\n\n    def _scramble(self):\n        g: Optional[torch.Generator] = None\n        if self.seed is not None:\n            g = torch.Generator()\n            g.manual_seed(self.seed)\n\n        cpu = torch.device(\"cpu\")\n\n        # Generate shift vector\n        shift_ints = torch.randint(\n            2, (self.dimension, self.MAXBIT), device=cpu, generator=g\n        )\n        self.shift = torch.mv(\n            shift_ints, torch.pow(2, torch.arange(0, self.MAXBIT, device=cpu))\n        )\n\n        # Generate lower triangular matrices (stacked across dimensions)\n        ltm_dims = (self.dimension, self.MAXBIT, self.MAXBIT)\n        ltm = torch.randint(2, ltm_dims, device=cpu, generator=g).tril()\n\n        torch._sobol_engine_scramble_(self.sobolstate, ltm, self.dimension)\n\n    def __repr__(self):\n        fmt_string = [f\"dimension={self.dimension}\"]\n        if self.scramble:\n            fmt_string += [\"scramble=True\"]\n        if self.seed is not None:\n            fmt_string += [f\"seed={self.seed}\"]\n        return self.__class__.__name__ + \"(\" + \", \".join(fmt_string) + \")\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.save": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\serialization.py",
      "start_line": 796,
      "end_line": 865,
      "code": "def save(\n    obj: object,\n    f: FILE_LIKE,\n    pickle_module: Any = pickle,\n    pickle_protocol: int = DEFAULT_PROTOCOL,\n    _use_new_zipfile_serialization: bool = True,\n    _disable_byteorder_record: bool = False,\n) -> None:\n    # Reference: https://github.com/pytorch/pytorch/issues/54354\n    # The first line of this docstring overrides the one Sphinx generates for the\n    # documentation. We need it so that Sphinx doesn't leak `pickle`s path from\n    # the build environment (e.g. `<module 'pickle' from '/leaked/path').\n\n    torch._C._log_api_usage_once(\"torch.save\")\n    _check_dill_version(pickle_module)\n    _check_save_filelike(f)\n\n    if _use_new_zipfile_serialization:\n        with _open_zipfile_writer(f) as opened_zipfile:\n            _save(\n                obj,\n                opened_zipfile,\n                pickle_module,\n                pickle_protocol,\n                _disable_byteorder_record,\n            )\n            return\n    else:\n        global _serialization_tls\n        if _serialization_tls.skip_data:\n            raise RuntimeError(\n                \"Cannot use skip_data=True with _use_new_zipfile_serialization=False\"\n            )\n        with _open_file_like(f, \"wb\") as opened_file:\n            _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.load": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\serialization.py",
      "start_line": 1117,
      "end_line": 1386,
      "code": "def load(\n    f: FILE_LIKE,\n    map_location: MAP_LOCATION = None,\n    pickle_module: Any = None,\n    *,\n    weights_only: Optional[bool] = None,\n    mmap: Optional[bool] = None,\n    **pickle_load_args: Any,\n) -> Any:\n    # Reference: https://github.com/pytorch/pytorch/issues/54354\n    # The first line of this docstring overrides the one Sphinx generates for the\n    # documentation. We need it so that Sphinx doesn't leak `pickle`s path from\n    # the build environment (e.g. `<module 'pickle' from '/leaked/path').\n\n    torch._C._log_api_usage_once(\"torch.load\")\n    UNSAFE_MESSAGE = (\n        \"Re-running `torch.load` with `weights_only` set to `False` will likely succeed, \"\n        \"but it can result in arbitrary code execution. Do it only if you got the file from a \"\n        \"trusted source.\"\n    )\n    DOCS_MESSAGE = (\n        \"\\n\\nCheck the documentation of torch.load to learn more about types accepted by default with \"\n        \"weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\"\n    )\n\n    def _get_wo_message(message: str) -> str:\n        unsafe_global_pattern = r\"GLOBAL (\\S+) was not an allowed global by default.\"\n        has_unsafe_global = re.search(unsafe_global_pattern, message) is not None\n        blocklist_pattern = r\"whose module (\\S+) is blocked\"\n        has_blocklist = re.search(blocklist_pattern, message) is not None\n        if has_unsafe_global:\n            updated_message = (\n                \"Weights only load failed. This file can still be loaded, to do so you have two options, \"\n                \"\\033[1mdo those steps only if you trust the source of the checkpoint\\033[0m. \"\n                f\"\\n\\t(1) {UNSAFE_MESSAGE}\\n\\t(2) Alternatively, to load with `weights_only=True` please check \"\n                \"the recommended steps in the following error message.\\n\\tWeightsUnpickler error: \"\n                + message\n            )\n        else:\n            updated_message = f\"Weights only load failed. {UNSAFE_MESSAGE}\\n\"\n            if not has_blocklist:\n                updated_message += (\n                    \"Please file an issue with the following so that we can make \"\n                    \"`weights_only=True` compatible with your use case: WeightsUnpickler error: \"\n                )\n            updated_message += message\n        return updated_message + DOCS_MESSAGE\n\n    global _serialization_tls\n    skip_data = _serialization_tls.skip_data\n    if skip_data:\n        raise RuntimeError(\n            \"`torch.load` called within a torch.serialization.skip_data context manager \"\n            \"is not supported yet. Please call torch.load outside the skip_data context manager.\"\n        )\n\n    if weights_only is None:\n        weights_only, warn_weights_only = False, True\n    else:\n        warn_weights_only = False\n\n    # Add ability to force safe only weight loads via environment variable\n    if os.getenv(\"TORCH_FORCE_WEIGHTS_ONLY_LOAD\", \"0\").lower() in [\n        \"1\",\n        \"y\",\n        \"yes\",\n        \"true\",\n    ]:\n        weights_only = True\n\n    if weights_only:\n        if pickle_module is not None:\n            raise RuntimeError(\n                \"Can not safely load weights when explicit pickle_module is specified\"\n            )\n    else:\n        if pickle_module is None:\n            if warn_weights_only:\n                warnings.warn(\n                    \"You are using `torch.load` with `weights_only=False` (the current default value), which uses \"\n                    \"the default pickle module implicitly. It is possible to construct malicious pickle data \"\n                    \"which will execute arbitrary code during unpickling (See \"\n                    \"https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). \"\n                    \"In a future release, the default value for `weights_only` will be flipped to `True`. This \"\n                    \"limits the functions that could be executed during unpickling. Arbitrary objects will no \"\n                    \"longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the \"\n                    \"user via `torch.serialization.add_safe_globals`. We recommend you start setting \"\n                    \"`weights_only=True` for any use case where you don't have full control of the loaded file. \"\n                    \"Please open an issue on GitHub for any issues related to this experimental feature.\",\n                    FutureWarning,\n                    stacklevel=2,\n                )\n            pickle_module = pickle\n\n    # make flipping default BC-compatible\n    if mmap is None:\n        mmap = False\n\n    _check_dill_version(pickle_module)\n\n    if \"encoding\" not in pickle_load_args.keys():\n        pickle_load_args[\"encoding\"] = \"utf-8\"\n\n    with _open_file_like(f, \"rb\") as opened_file:\n        if _is_zipfile(opened_file):\n            # The zipfile reader is going to advance the current file position.\n            # If we want to actually tail call to torch.jit.load, we need to\n            # reset back to the original position.\n            orig_position = opened_file.tell()\n            overall_storage = None\n            with _open_zipfile_reader(opened_file) as opened_zipfile:\n                if _is_torchscript_zip(opened_zipfile):\n                    warnings.warn(\n                        \"'torch.load' received a zip file that looks like a TorchScript archive\"\n                        \" dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to\"\n                        \" silence this warning)\",\n                        UserWarning,\n                    )\n                    opened_file.seek(orig_position)\n                    return torch.jit.load(opened_file, map_location=map_location)\n                if mmap:\n                    if not _is_path(f):\n                        raise ValueError(\n                            \"f must be a file path in order to use the mmap argument\"\n                        )\n                    size = os.path.getsize(f)\n                    if not IS_WINDOWS:\n                        shared = get_default_mmap_options() == MAP_SHARED\n                    else:\n                        shared = False\n                    overall_storage = torch.UntypedStorage.from_file(\n                        os.fspath(f), shared, size\n                    )\n                if weights_only:\n                    try:\n                        return _load(\n                            opened_zipfile,\n                            map_location,\n                            _weights_only_unpickler,\n                            overall_storage=overall_storage,\n                            **pickle_load_args,\n                        )\n                    except pickle.UnpicklingError as e:\n                        raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n                return _load(\n                    opened_zipfile,\n                    map_location,\n                    pickle_module,\n                    overall_storage=overall_storage,\n                    **pickle_load_args,\n                )\n        if mmap:\n            f_name = \"\" if not isinstance(f, str) else f\"{f}, \"\n            raise RuntimeError(\n                \"mmap can only be used with files saved with \"\n                f\"`torch.save({f_name}_use_new_zipfile_serialization=True), \"\n                \"please torch.save your checkpoint with this option in order to use mmap.\"\n            )\n        if weights_only:\n            try:\n                return _legacy_load(\n                    opened_file,\n                    map_location,\n                    _weights_only_unpickler,\n                    **pickle_load_args,\n                )\n            except pickle.UnpicklingError as e:\n                raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n        return _legacy_load(\n            opened_file, map_location, pickle_module, **pickle_load_args\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.get_num_threads": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.set_num_threads": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.get_num_interop_threads": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.set_num_interop_threads": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.set_grad_enabled": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\autograd\\grad_mode.py",
      "start_line": 143,
      "end_line": 203,
      "code": "class set_grad_enabled(_DecoratorContextManager):\n\n    def __init__(self, mode: bool) -> None:\n        self.prev = torch.is_grad_enabled()\n        self.mode = mode\n        torch._C._set_grad_enabled(mode)\n\n    def __call__(self, orig_func: F) -> F:\n        torch._C._set_grad_enabled(self.prev)\n        return super().__call__(orig_func)\n\n    def __enter__(self) -> None:\n        torch._C._set_grad_enabled(self.mode)\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        torch._C._set_grad_enabled(self.prev)\n\n    def clone(self) -> \"set_grad_enabled\":\n        r\"\"\"\n        Create a copy of this class\n        \"\"\"\n        return self.__class__(self.mode)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.abs": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "abs",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 546,
      "end_line": 548,
      "code": "Tensor abs(const Tensor& self) {\n  return unary_op_impl_with_complex_to_float(self, at::abs_out);\n}\n"
    }
  },
  "torch.absolute": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.acos": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "acos_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 321,
      "end_line": 321,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(acos_out, acos_stub)\n"
    }
  },
  "torch.arccos": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.acosh": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "acosh_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 322,
      "end_line": 322,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(acosh_out, acosh_stub)\n"
    }
  },
  "torch.arccosh": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.add": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "add_sparse",
      "file": "aten/src/ATen/native/sparse/SparseTensorMath.cpp",
      "start_line": 407,
      "end_line": 415,
      "code": "Tensor add_sparse(const Tensor& self, const Tensor& other, const Scalar& alpha) {\n  // TODO: Why?! Can't we just flip the order here...\n  TORCH_CHECK(!(self.is_sparse() && !other.is_sparse()),\n              \"add(sparse, dense) is not supported. Use add(dense, sparse) instead.\");\n  auto commonDtype = at::result_type(self, other);\n  alpha_check(commonDtype, alpha);\n  Tensor result = at::empty({0}, self.options().dtype(commonDtype));\n  return at::add_out(result, self, other, alpha);  // redispatch!\n}\n"
    }
  },
  "torch.addcdiv": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "addcdiv_out",
      "file": "aten/src/ATen/native/PointwiseOps.cpp",
      "start_line": 58,
      "end_line": 65,
      "code": "TORCH_IMPL_FUNC(addcdiv_out)\n(const Tensor& self,\n const Tensor& tensor1,\n const Tensor& tensor2,\n const Scalar& value,\n const Tensor& result) {\n  addcdiv_stub(device_type(), *this, value);\n}\n"
    }
  },
  "torch.addcmul": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "addcmul_out",
      "file": "aten/src/ATen/native/PointwiseOps.cpp",
      "start_line": 49,
      "end_line": 56,
      "code": "TORCH_IMPL_FUNC(addcmul_out)\n(const Tensor& self,\n const Tensor& tensor1,\n const Tensor& tensor2,\n const Scalar& value,\n const Tensor& result) {\n  addcmul_stub(device_type(), *this, value);\n}\n"
    }
  },
  "torch.asin": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "asin_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 171,
      "end_line": 171,
      "code": "COALESCED_UNARY_UFUNC(asin);\n"
    }
  },
  "torch.arcsin": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.asinh": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "asinh_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 172,
      "end_line": 172,
      "code": "COALESCED_UNARY_UFUNC(asinh);\n"
    }
  },
  "torch.arcsinh": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.atan": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "atan_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 173,
      "end_line": 173,
      "code": "COALESCED_UNARY_UFUNC(atan);\n"
    }
  },
  "torch.arctan": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.atanh": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "atanh_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 174,
      "end_line": 174,
      "code": "COALESCED_UNARY_UFUNC(atanh);\n"
    }
  },
  "torch.arctanh": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.atan2": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "atan2_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 794,
      "end_line": 796,
      "code": "TORCH_IMPL_FUNC(atan2_out) (const Tensor& self, const Tensor& other, const Tensor& result) {\n  atan2_stub(device_type(), *this);\n}\n"
    }
  },
  "torch.bitwise_not": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "bitwise_not_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 327,
      "end_line": 327,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(bitwise_not_out, bitwise_not_stub)\n"
    }
  },
  "torch.bitwise_and": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "bitwise_and_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 535,
      "end_line": 535,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(bitwise_and_out, bitwise_and_stub);\n"
    }
  },
  "torch.bitwise_or": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "bitwise_or_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 536,
      "end_line": 536,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(bitwise_or_out, bitwise_or_stub);\n"
    }
  },
  "torch.bitwise_xor": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "bitwise_xor_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 537,
      "end_line": 537,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(bitwise_xor_out, bitwise_xor_stub);\n"
    }
  },
  "torch.ceil": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "ceil_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 175,
      "end_line": 175,
      "code": "COALESCED_UNARY_UFUNC(ceil);\n"
    }
  },
  "torch.clamp": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "clamp_quantized_cpu",
      "file": "aten/src/ATen/native/quantized/cpu/qclamp.cpp",
      "start_line": 129,
      "end_line": 138,
      "code": "Tensor clamp_quantized_cpu(\n    const Tensor& qx,\n    const std::optional<Scalar>& min,\n    const std::optional<Scalar>& max) {\n  Tensor qy;\n  AT_DISPATCH_QINT_TYPES(qx.scalar_type(), \"clamp\", [&]() {\n    qy = quantized_clamp_impl(qx, min, max);\n  });\n  return qy;\n}\n"
    }
  },
  "torch.max": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "max",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 1497,
      "end_line": 1499,
      "code": "Tensor max(const Tensor& self, const Tensor& other) {\n  return at::maximum(self, other);\n}\n"
    }
  },
  "torch.clip": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.conj": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "_conj",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 652,
      "end_line": 657,
      "code": "Tensor _conj(const Tensor& self) {\n  Tensor self_ = self.alias();\n  self_._set_conj(!self.is_conj());\n  namedinference::propagate_names(self_, self);\n  return self_;\n}\n"
    }
  },
  "torch.copysign": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "copysign_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 864,
      "end_line": 868,
      "code": "TORCH_IMPL_FUNC(copysign_out) (\n  const Tensor& self, const Tensor& other, const Tensor& result\n) {\n  copysign_stub(device_type(), *this);\n}\n"
    }
  },
  "torch.cos": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "cos_nested",
      "file": "aten/src/ATen/native/nested/NestedTensorUnaryOps.cpp",
      "start_line": 166,
      "end_line": 168,
      "code": "Tensor cos_nested(const Tensor& self) {\n  return map_nt(self, at::cos);\n}\n"
    }
  },
  "torch.cosh": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "cosh_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 329,
      "end_line": 329,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(cosh_out, cosh_stub)\n"
    }
  },
  "torch.deg2rad": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "deg2rad",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 515,
      "end_line": 525,
      "code": "Tensor deg2rad(const Tensor& self) {\n  // Note: int-> float promotion handled differently from other Unary ops,\n  // as it does not use the usual TensorIterator + Kernel Dispatch pattern.\n  auto options = self.options();\n  if (c10::isIntegralType(self.scalar_type(), /*includeBool=*/true)) {\n    options = options.dtype(c10::get_default_dtype());\n  }\n  auto result = at::empty_like(self, options);\n  at::deg2rad_out(result, self);\n  return result;\n}\n"
    }
  },
  "torch.div": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "div_sparse",
      "file": "aten/src/ATen/native/sparse/SparseTensorMath.cpp",
      "start_line": 260,
      "end_line": 267,
      "code": "Tensor div_sparse(const Tensor& self, const Tensor& value) {\n  auto commonDtype = at::result_type(self, value);\n  if (c10::isIntegralType(commonDtype, /*includeBool=*/true)) {\n    commonDtype = typeMetaToScalarType(at::get_default_dtype());\n  }\n  Tensor result = at::empty({0}, self.options().dtype(commonDtype));\n  return div_out_sparse_zerodim(self, value, result);\n}\n"
    }
  },
  "torch.divide": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.digamma": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "digamma_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 330,
      "end_line": 330,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(digamma_out, digamma_stub)\n"
    }
  },
  "torch.erf": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "erf_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 177,
      "end_line": 177,
      "code": "COALESCED_UNARY_UFUNC(erf);\n"
    }
  },
  "torch.erfc": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "erfc_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 332,
      "end_line": 332,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(erfc_out, erfc_stub)\n"
    }
  },
  "torch.erfinv": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "erfinv_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 178,
      "end_line": 178,
      "code": "COALESCED_UNARY_UFUNC(erfinv);\n"
    }
  },
  "torch.exp": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "exp_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 334,
      "end_line": 334,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(exp_out, exp_stub)\n"
    }
  },
  "torch.exp2": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "exp2_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 335,
      "end_line": 335,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(exp2_out, exp2_stub)\n"
    }
  },
  "torch.expm1": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "expm1_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 179,
      "end_line": 179,
      "code": "COALESCED_UNARY_UFUNC(expm1);\n"
    }
  },
  "torch.fake_quantize_per_channel_affine": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.fake_quantize_per_tensor_affine": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.fix": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.trunc": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "trunc_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 192,
      "end_line": 192,
      "code": "COALESCED_UNARY_UFUNC(trunc);\n"
    }
  },
  "torch.float_power": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.floor": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "floor_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 180,
      "end_line": 180,
      "code": "COALESCED_UNARY_UFUNC(floor);\n"
    }
  },
  "torch.floor_divide": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "floor_divide",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 978,
      "end_line": 983,
      "code": "Tensor floor_divide(const Tensor& self, const Tensor& other) {\n  Tensor result;\n  auto iter = TensorIterator::binary_op(result, self, other);\n  div_floor_stub(iter.device_type(), iter);\n  return iter.output();\n}\n"
    }
  },
  "torch.fmod": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "fmod_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 542,
      "end_line": 542,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(fmod_out, fmod_stub);\n"
    }
  },
  "torch.frac": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "frac_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 181,
      "end_line": 181,
      "code": "COALESCED_UNARY_UFUNC(frac);\n"
    }
  },
  "torch.ldexp": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.lerp": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.lgamma": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "lgamma_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 339,
      "end_line": 339,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(lgamma_out, lgamma_stub)\n"
    }
  },
  "torch.log": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "log_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 340,
      "end_line": 340,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(log_out, log_stub)\n"
    }
  },
  "torch.log10": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "log10_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 341,
      "end_line": 341,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(log10_out, log10_stub)\n"
    }
  },
  "torch.log1p": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "log1p_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 182,
      "end_line": 182,
      "code": "COALESCED_UNARY_UFUNC(log1p);\n"
    }
  },
  "torch.log2": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "log2_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 343,
      "end_line": 343,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(log2_out, log2_stub)\n"
    }
  },
  "torch.logaddexp": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "logaddexp_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 543,
      "end_line": 543,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(logaddexp_out, logaddexp_stub);\n"
    }
  },
  "torch.logaddexp2": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "logaddexp2_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 544,
      "end_line": 544,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(logaddexp2_out, logaddexp2_stub);\n"
    }
  },
  "torch.logical_and": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "logical_and",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 1481,
      "end_line": 1481,
      "code": "Tensor logical_and(const Tensor& self, const Tensor& other) { return comparison_op(self, other, static_cast<OutFunc>(at::logical_and_out)); }\n"
    }
  },
  "torch.logical_not": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "logical_not",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 857,
      "end_line": 860,
      "code": "Tensor logical_not(const Tensor& self) {\n  Tensor result = at::empty({0}, self.options().dtype(kBool));\n  return at::logical_not_out(result, self);\n}\n"
    }
  },
  "torch.logical_or": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "logical_or",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 1485,
      "end_line": 1485,
      "code": "Tensor logical_or(const Tensor& self, const Tensor& other) { return comparison_op(self, other, static_cast<OutFunc>(at::logical_or_out)); }\n"
    }
  },
  "torch.logical_xor": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "logical_xor",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 1489,
      "end_line": 1489,
      "code": "Tensor logical_xor(const Tensor& self, const Tensor& other) { return comparison_op(self, other, static_cast<OutFunc>(at::logical_xor_out)); }\n"
    }
  },
  "torch.logit": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "logit",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 780,
      "end_line": 783,
      "code": "Tensor logit(const Tensor& self, std::optional<double> eps) {\n  return unary_op_impl_float(\n      self, logit_stub, Scalar(eps ? eps.value() : -1.0));\n}\n"
    }
  },
  "torch.hypot": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "hypot_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 547,
      "end_line": 547,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(hypot_out, hypot_stub);\n"
    }
  },
  "torch.i0": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "i0_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 338,
      "end_line": 338,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(i0_out, i0_stub)\n"
    }
  },
  "torch.igamma": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "igamma_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 548,
      "end_line": 548,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(igamma_out, igamma_stub);\n"
    }
  },
  "torch.igammac": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "igammac_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 549,
      "end_line": 549,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(igammac_out, igammac_stub);\n"
    }
  },
  "torch.mul": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.multiply": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.mvlgamma": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "mvlgamma",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 886,
      "end_line": 904,
      "code": "Tensor mvlgamma(const Tensor& self, int64_t p) {\n  mvlgamma_check(self, p);\n  auto dtype = c10::scalarTypeToTypeMeta(self.scalar_type());\n  if (at::isIntegralType(self.scalar_type(), /*include_bool=*/true)) {\n    // int -> float promotion\n    dtype = c10::get_default_dtype();\n  }\n  Tensor args = native::arange(\n      -p * HALF + HALF,\n      HALF,\n      HALF,\n      optTypeMetaToScalarType(dtype),\n      self.options().layout_opt(),\n      self.options().device_opt(),\n      self.options().pinned_memory_opt());\n  args = args.add(self.unsqueeze(-1));\n  const auto p2_sub_p = static_cast<double>(p * (p - 1));\n  return args.lgamma_().sum(-1).add_(p2_sub_p * std::log(c10::pi<double>) * QUARTER);\n}\n"
    }
  },
  "torch.nan_to_num": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "nan_to_num",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 826,
      "end_line": 833,
      "code": "Tensor nan_to_num(\n    const Tensor& self,\n    std::optional<double> nan,\n    std::optional<double> pos_inf,\n    std::optional<double> neg_inf) {\n  auto result = at::empty_like(self);\n  return at::nan_to_num_out(result, self, nan, pos_inf, neg_inf);\n}\n"
    }
  },
  "torch.neg": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "neg_sparse",
      "file": "aten/src/ATen/native/sparse/SparseTensorMath.cpp",
      "start_line": 151,
      "end_line": 155,
      "code": "SparseTensor neg_sparse(const SparseTensor& t) {\n  SparseTensor r = at::empty_like(t);\n  neg_out_sparse(t, r);\n  return r;\n}\n"
    }
  },
  "torch.negative": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nextafter": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "nextafter_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 550,
      "end_line": 550,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(nextafter_out, nextafter_stub);\n"
    }
  },
  "torch.polygamma": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "polygamma_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 384,
      "end_line": 387,
      "code": "TORCH_IMPL_FUNC(polygamma_out)\n(int64_t n, const Tensor& self, const Tensor& result) {\n  polygamma_stub(device_type(), *this, n);\n}\n"
    }
  },
  "torch.pow": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.rad2deg": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "rad2deg",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 497,
      "end_line": 507,
      "code": "Tensor rad2deg(const Tensor& self) {\n  // Note: int-> float promotion handled differently from other Unary ops,\n  // as it does not use the usual TensorIterator + Kernel Dispatch pattern.\n  auto options = self.options();\n  if (c10::isIntegralType(self.scalar_type(), /*includeBool=*/true)) {\n    options = options.dtype(c10::get_default_dtype());\n  }\n  auto result = at::empty_like(self, options);\n  at::rad2deg_out(result, self);\n  return result;\n}\n"
    }
  },
  "torch.real": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "view_as_real",
      "file": "<empty>",
      "start_line": -1,
      "end_line": -1,
      "code": ""
    }
  },
  "torch.reciprocal": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "reciprocal_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 345,
      "end_line": 345,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(reciprocal_out, reciprocal_stub)\n"
    }
  },
  "torch.remainder": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "remainder_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 551,
      "end_line": 551,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(remainder_out, remainder_stub);\n"
    }
  },
  "torch.round": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "round_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 183,
      "end_line": 183,
      "code": "COALESCED_UNARY_UFUNC(round);\n"
    }
  },
  "torch.rsqrt": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "rsqrt_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 346,
      "end_line": 346,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(rsqrt_out, rsqrt_stub)\n"
    }
  },
  "torch.sigmoid": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "sigmoid_quantized_cpu",
      "file": "aten/src/ATen/native/quantized/cpu/qsigmoid.cpp",
      "start_line": 100,
      "end_line": 128,
      "code": "Tensor sigmoid_quantized_cpu(const Tensor& qx) {\n#ifdef USE_PYTORCH_QNNPACK\n  if (at::globalContext().qEngine() == at::QEngine::QNNPACK &&\n      qx.scalar_type() == kQUInt8) {\n    constexpr double output_scale = 1.0f / 256.0f;\n    constexpr int64_t output_zero_point = 0;\n    return qnnpack_sigmoid(qx, output_scale, output_zero_point);\n  }\n#endif  // USE_PYTORCH_QNNPACK\n  Tensor qy;\n  AT_DISPATCH_QINT_TYPES(qx.scalar_type(), \"qsigmoid\", [&]() {\n    // Naive implementation: uses dequantize/execute/quantize routine\n    // - Output scale is set to 1.0 / 2^(BIT_NUM)\n    // - For signed types output zero point is set to 0\n    // - For unsigned types output zero point is set to (qmax + qmin) / 2.0\n    // See https://stackoverflow.com/a/34448562/3606192 for potential\n    // optimizations\n    double output_scale = 0.00390625;  // 1.0 / 2^8\n    int64_t output_zero_point = 0;\n    // NOLINTNEXTLINE(clang-analyzer-core.NullDereference)\n    if (SCALAR_TYPE == at::kQInt32) {\n      output_scale = 2.3283064365386963e-10;  // 1.0 / 2^32\n    } else if (SCALAR_TYPE == at::kQInt8) {\n      output_zero_point = -128;\n    }\n    qsigmoid_stub(qx.device().type(), qx, qy, output_scale, output_zero_point);\n  });\n  return qy;\n}\n"
    }
  },
  "torch.sign": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "sign_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 185,
      "end_line": 185,
      "code": "COALESCED_UNARY_UFUNC(sign);\n"
    }
  },
  "torch.sgn": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "sgn_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 186,
      "end_line": 186,
      "code": "COALESCED_UNARY_UFUNC(sgn);\n"
    }
  },
  "torch.signbit": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "signbit_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 200,
      "end_line": 200,
      "code": "COALESCED_UNARY_UFUNC_NO_INPLACE(signbit);\n"
    }
  },
  "torch.sin": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "sin_sparse_csr",
      "file": "aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp",
      "start_line": 461,
      "end_line": 461,
      "code": "CREATE_UNARY_UFUNC(sin);\n"
    }
  },
  "torch.sinc": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "sinc_out",
      "file": "aten/src/ATen/native/UnaryOps.cpp",
      "start_line": 350,
      "end_line": 350,
      "code": "CREATE_UNARY_TORCH_IMPL_FUNC(sinc_out, sinc_stub)\n"
    }
  },
  "torch.sinh": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "sinh_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 188,
      "end_line": 188,
      "code": "COALESCED_UNARY_UFUNC(sinh);\n"
    }
  },
  "torch.sqrt": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "sqrt_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 189,
      "end_line": 189,
      "code": "COALESCED_UNARY_UFUNC(sqrt);\n"
    }
  },
  "torch.square": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.sub": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "sub_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 433,
      "end_line": 438,
      "code": "TORCH_IMPL_FUNC(sub_out) (\n  const Tensor& self, const Tensor& other, const Scalar& alpha, const Tensor& result\n) {\n  add_stub(device_type(), *this, -alpha);\n  TORCH_INTERNAL_ASSERT(result.scalar_type() == output().dtype());\n}\n"
    }
  },
  "torch.subtract": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.tan": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "tan_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 190,
      "end_line": 190,
      "code": "COALESCED_UNARY_UFUNC(tan);\n"
    }
  },
  "torch.tanh": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "tanh_quantized_cpu",
      "file": "aten/src/ATen/native/quantized/cpu/qtanh.cpp",
      "start_line": 92,
      "end_line": 102,
      "code": "Tensor tanh_quantized_cpu(const Tensor& qx) {\n#ifdef USE_PYTORCH_QNNPACK\n  if (at::globalContext().qEngine() == at::QEngine::QNNPACK &&\n      qx.scalar_type() == kQUInt8) {\n    return qnnpack_tanh(qx);\n  }\n#endif  // USE_PYTORCH_QNNPACK\n  Tensor qy;\n  qtanh_stub(qx.device().type(), qx, qy);\n  return qy;\n}\n"
    }
  },
  "torch.true_divide": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.xlogy": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.argmax": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "argmax_out",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 1753,
      "end_line": 1759,
      "code": "TORCH_IMPL_FUNC(argmax_out)\n(const Tensor& self,\n std::optional<int64_t> dim,\n bool keepdim,\n const Tensor& result) {\n  argmax_argmin_impl(self, dim, keepdim, result, argmax_stub);\n}\n"
    }
  },
  "torch.argmin": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "argmin_out",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 1761,
      "end_line": 1767,
      "code": "TORCH_IMPL_FUNC(argmin_out)\n(const Tensor& self,\n std::optional<int64_t> dim,\n bool keepdim,\n const Tensor& result) {\n  argmax_argmin_impl(self, dim, keepdim, result, argmin_stub);\n}\n"
    }
  },
  "torch.amax": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "amax_out",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 1710,
      "end_line": 1716,
      "code": "TORCH_IMPL_FUNC(amax_out) (const Tensor& self, IntArrayRef dim, bool keepdim, const Tensor& result) {\n  auto iter =\n      meta::make_reduction(self, result, dim, keepdim, self.scalar_type());\n  if (iter.numel() != 0) {\n    max_values_stub(iter.device_type(), iter);\n  }\n}\n"
    }
  },
  "torch.amin": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "amin_out",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 1702,
      "end_line": 1708,
      "code": "TORCH_IMPL_FUNC(amin_out) (const Tensor& self, IntArrayRef dim, bool keepdim, const Tensor& result) {\n  auto iter =\n      meta::make_reduction(self, result, dim, keepdim, self.scalar_type());\n  if (iter.numel() != 0) {\n    min_values_stub(iter.device_type(), iter);\n  }\n}\n"
    }
  },
  "torch.all": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "all_all_out",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 1621,
      "end_line": 1623,
      "code": "TORCH_IMPL_FUNC(all_all_out)(const Tensor& self, const Tensor& result) {\n  allany_impl<1>(self, result, {}, false, and_stub);\n}\n"
    }
  },
  "torch.any": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "any_sparse",
      "file": "aten/src/ATen/native/sparse/SparseTensorMath.cpp",
      "start_line": 1892,
      "end_line": 1896,
      "code": "Tensor any_sparse(const Tensor& self) {\n  TORCH_INTERNAL_ASSERT(self.is_sparse());\n\n  return at::any(self._values());\n}\n"
    }
  },
  "torch.min": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "min",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 1506,
      "end_line": 1508,
      "code": "Tensor min(const Tensor& self, const Tensor& other) {\n  return at::minimum(self, other);\n}\n"
    }
  },
  "torch.dist": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "dist",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 2216,
      "end_line": 2218,
      "code": "Tensor dist(const Tensor &self, const Tensor& other, const Scalar& p){\n  return at::norm(self - other, p);\n}\n"
    }
  },
  "torch.logsumexp": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "logsumexp",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 1492,
      "end_line": 1503,
      "code": "Tensor logsumexp(const Tensor& self, IntArrayRef dims, bool keepdim) {\n  TensorOptions result_options;\n  if (at::isIntegralType(self.scalar_type(), /*includeBool=*/true)) {\n    // even for integral inputs, result is floating dtype\n    auto default_dtype = at::typeMetaToScalarType(c10::get_default_dtype());\n    result_options = self.options().dtype(default_dtype);\n  } else {\n    result_options = self.options();\n  }\n  auto result = at::empty({0}, result_options);\n  return at::logsumexp_outf(self, dims, keepdim, result);\n}\n"
    }
  },
  "torch.mean": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "mean",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 1404,
      "end_line": 1406,
      "code": "Tensor mean(const Tensor &self, std::optional<ScalarType> dtype) {\n  return at::mean(self, IntArrayRef{}, false, dtype);\n}\n"
    }
  },
  "torch.median": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "median_cpu",
      "file": "aten/src/ATen/native/Sorting.cpp",
      "start_line": 889,
      "end_line": 891,
      "code": "Tensor median_cpu(const Tensor& self) {\n  return median_impl(self, /*ignore_nan=*/false);\n}\n"
    }
  },
  "torch.nanmedian": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "nanmedian_cpu",
      "file": "aten/src/ATen/native/Sorting.cpp",
      "start_line": 936,
      "end_line": 938,
      "code": "Tensor nanmedian_cpu(const Tensor& self) {\n  return median_impl(self, /*ignore_nan=*/true);\n}\n"
    }
  },
  "torch.mode": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "mode",
      "file": "aten/src/ATen/native/TensorCompare.cpp",
      "start_line": 580,
      "end_line": 584,
      "code": "std::tuple<Tensor, Tensor> mode(const Tensor& self, int64_t dim, bool keepdim) {\n  Tensor values = at::empty({0}, self.options());\n  Tensor indices = at::empty({0}, self.options().dtype(kLong));\n  return at::native::mode_out(self, dim, keepdim, values, indices);\n}\n"
    }
  },
  "torch.norm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 1671,
      "end_line": 1888,
      "code": "def norm(  # noqa: F811\n    input,\n    p: Optional[Union[float, str]] = \"fro\",\n    dim=None,\n    keepdim=False,\n    out=None,\n    dtype=None,\n):\n\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            norm, (input,), input, p=p, dim=dim, keepdim=keepdim, out=out, dtype=dtype\n        )\n\n    # NB. All the repeated code and weird python is to please TorchScript.\n    #     For a more compact implementation see the relevant function in `_refs/__init__.py`\n\n    # We don't do this for MPS or sparse tensors\n    if input.layout == torch.strided and input.device.type in (\n        \"cpu\",\n        \"cuda\",\n        \"meta\",\n        torch.utils.backend_registration._privateuse1_backend_name,\n    ):\n        if dim is not None:\n            if isinstance(dim, (int, torch.SymInt)):\n                _dim = [dim]\n            else:\n                _dim = dim\n        else:\n            _dim = None  # type: ignore[assignment]\n\n        if isinstance(p, str):\n            if p == \"fro\" and (\n                dim is None or isinstance(dim, (int, torch.SymInt)) or len(dim) <= 2\n            ):\n                if out is None:\n                    return torch.linalg.vector_norm(\n                        input, 2, _dim, keepdim, dtype=dtype\n                    )\n                else:\n                    return torch.linalg.vector_norm(\n                        input, 2, _dim, keepdim, dtype=dtype, out=out\n                    )\n\n            # Here we either call the nuclear norm, or we call matrix_norm with some arguments\n            # that will throw an error\n            if _dim is None:\n                _dim = list(range(input.ndim))\n            if out is None:\n                return torch.linalg.matrix_norm(input, p, _dim, keepdim, dtype=dtype)\n            else:\n                return torch.linalg.matrix_norm(\n                    input, p, _dim, keepdim, dtype=dtype, out=out\n                )\n        else:\n            # NB. p should be Union[str, number], not Optional!\n            _p = 2.0 if p is None else p\n            if out is None:\n                return torch.linalg.vector_norm(input, _p, _dim, keepdim, dtype=dtype)\n            else:\n                return torch.linalg.vector_norm(\n                    input, _p, _dim, keepdim, dtype=dtype, out=out\n                )\n\n    ndim = input.dim()\n\n    # catch default case\n    if dim is None and out is None and dtype is None and p is not None:\n        if isinstance(p, str):\n            if p == \"fro\":\n                return _VF.frobenius_norm(input, dim=(), keepdim=keepdim)\n        if not isinstance(p, str):\n            _dim = list(range(ndim))\n            return _VF.norm(input, p, dim=_dim, keepdim=keepdim)  # type: ignore[attr-defined]\n\n    # TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\n    # remove the overloads where dim is an int and replace with BraodcastingList1\n    # and remove next four lines, replace _dim with dim\n    if dim is not None:\n        if isinstance(dim, (int, torch.SymInt)):\n            _dim = [dim]\n        else:\n            _dim = dim\n    else:\n        _dim = None  # type: ignore[assignment]\n\n    if isinstance(p, str):\n        if p == \"fro\":\n            if dtype is not None:\n                raise ValueError(\"dtype argument is not supported in frobenius norm\")\n\n            if _dim is None:\n                _dim = list(range(ndim))\n            if out is None:\n                return _VF.frobenius_norm(input, _dim, keepdim=keepdim)  # type: ignore[arg-type]\n            else:\n                return _VF.frobenius_norm(input, _dim, keepdim=keepdim, out=out)  # type: ignore[arg-type]\n        elif p == \"nuc\":\n            if dtype is not None:\n                raise ValueError(\"dtype argument is not supported in nuclear norm\")\n            if _dim is None:\n                if out is None:\n                    return _VF.nuclear_norm(input, keepdim=keepdim)  # type: ignore[arg-type]\n                else:\n                    return _VF.nuclear_norm(input, keepdim=keepdim, out=out)  # type: ignore[arg-type]\n            else:\n                if out is None:\n                    return _VF.nuclear_norm(input, _dim, keepdim=keepdim)  # type: ignore[arg-type]\n                else:\n                    return _VF.nuclear_norm(input, _dim, keepdim=keepdim, out=out)  # type: ignore[arg-type]\n        raise RuntimeError(f\"only valid string values are 'fro' and 'nuc', found {p}\")\n    else:\n        if _dim is None:\n            _dim = list(range(ndim))\n\n        if out is None:\n            if dtype is None:\n                return _VF.norm(input, p, _dim, keepdim=keepdim)  # type: ignore[attr-defined]\n            else:\n                return _VF.norm(input, p, _dim, keepdim=keepdim, dtype=dtype)  # type: ignore[attr-defined]\n        else:\n            if dtype is None:\n                return _VF.norm(input, p, _dim, keepdim=keepdim, out=out)  # type: ignore[attr-defined]\n            else:\n                return _VF.norm(input, p, _dim, keepdim=keepdim, dtype=dtype, out=out)  # type: ignore[attr-defined]\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nansum": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "nansum",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 1258,
      "end_line": 1262,
      "code": "Tensor nansum(const Tensor& self, at::OptionalIntArrayRef dim, bool keepdim, std::optional<ScalarType> opt_dtype) {\n  ScalarType dtype = get_dtype_from_self(self, opt_dtype, true);\n  Tensor result = create_reduction_result(self, dim, keepdim, dtype);\n  return at::native::nansum_out(self, dim, keepdim, dtype, result);\n}\n"
    }
  },
  "torch.prod": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "prod",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 1331,
      "end_line": 1337,
      "code": "Tensor prod(const Tensor &self, std::optional<ScalarType> opt_dtype) {\n  auto dtype = get_dtype_from_self(self, opt_dtype, true);\n  auto shape = meta::get_reduction_shape(self, {}, false);\n  Tensor result = at::empty(shape, self.options().dtype(dtype));\n  impl_func_prod(self, {}, false, dtype, result);\n  return result;\n}\n"
    }
  },
  "torch.quantile": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nanquantile": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.std": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.std_mean": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.sum": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "sum",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 1223,
      "end_line": 1225,
      "code": "Tensor sum(const Tensor &self, std::optional<ScalarType> dtype) {\n  return at::sum(self, IntArrayRef{}, false, dtype);\n}\n"
    }
  },
  "torch.unique": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_jit_internal.py",
      "start_line": 614,
      "end_line": 624,
      "code": "def fn(*args, **kwargs):\n    dispatch_flag = default\n    if arg_name in kwargs:\n        dispatch_flag = kwargs[arg_name]\n    elif arg_index < len(args):\n        dispatch_flag = args[arg_index]\n\n    if dispatch_flag:\n        return if_true(*args, **kwargs)\n    else:\n        return if_false(*args, **kwargs)\n"
    },
    "cpp": {
      "function": "_unique_cpu",
      "file": "aten/src/ATen/native/Unique.cpp",
      "start_line": 441,
      "end_line": 455,
      "code": "std::tuple<Tensor, Tensor>\n_unique_cpu(const Tensor& self, const bool sorted, const bool return_inverse) {\n  if (self.scalar_type() == kBool) {\n    auto [output, inverse, _] = unique_cpu_bool_template(\n        self, return_inverse, /* return_counts */false);\n    return std::make_tuple(output, inverse);\n  }\n  return AT_DISPATCH_V2(self.scalar_type(), \"unique\", [&] AT_WRAP({\n    // The current CPU implementation of unique always sort due to\n    // this is faster than hash table\n    auto [output, inverse, _] = unique_cpu_sorted_template<scalar_t>(\n        self, return_inverse, /* return_counts */false, IsUnique<scalar_t, /* equal_nan */false>());\n    return std::make_tuple(output, inverse);\n  }), AT_EXPAND(AT_ALL_TYPES), kBFloat16, kHalf, AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES));\n}\n"
    }
  },
  "torch.unique_consecutive": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_jit_internal.py",
      "start_line": 614,
      "end_line": 624,
      "code": "def fn(*args, **kwargs):\n    dispatch_flag = default\n    if arg_name in kwargs:\n        dispatch_flag = kwargs[arg_name]\n    elif arg_index < len(args):\n        dispatch_flag = args[arg_index]\n\n    if dispatch_flag:\n        return if_true(*args, **kwargs)\n    else:\n        return if_false(*args, **kwargs)\n"
    },
    "cpp": {
      "function": "unique_consecutive_cpu",
      "file": "aten/src/ATen/native/Unique.cpp",
      "start_line": 485,
      "end_line": 493,
      "code": "std::tuple<Tensor, Tensor, Tensor>\nunique_consecutive_cpu(const Tensor& self, const bool return_inverse, const bool return_counts, std::optional<int64_t> dim) {\n  if (!dim.has_value() || (dim.value() == 0 && self.dim() == 1)) {\n    return AT_DISPATCH_V2(self.scalar_type(), \"unique\", AT_WRAP([&] {\n      return unique_consecutive_cpu_template<scalar_t>(self, return_inverse, return_counts);\n    }), AT_EXPAND(AT_ALL_TYPES), kBFloat16, kBool, kHalf, AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES));\n  }\n  return unique_dim_consecutive_cpu(self, dim.value(), return_inverse, return_counts);\n}\n"
    }
  },
  "torch.var": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.var_mean": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.count_nonzero": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "count_nonzero",
      "file": "aten/src/ATen/native/TensorAdvancedIndexing.cpp",
      "start_line": 2328,
      "end_line": 2333,
      "code": "Tensor count_nonzero(const Tensor& self, std::optional<int64_t> dim) {\n  if (dim) {\n    return at::count_nonzero(self, IntArrayRef{*dim});\n  }\n  return at::count_nonzero(self, IntArrayRef{});\n}\n"
    }
  },
  "torch.allclose": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "allclose",
      "file": "aten/src/ATen/native/TensorCompare.cpp",
      "start_line": 284,
      "end_line": 286,
      "code": "bool allclose(const Tensor& self, const Tensor& other, double rtol, double atol, bool equal_nan) {\n  return at::isclose(self, other, rtol, atol, equal_nan).all().item<uint8_t>();\n}\n"
    }
  },
  "torch.argsort": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.eq": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.equal": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "cpu_equal",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 2220,
      "end_line": 2292,
      "code": "bool cpu_equal(const Tensor& self, const Tensor& other) {\n  if (!at::namedinference::are_names_equal(\n        self.unsafeGetTensorImpl(), other.unsafeGetTensorImpl())) {\n    return false;\n  }\n  at::NoNamesGuard guard;\n  TORCH_CHECK(self.device() == other.device(), \"Cannot compare two tensors on \"\n              \"different devices. Got: \", self.device(), \" and \", other.device());\n  if (!self.is_same_size(other)) {\n    return false;\n  }\n  // Since the flags like neg/conj should be already handled outside the\n  // TensorIterator, it should be safe to have the following fast path by\n  // ensuring the storage and strides exactly the same.\n  if (self.is_alias_of(other)\n      && self.storage_offset() == other.storage_offset()\n      && self.dtype() == other.dtype()\n      && self.is_contiguous() == other.is_contiguous()\n      && self.strides().equals(other.strides())\n      // Extra checks to ensure the safety in case cpu_equal is directly called in C++.\n      && self.layout() == other.layout()\n      && self.is_neg() == other.is_neg()\n      && self.is_conj() == other.is_conj()) {\n    if (c10::isIntegralType(self.scalar_type(), /*includeBool=*/true)) {\n      return true;\n    }\n    std::atomic<bool> result{true};\n    auto iter = TensorIteratorConfig().add_const_input(self).build();\n    AT_DISPATCH_FLOATING_AND_COMPLEX_TYPES_AND2(kHalf, kBFloat16, iter.input_dtype(), \"equal_notnan_cpu\", [&] {\n      iter.for_each([&](char** data, const int64_t *strides, int64_t dim_size) {\n        if (!result) {\n            return;\n        }\n        char* self_data = data[0];\n        for (C10_UNUSED const auto i : c10::irange(dim_size)) {\n          if (isnan_(c10::load<scalar_t>(self_data))) {\n            result = false;\n            return;\n          }\n          self_data += strides[0];\n        }\n      });\n    });\n    return result.load();\n  }\n\n  std::atomic<bool> result{true};\n  auto iter = TensorIteratorConfig()\n    .add_const_input(self)\n    .add_const_input(other)\n    .allow_cpu_scalars(true)\n    .promote_inputs_to_common_dtype(true)\n    .build();\n\n  AT_DISPATCH_V2(iter.input_dtype(), \"equal_cpu\", AT_WRAP([&] {\n    iter.for_each([&](char** data, const int64_t *strides, int64_t dim_size) {\n      if (!result) {\n          return;\n      }\n      char* self_data = data[0];\n      char* other_data = data[1];\n      for (C10_UNUSED const auto i : c10::irange(dim_size)) {\n        if (c10::load<scalar_t>(self_data) != c10::load<scalar_t>(other_data)) {\n          result = false;\n          return;\n        }\n        self_data += strides[0];\n        other_data += strides[1];\n      }\n    });\n  }), kBool, kBFloat16, kHalf, AT_EXPAND(AT_ALL_TYPES_AND_COMPLEX), AT_EXPAND(AT_BAREBONES_UNSIGNED_TYPES));\n  return result.load();\n}\n"
    }
  },
  "torch.ge": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "_has_same_storage_numel",
      "file": "aten/src/ATen/native/AutogradComposite.cpp",
      "start_line": 90,
      "end_line": 92,
      "code": "bool _has_same_storage_numel(const at::Tensor& base, const at::Tensor& other) {\n  return base.storage().sym_nbytes() / base.itemsize() == other.storage().sym_nbytes() / other.itemsize();\n}\n"
    }
  },
  "torch.greater_equal": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.gt": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.greater": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.isclose": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.isfinite": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.isinf": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "isinf",
      "file": "aten/src/ATen/native/TensorCompare.cpp",
      "start_line": 388,
      "end_line": 403,
      "code": "Tensor isinf(const Tensor &self) {\n  // Note: Integral tensor values are never infinite\n  if (c10::isIntegralType(self.scalar_type(), /*includeBool=*/true)) {\n    return at::zeros_like(self, at::kBool, at::MemoryFormat::Preserve);\n  }\n\n  // Note: a complex value is infinite when either part is infinite\n  if (self.is_complex()) {\n    return at::isinf(at::real(self)).__ior__\n          (at::isinf(at::imag(self)));\n  }\n\n  return _AT_DISPATCH_INF_TYPES(self.scalar_type(), \"isinf\", [&]() {\n    return self.abs() == std::numeric_limits<scalar_t>::infinity();\n  });\n}\n"
    }
  },
  "torch.isposinf": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "isposinf_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 202,
      "end_line": 202,
      "code": "COALESCED_UNARY_UFUNC_NO_INPLACE(isposinf);\n"
    }
  },
  "torch.isneginf": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "isneginf_sparse",
      "file": "aten/src/ATen/native/sparse/SparseUnaryOps.cpp",
      "start_line": 201,
      "end_line": 201,
      "code": "COALESCED_UNARY_UFUNC_NO_INPLACE(isneginf);\n"
    }
  },
  "torch.isnan": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "isnan",
      "file": "aten/src/ATen/native/TensorCompare.cpp",
      "start_line": 362,
      "end_line": 364,
      "code": "Tensor isnan(const Tensor& self) {\n  return self != self;\n}\n"
    }
  },
  "torch.isreal": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.kthvalue": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "kthvalue",
      "file": "aten/src/ATen/native/Sorting.cpp",
      "start_line": 806,
      "end_line": 815,
      "code": "std::tuple<Tensor, Tensor> kthvalue(\n    const Tensor& self,\n    int64_t k,\n    int64_t dim,\n    bool keepdim) {\n  Tensor values = at::empty({0}, self.options());\n  Tensor indices = at::empty({0}, self.options().dtype(kLong));\n  at::kthvalue_out(values, indices, self, k, dim, keepdim);\n  return std::make_tuple(values, indices);\n}\n"
    }
  },
  "torch.le": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.less_equal": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.lt": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "_cslt_compress",
      "file": "aten/src/ATen/native/sparse/cuda/cuSPARSELtOps.cpp",
      "start_line": 394,
      "end_line": 396,
      "code": "at::Tensor _cslt_compress(const Tensor& sparse_input){\n    TORCH_CHECK(false, \"cuSPARSELt not supported on your machine.\");\n}\n"
    }
  },
  "torch.less": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.maximum": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "maximum_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 538,
      "end_line": 538,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(maximum_out, maximum_stub);\n"
    }
  },
  "torch.minimum": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "minimum_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 539,
      "end_line": 539,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(minimum_out, minimum_stub);\n"
    }
  },
  "torch.fmax": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "fmax_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 540,
      "end_line": 540,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(fmax_out, fmax_stub);\n"
    }
  },
  "torch.fmin": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "fmin_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 541,
      "end_line": 541,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(fmin_out, fmin_stub);\n"
    }
  },
  "torch.ne": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "_new_zeros_with_same_feature_meta",
      "file": "aten/src/ATen/native/AutogradComposite.cpp",
      "start_line": 42,
      "end_line": 88,
      "code": "Tensor _new_zeros_with_same_feature_meta(\n    const at::Tensor& self,\n    const at::Tensor& other,\n    int64_t self_num_batch_dims) {\n  auto other_sizes = other.sym_sizes();\n  auto other_strides = other.sym_strides();\n  auto other_storage_offset = other.storage_offset();\n  auto other_storage_numel = other.storage().sym_nbytes() / other.itemsize();\n\n  if (self_num_batch_dims == 0) {\n    auto new_tensor = at::zeros_symint({other_storage_numel}, other.options());\n    return new_tensor.as_strided_symint(other_sizes, other_strides, other_storage_offset);\n  }\n\n  auto self_sizes = self.sym_sizes();\n\n  // NB: We don't check that the sizes of self is the same as that of other\n  //     because this function is also used in the inplace over view case\n  //     In the inplace over view case we cannot rely on self and other being\n  //     the same size. So we will use the size of other, and simply tack on\n  //     the batch dims from self. For example: If self.sizes: [B, 2, 3],\n  //     and other.size: [6], we return [B, 6].\n  //     Also see the test test_inplace_on_view_not_same_layout, for when we reach\n  //     this case.\n  constexpr int64_t kSmallBufferSizeHint = 8;\n\n  auto out_sizes = c10::SmallVector<c10::SymInt, kSmallBufferSizeHint>(other.dim() + self_num_batch_dims);\n  std::copy(self_sizes.begin(), self_sizes.begin() + self_num_batch_dims, out_sizes.begin());\n  std::copy(other_sizes.begin(), other_sizes.end(), out_sizes.begin() + self_num_batch_dims);\n\n  // We use the strides of other, and tack on the strides computed with\n  // the batch dims of self, so that the slices are arranged contiguously\n  auto out_strides = c10::SmallVector<c10::SymInt, kSmallBufferSizeHint>(other.dim() + self_num_batch_dims);\n  auto prod = other_storage_numel;\n\n  for (int64_t i = self_num_batch_dims - 1; i >= 0; --i) {\n    out_strides[i] = prod;\n    prod *= self_sizes[i];\n  }\n  std::copy(other_strides.begin(), other_strides.end(), out_strides.begin() + self_num_batch_dims);\n\n  auto storage_numel = prod;\n\n  // Inherit the TensorOptions of the primal\n  auto new_tensor = at::zeros_symint({storage_numel}, other.options());\n  return new_tensor.as_strided_symint(out_sizes, out_strides, other_storage_offset);\n}\n"
    }
  },
  "torch.not_equal": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.sort": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "sort",
      "file": "aten/src/ATen/native/NamedTensor.cpp",
      "start_line": 383,
      "end_line": 385,
      "code": "std::tuple<Tensor, Tensor> sort(const Tensor& self, std::optional<bool> stable, Dimname dim, bool keepdim) {\n  reportNYIDimnameOverload(\"sort\");\n}\n"
    }
  },
  "torch.topk": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "topk_quantized_cpu",
      "file": "aten/src/ATen/native/quantized/cpu/Sorting.cpp",
      "start_line": 45,
      "end_line": 63,
      "code": "std::tuple<Tensor, Tensor> topk_quantized_cpu(\n    const Tensor& self,\n    int64_t k,\n    int64_t dim,\n    bool largest,\n    bool sorted) {\n  auto qscheme = self.qscheme();\n  TORCH_CHECK(\n      qscheme == QScheme::PER_TENSOR_AFFINE ||\n          qscheme == QScheme::PER_TENSOR_SYMMETRIC,\n      \"Top-K is only supported on per-tensor quantization\");\n  Tensor values = at::_empty_affine_quantized(\n    {0},\n    self.options(),\n    self.q_scale(),\n    self.q_zero_point());\n  Tensor indices = at::empty({0}, self.options().dtype(kLong));\n  return quantized_topk_out_cpu(values, indices, self, k, dim, largest, sorted);\n}\n"
    }
  },
  "torch.msort": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.stft": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 537,
      "end_line": 713,
      "code": "def stft(\n    input: Tensor,\n    n_fft: int,\n    hop_length: Optional[int] = None,\n    win_length: Optional[int] = None,\n    window: Optional[Tensor] = None,\n    center: bool = True,\n    pad_mode: str = \"reflect\",\n    normalized: bool = False,\n    onesided: Optional[bool] = None,\n    return_complex: Optional[bool] = None,\n) -> Tensor:\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            stft,\n            (input,),\n            input,\n            n_fft,\n            hop_length=hop_length,\n            win_length=win_length,\n            window=window,\n            center=center,\n            pad_mode=pad_mode,\n            normalized=normalized,\n            onesided=onesided,\n            return_complex=return_complex,\n        )\n    # NOTE: Do not edit. This code will be removed once the forward-compatibility\n    #       period is over for PR #73432\n    if center:\n        signal_dim = input.dim()\n        extended_shape = [1] * (3 - signal_dim) + list(input.size())\n        pad = int(n_fft // 2)\n        input = F.pad(input.view(extended_shape), [pad, pad], pad_mode)\n        input = input.view(input.shape[-signal_dim:])\n    return _VF.stft(  # type: ignore[attr-defined]\n        input,\n        n_fft,\n        hop_length,\n        win_length,\n        window,\n        normalized,\n        onesided,\n        return_complex,\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.istft": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.bartlett_window": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "bartlett_window",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1429,
      "end_line": 1436,
      "code": "Tensor bartlett_window(int64_t window_length,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  return native::bartlett_window(\n      window_length, /*periodic=*/true, dtype, layout, device, pin_memory);\n}\n"
    }
  },
  "torch.blackman_window": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "blackman_window",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1468,
      "end_line": 1475,
      "code": "Tensor blackman_window(int64_t window_length,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  return native::blackman_window(\n      window_length, /*periodic=*/true, dtype, layout, device, pin_memory);\n}\n"
    }
  },
  "torch.hamming_window": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "hamming_window",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1508,
      "end_line": 1515,
      "code": "Tensor hamming_window(int64_t window_length,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  return native::hamming_window(\n      window_length, /*periodic=*/true, dtype, layout, device, pin_memory);\n}\n"
    }
  },
  "torch.hann_window": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "hann_window",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1576,
      "end_line": 1582,
      "code": "Tensor hann_window(int64_t window_length,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  return native::hann_window(window_length, /*periodic=*/true, dtype, layout, device, pin_memory);\n}\n"
    }
  },
  "torch.kaiser_window": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "kaiser_window",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1601,
      "end_line": 1614,
      "code": "Tensor kaiser_window(int64_t window_length,\n    std::optional<ScalarType> dtype,\n    std::optional<Layout> layout,\n    std::optional<Device> device,\n    std::optional<bool> pin_memory) {\n  return native::kaiser_window(\n      window_length,\n      /*periodic=*/true,\n      /*beta=*/12.0,\n      dtype,\n      layout,\n      device,\n      pin_memory);\n}\n"
    }
  },
  "torch.atleast_1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 1487,
      "end_line": 1520,
      "code": "def atleast_1d(*tensors):\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(atleast_1d, tensors, *tensors)\n    if len(tensors) == 1:\n        tensors = tensors[0]\n    return _VF.atleast_1d(tensors)  # type: ignore[attr-defined]\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.atleast_2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 1523,
      "end_line": 1558,
      "code": "def atleast_2d(*tensors):\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(atleast_2d, tensors, *tensors)\n    if len(tensors) == 1:\n        tensors = tensors[0]\n    return _VF.atleast_2d(tensors)  # type: ignore[attr-defined]\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.atleast_3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 1561,
      "end_line": 1604,
      "code": "def atleast_3d(*tensors):\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(atleast_3d, tensors, *tensors)\n    if len(tensors) == 1:\n        tensors = tensors[0]\n    return _VF.atleast_3d(tensors)  # type: ignore[attr-defined]\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.bincount": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "_bincount_cpu",
      "file": "aten/src/ATen/native/SummaryOps.cpp",
      "start_line": 70,
      "end_line": 83,
      "code": "Tensor\n_bincount_cpu(const Tensor& self, const std::optional<Tensor>& weights_opt, int64_t minlength) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> weights_maybe_owned = at::borrow_from_optional_tensor(weights_opt);\n  const Tensor& weights = *weights_maybe_owned;\n\n  return AT_DISPATCH_INTEGRAL_TYPES(self.scalar_type(), \"bincount_cpu\", [&] {\n    const auto scalar = weights.scalar_type();\n    if (scalar == ScalarType::Undefined || scalar == ScalarType::Float)\n      return _bincount_cpu_template<scalar_t, float>(self.contiguous(), weights.contiguous(), minlength);\n    return _bincount_cpu_template<scalar_t, double>(\n        self.contiguous(), weights.contiguous().to(kDouble), minlength);\n  });\n}\n"
    }
  },
  "torch.block_diag": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 1395,
      "end_line": 1428,
      "code": "def block_diag(*tensors):\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(block_diag, tensors, *tensors)\n    return torch._C._VariableFunctions.block_diag(tensors)  # type: ignore[attr-defined]\n"
    },
    "cpp": {
      "function": "block_diag",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 862,
      "end_line": 935,
      "code": "Tensor block_diag(TensorList tensors) {\n  Tensor result;\n  if (tensors.empty()) {\n    result = at::empty({1, 0});\n    return result;\n  }\n\n  const Device& device = tensors[0].device();\n  for (const auto tensor_idx : c10::irange(tensors.size())) {\n    const Tensor& tensor = tensors[tensor_idx];\n\n    TORCH_CHECK(\n      tensor.device() == device,\n      \"torch.block_diag: input tensors must all be on the same device.\",\n      \" Input 0 is on device \", device,\n      \" and input \", tensor_idx, \" is on device \", tensor.device()\n    );\n  }\n\n  ScalarType output_scalar_type = native::result_type(tensors);\n  int64_t result_dim0 = 0;\n  int64_t result_dim1 = 0;\n  std::vector<Tensor> tensors_2D(tensors.size());\n\n  // Sum the dimensions of the tensors, check tensor sizes,\n  // and expand all 0-D and 1-D tensors so that everything\n  // is 2-D\n  for (const auto tensor_idx : c10::irange(tensors.size())) {\n    const Tensor& tensor = tensors[tensor_idx];\n    int64_t ndims = tensor.dim();\n    TORCH_CHECK(\n      ndims <= 2,\n      \"torch.block_diag: Input tensors must have 2 or fewer dimensions. Input \",\n      tensor_idx, \" has \", ndims, \" dimensions\"\n    );\n\n    int64_t dim0 = 1;\n    int64_t dim1 = 1;\n\n    if (ndims == 2) {\n      dim0 = tensor.size(0);\n      dim1 = tensor.size(1);\n      tensors_2D[tensor_idx] = tensor;\n    } else if (ndims == 1) {\n      // Switching dim 0 to dim 1 is intentional\n      dim1 = tensor.size(0);\n      tensors_2D[tensor_idx] = tensor.expand({dim0, dim1});\n    } else {\n      tensors_2D[tensor_idx] = tensor.expand({dim0, dim1});\n    }\n    result_dim0 += dim0;\n    result_dim1 += dim1;\n  }\n\n  result = at::zeros(\n    {result_dim0, result_dim1},\n    tensors[0].options().dtype(output_scalar_type)\n  );\n\n  int64_t cur_dim0 = 0;\n  int64_t cur_dim1 = 0;\n\n  // Copy each tensor into the appropriate location in the result matrix\n  for (const auto& tensor : tensors_2D) {\n    int64_t dim0 = tensor.size(0);\n    int64_t dim1 = tensor.size(1);\n    result.slice(0, cur_dim0, cur_dim0+dim0).slice(1, cur_dim1, cur_dim1+dim1).copy_(tensor);\n\n    cur_dim0 += dim0;\n    cur_dim1 += dim1;\n  }\n\n  return result;\n}\n"
    }
  },
  "torch.broadcast_tensors": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 47,
      "end_line": 76,
      "code": "def broadcast_tensors(*tensors):\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(broadcast_tensors, tensors, *tensors)\n    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.broadcast_to": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "broadcast_to_symint",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 554,
      "end_line": 556,
      "code": "Tensor broadcast_to_symint(const Tensor& self, SymIntArrayRef size) {\n  return self.expand_symint(size);\n}\n"
    }
  },
  "torch.broadcast_shapes": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 79,
      "end_line": 152,
      "code": "def broadcast_shapes(*shapes):\n    # This wrapper exists to support variadic args.\n    # TODO Move this to C++ once the jit has better support for torch.Size.\n    if not torch.jit.is_tracing():\n        max_len = 0\n        for shape in shapes:\n            if isinstance(shape, (int, torch.SymInt)):\n                if max_len < 1:\n                    max_len = 1\n            elif isinstance(shape, (tuple, list)):\n                s = len(shape)\n                if max_len < s:\n                    max_len = s\n        result = [1] * max_len\n\n        from torch.fx.experimental.symbolic_shapes import guard_size_oblivious\n\n        for shape in shapes:\n            if isinstance(shape, (int, torch.SymInt)):\n                shape = (shape,)\n            if isinstance(shape, (tuple, list)):\n                for i in range(-1, -1 - len(shape), -1):\n                    if shape[i] < 0:\n                        raise RuntimeError(\n                            f\"Trying to create tensor with negative dimension ({shape[i]}): ({shape[i]})\"\n                        )\n                    # NB: result is initialized to 1 so this is effectively an\n                    # equals one test\n                    if guard_size_oblivious(shape[i] == 1) or guard_size_oblivious(\n                        shape[i] == result[i]\n                    ):\n                        continue\n                    if result[i] != 1:\n                        raise RuntimeError(\n                            \"Shape mismatch: objects cannot be broadcast to a single shape\"\n                        )\n                    result[i] = shape[i]\n            else:\n                raise RuntimeError(\n                    \"Input shapes should be of type ints, a tuple of ints, or a list of ints, got \",\n                    shape,\n                )\n        return torch.Size(result)\n    else:\n        # with implementation above, torch.jit.trace hardcodes the sizes which makes subsequent replays fail\n        with torch.no_grad():\n            scalar = torch.zeros((), device=\"cpu\")\n            tensors = [scalar.expand(shape) for shape in shapes]\n            tensors = broadcast_tensors(*tensors)\n            return tensors[0].shape\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.bucketize": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "bucketize_cpu",
      "file": "aten/src/ATen/native/Bucketization.cpp",
      "start_line": 234,
      "end_line": 240,
      "code": "Tensor bucketize_cpu(const Tensor& self, const Tensor& boundaries, bool out_int32, bool right) {\n  ScalarType scalar_type = out_int32 ? ScalarType::Int : ScalarType::Long;\n  c10::TensorOptions options = TensorOptions().device(self.options().device()).dtype(scalar_type);\n  Tensor result = at::empty({0}, options, MemoryFormat::Contiguous);\n  at::native::bucketize_out_cpu(self, boundaries, out_int32, right, result);\n  return result;\n}\n"
    }
  },
  "torch.cartesian_prod": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 1360,
      "end_line": 1392,
      "code": "def cartesian_prod(*tensors: Tensor) -> Tensor:\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(cartesian_prod, tensors, *tensors)\n    return _VF.cartesian_prod(tensors)  # type: ignore[attr-defined]\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.cdist": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 1431,
      "end_line": 1484,
      "code": "def cdist(x1, x2, p=2.0, compute_mode=\"use_mm_for_euclid_dist_if_necessary\"):\n    # type: (Tensor, Tensor, float, str) -> (Tensor)\n    if has_torch_function_variadic(x1, x2):\n        return handle_torch_function(\n            cdist, (x1, x2), x1, x2, p=p, compute_mode=compute_mode\n        )\n    if compute_mode == \"use_mm_for_euclid_dist_if_necessary\":\n        return _VF.cdist(x1, x2, p, None)  # type: ignore[attr-defined]\n    elif compute_mode == \"use_mm_for_euclid_dist\":\n        return _VF.cdist(x1, x2, p, 1)  # type: ignore[attr-defined]\n    elif compute_mode == \"donot_use_mm_for_euclid_dist\":\n        return _VF.cdist(x1, x2, p, 2)  # type: ignore[attr-defined]\n    else:\n        raise ValueError(f\"{compute_mode} is not a valid value for compute_mode\")\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.clone": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "clone",
      "file": "aten/src/ATen/CPUGeneratorImpl.cpp",
      "start_line": 336,
      "end_line": 338,
      "code": "std::shared_ptr<CPUGeneratorImpl> CPUGeneratorImpl::clone() const {\n  return std::shared_ptr<CPUGeneratorImpl>(this->clone_impl());\n}\n"
    }
  },
  "torch.combinations": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.cross": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "binary_cross_entropy_cpu",
      "file": "aten/src/ATen/native/Loss.cpp",
      "start_line": 253,
      "end_line": 261,
      "code": "Tensor binary_cross_entropy_cpu(const Tensor& input, const Tensor& target, const std::optional<Tensor>& weight_opt, int64_t reduction) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> weight_maybe_owned = at::borrow_from_optional_tensor(weight_opt);\n  const Tensor& weight = *weight_maybe_owned;\n\n    Tensor loss = at::empty_like(input);\n    return at::native::binary_cross_entropy_out_cpu(\n        input, target, weight, reduction, loss);\n}\n"
    }
  },
  "torch.cummax": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "cummax",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 816,
      "end_line": 821,
      "code": "std::tuple<Tensor, Tensor> cummax(const Tensor& self, int64_t dim) {\n  auto values = at::empty(self.sizes(), self.options());\n  auto indices = at::empty(self.sizes(), self.options().dtype(at::kLong));\n  at::cummax_out(values, indices, self, dim);\n  return std::make_tuple(values, indices);\n}\n"
    }
  },
  "torch.cummin": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "cummin",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 851,
      "end_line": 856,
      "code": "std::tuple<Tensor, Tensor> cummin(const Tensor& self, int64_t dim) {\n  auto values = at::empty(self.sizes(), self.options());\n  auto indices = at::empty(self.sizes(), self.options().dtype(at::kLong));\n  at::cummin_out(values, indices, self, dim);\n  return std::make_tuple(values, indices);\n}\n"
    }
  },
  "torch.cumprod": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "cumprod_out",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 499,
      "end_line": 505,
      "code": "TORCH_IMPL_FUNC(cumprod_out)\n(const Tensor& self,\n int64_t dim,\n std::optional<ScalarType> dtype,\n const Tensor& result) {\n  impl_func_cum_ops(self, dim, result, cumprod_stub);\n}\n"
    }
  },
  "torch.cumsum": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "cumsum_out",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 491,
      "end_line": 497,
      "code": "TORCH_IMPL_FUNC(cumsum_out)\n(const Tensor& self,\n int64_t dim,\n std::optional<ScalarType> dtype,\n const Tensor& result) {\n  impl_func_cum_ops(self, dim, result, cumsum_stub);\n}\n"
    }
  },
  "torch.diag": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "block_diag",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 862,
      "end_line": 935,
      "code": "Tensor block_diag(TensorList tensors) {\n  Tensor result;\n  if (tensors.empty()) {\n    result = at::empty({1, 0});\n    return result;\n  }\n\n  const Device& device = tensors[0].device();\n  for (const auto tensor_idx : c10::irange(tensors.size())) {\n    const Tensor& tensor = tensors[tensor_idx];\n\n    TORCH_CHECK(\n      tensor.device() == device,\n      \"torch.block_diag: input tensors must all be on the same device.\",\n      \" Input 0 is on device \", device,\n      \" and input \", tensor_idx, \" is on device \", tensor.device()\n    );\n  }\n\n  ScalarType output_scalar_type = native::result_type(tensors);\n  int64_t result_dim0 = 0;\n  int64_t result_dim1 = 0;\n  std::vector<Tensor> tensors_2D(tensors.size());\n\n  // Sum the dimensions of the tensors, check tensor sizes,\n  // and expand all 0-D and 1-D tensors so that everything\n  // is 2-D\n  for (const auto tensor_idx : c10::irange(tensors.size())) {\n    const Tensor& tensor = tensors[tensor_idx];\n    int64_t ndims = tensor.dim();\n    TORCH_CHECK(\n      ndims <= 2,\n      \"torch.block_diag: Input tensors must have 2 or fewer dimensions. Input \",\n      tensor_idx, \" has \", ndims, \" dimensions\"\n    );\n\n    int64_t dim0 = 1;\n    int64_t dim1 = 1;\n\n    if (ndims == 2) {\n      dim0 = tensor.size(0);\n      dim1 = tensor.size(1);\n      tensors_2D[tensor_idx] = tensor;\n    } else if (ndims == 1) {\n      // Switching dim 0 to dim 1 is intentional\n      dim1 = tensor.size(0);\n      tensors_2D[tensor_idx] = tensor.expand({dim0, dim1});\n    } else {\n      tensors_2D[tensor_idx] = tensor.expand({dim0, dim1});\n    }\n    result_dim0 += dim0;\n    result_dim1 += dim1;\n  }\n\n  result = at::zeros(\n    {result_dim0, result_dim1},\n    tensors[0].options().dtype(output_scalar_type)\n  );\n\n  int64_t cur_dim0 = 0;\n  int64_t cur_dim1 = 0;\n\n  // Copy each tensor into the appropriate location in the result matrix\n  for (const auto& tensor : tensors_2D) {\n    int64_t dim0 = tensor.size(0);\n    int64_t dim1 = tensor.size(1);\n    result.slice(0, cur_dim0, cur_dim0+dim0).slice(1, cur_dim1, cur_dim1+dim1).copy_(tensor);\n\n    cur_dim0 += dim0;\n    cur_dim1 += dim1;\n  }\n\n  return result;\n}\n"
    }
  },
  "torch.diag_embed": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "diag_embed",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 1122,
      "end_line": 1136,
      "code": "Tensor diag_embed(const Tensor& self, int64_t offset, int64_t dim1_, int64_t dim2_) {\n  int64_t nDims = self.dim() + 1;\n  int64_t dim1 = maybe_wrap_dim(dim1_, nDims);\n  int64_t dim2 = maybe_wrap_dim(dim2_, nDims);\n  TORCH_CHECK(dim1 != dim2, \"diagonal dimensions cannot be identical \", dim1_, \", \", dim2_);\n  int64_t new_dim_len = std::abs(offset) + self.size(-1);\n  auto sizes = self.sizes().vec();\n  sizes.pop_back();\n  sizes.insert(sizes.begin() + std::min(dim1, dim2), new_dim_len);\n  sizes.insert(sizes.begin() + std::max(dim1, dim2), new_dim_len);\n  auto result = at::zeros(sizes, self.options());\n  auto diag = result.diagonal(offset, dim1, dim2);\n  diag.copy_(self);\n  return result;\n}\n"
    }
  },
  "torch.diagflat": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.diagonal": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "diagonal",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 1054,
      "end_line": 1106,
      "code": "Tensor diagonal(const Tensor& self, int64_t offset, int64_t dim1_, int64_t dim2_) {\n  int64_t nDims = self.dim();\n  int64_t dim1 = maybe_wrap_dim(dim1_, nDims);\n  int64_t dim2 = maybe_wrap_dim(dim2_, nDims);\n  TORCH_CHECK(dim1 != dim2, \"diagonal dimensions cannot be identical \", dim1_, \", \", dim2_);\n  auto outnames = namedinference::compute_diagonal_outnames(self, dim1, dim2);\n  NoNamesGuard no_names_guard;\n\n  // NOLINTNEXTLINE(cppcoreguidelines-init-variables)\n  int64_t diag_size;\n  int64_t storage_offset = self.storage_offset();\n  // compute storage offset and size for the diagonal\n  // for positive values of offset (above the main diagonal)\n  // \"leftmost columns\" (along dim2) are dropped\n  // for negative values of offset (below the main diagonal)\n  // \"topmost rows\" (along dim1) are dropped.\n  // Note that we invert +/- in the second to absorb the negative\n  // sign in the offset.\n  if (offset >= 0) {\n    diag_size = std::max<int64_t>(std::min(self.size(dim1), self.size(dim2)-offset), 0);\n  } else {\n    diag_size = std::max<int64_t>(std::min(self.size(dim1)+offset, self.size(dim2)), 0);\n  }\n\n  // NumPy allows you to specify offsets \"off the end\"; let's just be careful not to\n  // set a ridiculous storage_offset in that case (technically it shouldn't matter\n  // because there are no elements in the tensor, but let's be kosher).\n  if (diag_size == 0) {\n    // skip\n  } else if (offset >= 0) {\n    storage_offset += offset * self.stride(dim2);\n  } else {\n    storage_offset -= offset * self.stride(dim1);\n  }\n\n  // construct new size and stride: we drop dim1 and dim2 (maximum first for not changing the index of the minimum)\n  // the new (\"joint\") dimension is appended to the end of the shape / stride to match numpy semantics\n  DimVector sizes(self.sizes().begin(), self.sizes().end());\n  DimVector strides(self.strides().begin(), self.strides().end());\n  sizes.erase(sizes.begin() + std::max(dim1, dim2));\n  strides.erase(strides.begin() + std::max(dim1, dim2));\n  sizes.erase(sizes.begin() + std::min(dim1, dim2));\n  strides.erase(strides.begin() + std::min(dim1, dim2));\n  sizes.push_back(diag_size);\n  strides.push_back(self.stride(dim1)+self.stride(dim2));\n\n  // return view with new parameters\n  auto result = self.as_strided(sizes, strides, storage_offset);\n\n  no_names_guard.reset();\n  namedinference::propagate_names_if_nonempty(result, outnames);\n  return result;\n}\n"
    }
  },
  "torch.diff": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.einsum": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 210,
      "end_line": 412,
      "code": "def einsum(*args: Any) -> Tensor:\n    import torch.backends.opt_einsum as opt_einsum\n\n    # This wrapper exists to support variadic args.\n    if len(args) < 2:\n        raise ValueError(\n            \"einsum(): must specify the equation string and at least one operand, \"\n            \"or at least one operand and its subscripts list\"\n        )\n\n    equation = None\n    operands = None\n\n    if isinstance(args[0], torch.Tensor):\n        # Convert the subscript list format which is an interleaving of operand and its subscripts\n        # list with an optional output subscripts list at the end (see documentation for more details on this)\n        # to the equation string format by creating the equation string from the subscripts list and grouping the\n        # input operands into a tensorlist (List[Tensor]).\n        def parse_subscript(n: int) -> str:\n            if n == Ellipsis:\n                return \"...\"\n            if n >= 0 and n < 26:\n                return chr(ord(\"A\") + n)\n            if n >= 26 and n < 52:\n                return chr(ord(\"a\") + n - 26)\n            raise ValueError(\n                \"einsum(): subscript in subscript list is not within the valid range [0, 52)\"\n            )\n\n        # Parse subscripts for input operands\n        equation = \",\".join(\"\".join(parse_subscript(s) for s in l) for l in args[1::2])\n\n        # Parse optional output subscripts (provided when the number of arguments is odd)\n        if len(args) % 2 == 1:\n            equation += \"->\" + \"\".join(parse_subscript(s) for s in args[-1])\n            operands = args[:-1:2]\n        else:\n            operands = args[::2]\n    else:\n        equation = args[0]\n        operands = args[1:]\n\n    if has_torch_function(operands):\n        return handle_torch_function(einsum, operands, equation, *operands)\n\n    if len(operands) == 1 and isinstance(operands[0], (list, tuple)):\n        # the old interface of passing the operands as one list argument\n        _operands = operands[0]\n        # recurse incase operands contains value that has torch function\n        # in the original implementation this line is omitted\n        return einsum(equation, *_operands)\n\n    if len(operands) <= 2 or not opt_einsum.enabled:\n        # the path for contracting 0 or 1 time(s) is already optimized\n        # or the user has disabled using opt_einsum\n        return _VF.einsum(equation, operands)  # type: ignore[attr-defined]\n\n    path = None\n    if opt_einsum.is_available():\n        _opt_einsum = opt_einsum.get_opt_einsum()\n        tupled_path = _opt_einsum.contract_path(\n            equation, *operands, optimize=opt_einsum.strategy\n        )[0]\n        # flatten path for dispatching to C++\n        path = [item for pair in tupled_path for item in pair]\n    return _VF.einsum(equation, operands, path=path)  # type: ignore[attr-defined]\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.flatten": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.flip": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "flip",
      "file": "aten/src/ATen/native/TensorTransformations.cpp",
      "start_line": 36,
      "end_line": 100,
      "code": "Tensor flip(const Tensor& self, IntArrayRef dims) {\n  const int64_t total_dims = self.dim();\n  // It wraps the dims and checks that there are no repeated dims\n  auto flip_dims_b = at::dim_list_to_bitset(dims, total_dims);\n\n  Tensor out_tensor = at::empty_like(self, MemoryFormat::Preserve);\n\n  // Count dimensions in which we need to do work\n  int n = 0;\n  auto strides = DimVector(self.strides());\n  for (const auto i : c10::irange(total_dims)) {\n    if(flip_dims_b[i] && self.size(i) > 1 && self.stride(i) != 0) {\n      n++;\n      strides[i] = 0;\n    }\n  }\n\n  // Nothing to do, we return fast\n  if (n == 0 || self.numel() <=1) {\n    out_tensor.copy_(self);\n    return out_tensor;\n  }\n\n  //create dummy output with 0 strides at flipped dimension, to prevent tensorIterator from coalescing flipped dims\n  const auto restrided_self = self.as_strided(self.sizes(), strides);\n  auto iter = TensorIteratorConfig()\n    .set_check_mem_overlap(false)\n    .check_all_same_dtype(false)\n    .declare_static_dtype_and_device(self.scalar_type(), self.device())\n    .add_output(out_tensor)\n    .add_const_input(self)\n    .add_const_input(restrided_self)\n    .build();\n\n  auto* data = reinterpret_cast<char*>(iter.data_ptr(0));\n  const auto sizes = iter.shape();\n  // This is a SmallVector of _signed_ ints\n  auto strides_bytes = DimVector(iter.strides(0));\n  const auto strides_self = iter.strides(1);\n  const auto strides_dummy = iter.strides(2);\n\n  // To understand this transformation, think of a 3D cube.\n  //   - The data ptr points to the lower-left most vertex of the cube\n  //   - The strides tell us how to move in each dimension,\n  //     that is, data + stride[i] advances one element in the dimension i\n  // To flip a dimension:\n  //   - We move the pointer to the opposite vertex of the cube\n  //   - We iterate in the opposite direction (invert the strides)\n\n  for (const auto i : c10::irange(iter.ndim())) {\n    // We know that an dimension has a zero stride and self[i] does not, as we defined above\n    // Note that it may be the case that strides_dummy[i] = 0 not because we set it, but because\n    // strides_self[i] == 0. We do not want to do anything there\n    if (strides_dummy[i] == 0 && strides_self[i] != 0) {\n      data += strides_bytes[i] * (sizes[i]-1);\n      strides_bytes[i] *= -1;\n    }\n  }\n  iter._unsafe_set_arg_strides(0, strides_bytes);\n  iter._unsafe_set_arg_data(0, reinterpret_cast<void*>(data));\n\n  flip_stub(iter.device_type(), iter, self.is_quantized());\n\n  return out_tensor;\n}\n"
    }
  },
  "torch.fliplr": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.flipud": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.kron": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.rot90": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "rot90",
      "file": "aten/src/ATen/native/TensorTransformations.cpp",
      "start_line": 123,
      "end_line": 156,
      "code": "Tensor rot90(const Tensor& self, int64_t k, IntArrayRef dims) {\n  const int64_t total_dims = self.dim(), total_rot_dims = dims.size();\n\n  TORCH_CHECK(total_rot_dims == 2,\n    \"expected total rotation dims == 2, but got dims = \", total_rot_dims);\n\n  TORCH_CHECK(total_dims >= 2,\n    \"expected total dims >= 2, but got total dims = \", total_dims);\n\n  TORCH_CHECK(dims[0] != dims[1] && std::abs(dims[0] - dims[1]) != total_dims,\n    \"expected rotation dims to be different, but got dim0 = \", dims[0],\n    \" and dim1 = \", dims[1]);\n\n  // check range of dims\n  TORCH_CHECK(dims[0] < total_dims && dims[0] >= -total_dims,\n    \"Rotation dim0 out of range, dim0 = \", dims[0]);\n\n  TORCH_CHECK(dims[1] < total_dims && dims[1] >= -total_dims,\n    \"Rotation dim1 out of range, dim1 = \", dims[1]);\n\n  // handle modulo with negative k\n  k = (4 + (k % 4)) % 4;\n\n  switch(k) {\n    case 1:\n      return self.flip({dims[1]}).transpose_(dims[0], dims[1]);\n    case 2:\n      return self.flip(dims);\n    case 3:\n      return self.flip({dims[0]}).transpose_(dims[0], dims[1]);\n    default:\n      return self.clone(at::MemoryFormat::Contiguous);\n  }\n}\n"
    }
  },
  "torch.gcd": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "gcd_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 545,
      "end_line": 545,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(gcd_out, gcd_stub);\n"
    }
  },
  "torch.histc": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "histogram_histc",
      "file": "aten/src/ATen/native/Histogram.cpp",
      "start_line": 410,
      "end_line": 414,
      "code": "Tensor histogram_histc(const Tensor& self, int64_t bin_ct,\n        const Scalar& min, const Scalar& max) {\n    Tensor hist = at::empty({0}, self.options(), MemoryFormat::Contiguous);\n    return histogram_histc_out(self, bin_ct, min, max, hist);\n}\n"
    }
  },
  "torch.meshgrid": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 425,
      "end_line": 519,
      "code": "def meshgrid(*tensors, indexing: Optional[str] = None) -> Tuple[Tensor, ...]:\n    return _meshgrid(*tensors, indexing=indexing)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.lcm": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "lcm_out",
      "file": "aten/src/ATen/native/BinaryOps.cpp",
      "start_line": 546,
      "end_line": 546,
      "code": "CREATE_BINARY_TORCH_IMPL_FUNC(lcm_out, lcm_stub);\n"
    }
  },
  "torch.logcumsumexp": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "logcumsumexp",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 455,
      "end_line": 462,
      "code": "Tensor logcumsumexp(const Tensor& self, int64_t dim) {\n  auto result = [&]() {\n    NoNamesGuard guard;\n    return at::_logcumsumexp(self, dim);\n  }();\n  namedinference::propagate_names(result, self);\n  return result;\n}\n"
    }
  },
  "torch.ravel": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.renorm": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "renorm_out",
      "file": "aten/src/ATen/native/Normalization.cpp",
      "start_line": 941,
      "end_line": 974,
      "code": "TORCH_IMPL_FUNC(renorm_out)(const Tensor& self, const Scalar& p, int64_t dim,\n                            const Scalar& maxnorm, const Tensor& out) {\n  auto self_sizes = self.sizes();\n  dim = c10::maybe_wrap_dim(dim, self_sizes.size());\n\n  DimVector reduce_dims(self_sizes.size());\n  std::iota(reduce_dims.begin(), reduce_dims.end(), 0);\n  reduce_dims.erase(reduce_dims.begin() + dim);\n\n  // For cuda half, calculate norm in float precision then cast\n  // normalization factor to half\n  auto dtype = self.scalar_type();\n  auto acc_type = at::toAccumulateType(dtype, /*is_cuda=*/true);\n  Tensor norm;\n  if (acc_type != dtype) {\n    norm = at::linalg_vector_norm(self, p.toDouble(), reduce_dims,\n                                  /*keepdim=*/true, /*dtype=*/acc_type);\n  } else {\n    norm = at::linalg_vector_norm(self, p.toDouble(), reduce_dims,\n                                  /*keepdim=*/true);\n  }\n\n  auto factor = (acc_type == c10::toRealValueType(dtype)) ?\n      norm : at::empty(norm.sizes(), self.options());\n  auto iter = TensorIteratorConfig()\n      .add_output(factor)\n      .add_input(norm)\n      .set_check_mem_overlap(false)\n      .cast_common_dtype_to_outputs(true)\n      .build();\n\n  renorm_scale_factor_stub(iter.device_type(), iter, maxnorm.toDouble());\n  at::mul_outf(self, factor, const_cast<Tensor&>(out));\n}\n"
    }
  },
  "torch.repeat_interleave": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "repeat_interleave_cpu",
      "file": "aten/src/ATen/native/Repeat.cpp",
      "start_line": 42,
      "end_line": 52,
      "code": "Tensor repeat_interleave_cpu(\n    const Tensor& repeat,\n    std::optional<int64_t> output_size) {\n  Tensor output;\n  AT_DISPATCH_INDEX_TYPES(repeat.scalar_type(), \"repeat_interleave_cpu\", [&]() {\n    output = repeat_interleave_common<index_t, compute_cpu<index_t>>(\n        repeat, output_size);\n  });\n\n  return output;\n}\n"
    }
  },
  "torch.roll": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "roll",
      "file": "aten/src/ATen/native/TensorTransformations.cpp",
      "start_line": 102,
      "end_line": 121,
      "code": "Tensor roll(const Tensor& self, IntArrayRef shifts, IntArrayRef dims) { // Used by CPU and MPS dispatch.\n  if (dims.size() != 1 || shifts.size() != 1) {\n    return roll_common(self, shifts, dims);\n  }\n  // avoid a div zero error below.\n  if (self.numel() == 0) {\n    return self.clone(at::MemoryFormat::Preserve);\n  }\n  int64_t dim = dims[0];\n  int64_t size = self.size(dim);\n  int64_t start = (size - shifts[0]) % size;\n  // Behavior of % is different in C++ vs Python for negative numbers. This\n  // corrects the difference.\n  if (start < 0) {\n    start = start + size;\n  }\n  auto t0 = self.narrow(dim, start, size-start);\n  auto t1 = self.narrow(dim, 0, start);\n  return at::cat({std::move(t0), std::move(t1)}, dim);\n}\n"
    }
  },
  "torch.searchsorted": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "searchsorted_cpu",
      "file": "aten/src/ATen/native/Bucketization.cpp",
      "start_line": 203,
      "end_line": 215,
      "code": "Tensor searchsorted_cpu(\n      const Tensor& sorted_sequence,\n      const Tensor& self,\n      bool out_int32,\n      bool right,\n      const std::optional<c10::string_view> side_opt,\n      const std::optional<Tensor>& sorter_opt) {\n  ScalarType scalar_type = out_int32 ? ScalarType::Int : ScalarType::Long;\n  c10::TensorOptions options = TensorOptions().device(self.options().device()).dtype(scalar_type);\n  Tensor result = at::empty({0}, options, MemoryFormat::Contiguous);\n  at::native::searchsorted_out_cpu(sorted_sequence, self, out_int32, right, side_opt, sorter_opt, result);\n  return result;\n}\n"
    }
  },
  "torch.tensordot": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 1258,
      "end_line": 1357,
      "code": "def tensordot(  # noqa: F811\n    a,\n    b,\n    dims=2,\n    out: Optional[torch.Tensor] = None,\n):\n    if has_torch_function_variadic(a, b):\n        return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)\n\n    if not isinstance(dims, (tuple, list, torch.Tensor, int, torch.SymInt)):\n        raise RuntimeError(\n            \"tensordot expects dims to be int or \"\n            + \"Tuple[List[int], List[int]] or \"\n            + \"List[List[int]] containing two lists, but got \"\n            + f\"dims={dims}\"\n        )\n\n    dims_a: List[int] = []\n    dims_b: List[int] = []\n\n    if isinstance(dims, (tuple, list)):\n        dims_a, dims_b = dims\n\n    if isinstance(dims, torch.Tensor):\n        num_elements = dims.numel()\n        if num_elements > 1:\n            assert dims.size()[0] == 2\n            dims_a = torch.jit.annotate(List[int], dims[0].tolist())\n            dims_b = torch.jit.annotate(List[int], dims[1].tolist())\n        else:\n            dims_val = int(dims.item())\n            if dims_val < 0:\n                raise RuntimeError(f\"tensordot expects dims >= 0, but got dims={dims}\")\n            dims_a = list(range(-dims_val, 0))\n            dims_b = list(range(dims_val))\n\n    if isinstance(dims, (int, torch.SymInt)):\n        if dims < 0:\n            raise RuntimeError(f\"tensordot expects dims >= 0, but got dims={dims}\")\n        if dims > min(a.dim(), b.dim()):\n            raise RuntimeError(\n                f\"tensordot expects dims < ndim_a or ndim_b, but got dims={dims}\"\n            )\n        dims_a = list(range(-dims, 0))\n        dims_b = list(range(dims))\n\n    if out is None:\n        return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]\n    else:\n        return _VF.tensordot(a, b, dims_a, dims_b, out=out)  # type: ignore[attr-defined]\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.trace": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "trace_cpu",
      "file": "aten/src/ATen/native/ReduceOps.cpp",
      "start_line": 1278,
      "end_line": 1306,
      "code": "Tensor trace_cpu(const Tensor& self) {\n  Tensor result;\n  // Returns the ScalarType of the self tensor if the tensor is non integral type\n  // In the case, self is an integer type tensor, at::kLong is return since promote_integers\n  // is set to true\n  ScalarType dtype = get_dtype_from_self(self, std::nullopt, true);\n  result = at::empty({}, self.options().dtype(dtype));\n  AT_DISPATCH_ALL_TYPES_AND_COMPLEX(self.scalar_type(), \"trace\", [&] {\n    using accscalar_t = at::acc_type<scalar_t, false>;\n    accscalar_t sum = 0;\n    const auto* t_data = self.const_data_ptr<scalar_t>();\n\n    int64_t t_stride_0, t_stride_1, t_diag_size;\n\n    TORCH_CHECK(self.dim() == 2, \"trace: expected a matrix, but got tensor with dim \", self.dim());\n\n    t_stride_0 = self.stride(0);\n    t_stride_1 = self.stride(1);\n\n    t_diag_size = std::min(self.size(0), self.size(1));\n    for (const auto i : c10::irange(t_diag_size)) {\n      sum += t_data[i * (t_stride_0 + t_stride_1)];\n    }\n    set_result<scalar_t>(result, sum);\n\n  });\n\n  return result;\n}\n"
    }
  },
  "torch.tril": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "tril_cpu",
      "file": "aten/src/ATen/native/TriangularOps.cpp",
      "start_line": 175,
      "end_line": 177,
      "code": "TORCH_IMPL_FUNC(tril_cpu)(const Tensor& self, int64_t k, const Tensor &result) {\n  compute_triu_tril<LowerTriangle>(self, k, result);\n}\n"
    }
  },
  "torch.tril_indices": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "tril_indices_cpu",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1179,
      "end_line": 1227,
      "code": "Tensor tril_indices_cpu(\n    int64_t row, int64_t col, int64_t offset, std::optional<ScalarType> dtype_opt,\n    std::optional<Layout> layout_opt, std::optional<Device> device_opt, std::optional<bool> pin_memory_opt) {\n  if (!dtype_opt.has_value()) {\n    dtype_opt = ScalarType::Long;\n  }\n\n  check_args(row, col, layout_opt);\n\n  auto tril_size = get_tril_size(row, col, offset);\n\n  // create an empty Tensor with correct size\n  auto result = at::native::empty_cpu({2, tril_size}, dtype_opt, layout_opt, device_opt, pin_memory_opt);\n\n  // The following three approaches result in very little performance\n  // differences. Hence, the 2nd option is taken for simpler code, and to return\n  // contiguous tensors. Refer to #14904 for more details.\n  //\n  // 1. sequential RAM access: fill row coordinates first, then columns. This\n  //    results in two for-loop and more arithmetic operations.\n  //\n  // 2. interleaved RAM access: fill in index coordinates one by one, which\n  //    jumps between the two output Tensor rows in every iteration.\n  //\n  // 3. sequential RAM + transpose: create an n X 2 Tensor, fill the Tensor\n  //    sequentially, and then transpose it.\n  AT_DISPATCH_INDEX_TYPES(result.scalar_type(), \"tril_indices\", [&]() -> void {\n    // fill the Tensor with correct values\n    index_t* result_data = result.data_ptr<index_t>();\n    int64_t i = 0;\n\n    index_t r = std::max<int64_t>(0, -offset), c = 0;\n    while (i < tril_size) {\n      result_data[i] = r;\n      result_data[tril_size + i++] = c;\n\n      // move to the next column and check if (r, c) is still in bound\n      c += 1;\n      if (c > r + offset || c >= col) {\n        r += 1;\n        c = 0;\n        // NOTE: not necessary to check if r is less than row here, because i\n        // and tril_size provide the guarantee\n      }\n    }\n  });\n\n  return result;\n}\n"
    }
  },
  "torch.triu": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "triu_cpu",
      "file": "aten/src/ATen/native/TriangularOps.cpp",
      "start_line": 179,
      "end_line": 181,
      "code": "TORCH_IMPL_FUNC(triu_cpu)(const Tensor& self, int64_t k, const Tensor &result) {\n  compute_triu_tril<UpperTriangle>(self, k, result);\n}\n"
    }
  },
  "torch.triu_indices": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "triu_indices_cpu",
      "file": "aten/src/ATen/native/TensorFactories.cpp",
      "start_line": 1229,
      "end_line": 1268,
      "code": "Tensor triu_indices_cpu(\n    int64_t row, int64_t col, int64_t offset, std::optional<ScalarType> dtype_opt,\n    std::optional<Layout> layout_opt, std::optional<Device> device_opt, std::optional<bool> pin_memory_opt) {\n  if (!dtype_opt.has_value()) {\n    dtype_opt = ScalarType::Long;\n  }\n\n  check_args(row, col, layout_opt);\n\n  auto triu_size = row * col - get_tril_size(row, col, offset - 1);\n\n  // create an empty Tensor with correct size\n  auto result = at::native::empty_cpu({2, triu_size}, dtype_opt, layout_opt, device_opt, pin_memory_opt);\n\n  AT_DISPATCH_INDEX_TYPES(result.scalar_type(), \"triu_indices\", [&]() -> void {\n    // fill the Tensor with correct values\n    index_t* result_data = result.data_ptr<index_t>();\n    int64_t i = 0;\n    // not typing std::max with scalar_t as it could be an unsigned type\n    // NOTE: no need to check if the returned value of std::max overflows\n    // index_t, as i and triu_size act as a guard.\n    index_t c = std::max<int64_t>(0, offset), r = 0;\n    while (i < triu_size) {\n      result_data[i] = r;\n      result_data[triu_size + i++] = c;\n\n      // move to the next column and check if (r, c) is still in bound\n      c += 1;\n      if (c >= col) {\n        r += 1;\n        // not typing std::max with scalar_t as it could be an unsigned type\n        // NOTE: not necessary to check if c is less than col or overflows here,\n        // because i and triu_size act as a guard.\n        c = std::max<int64_t>(0, r + offset);\n      }\n    }\n  });\n\n  return result;\n}\n"
    }
  },
  "torch.vander": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.view_as_real": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "view_as_real",
      "file": "<empty>",
      "start_line": -1,
      "end_line": -1,
      "code": ""
    }
  },
  "torch.view_as_complex": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "view_as_complex",
      "file": "<empty>",
      "start_line": -1,
      "end_line": -1,
      "code": ""
    }
  },
  "torch.addbmm": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "addbmm",
      "file": "aten/src/ATen/native/LinearAlgebra.cpp",
      "start_line": 1604,
      "end_line": 1607,
      "code": "Tensor addbmm(const Tensor& self, const Tensor& batch1, const Tensor& batch2, const Scalar& beta, const Scalar& alpha) {\n  Tensor result = at::empty({0}, self.options());\n  return native::addbmm_out(self, batch1, batch2, beta, alpha, result);\n}\n"
    }
  },
  "torch.addmm": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "addmm_sparse_dense_cpu",
      "file": "aten/src/ATen/native/sparse/SparseTensorMath.cpp",
      "start_line": 1335,
      "end_line": 1344,
      "code": "Tensor addmm_sparse_dense_cpu(\n    const Tensor& self,\n    const SparseTensor& mat1,\n    const Tensor& mat2,\n    const Scalar& beta,\n    const Scalar& alpha\n) {\n  c10::MaybeOwned<Tensor> b_self = expand_size(self, {mat1.size(0), mat2.size(1)}, \"addmm_out\");\n  return s_addmm_sparse_dense_cpu(*b_self, mat1, mat2, beta, alpha);\n}\n"
    }
  },
  "torch.addmv": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "addmv_out_cpu",
      "file": "aten/src/ATen/native/Blas.cpp",
      "start_line": 59,
      "end_line": 109,
      "code": "TORCH_IMPL_FUNC(addmv_out_cpu)(const Tensor &self, const Tensor &mat, const Tensor &vec, const Scalar& beta_, const Scalar& alpha_, const Tensor& result) {\n  c10::MaybeOwned<Tensor> self_ = expand_size(self, {mat.size(0)});\n  auto betaval = beta_.toComplexDouble();\n  if (mat.numel() == 0) {\n    // shortcut for an empty matrix\n    // By definition, when beta==0, values in self should be ignored. nans and infs\n    // should not propagate\n    if (betaval == 0.0) {\n      result.zero_();\n    } else {\n      at::cpu::mul_out(\n          // NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)\n          const_cast<Tensor&>(result),\n          self,\n          at::native::scalar_tensor(\n              beta_, self.scalar_type(), std::nullopt /* layout */, at::kCPU, std::nullopt /* pin_memory */));\n    }\n  } else {\n    if (!result.is_same(*self_) && betaval != 0.0) { //if beta is 0, result contents is ignored\n      // NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)\n      at::native::copy_(const_cast<Tensor&>(result), *self_);\n    }\n    if (result.numel() != 0) {\n\n      NoNamesGuard guard;\n      if (use_mkldnn_matmul(mat, vec, /*result=*/Tensor())){\n        mkldnn_matmul(mat, vec, result, beta_.to<float>(), alpha_.to<float>());\n        return;\n      }\n\n      auto r_stride = result.stride(0);\n      AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND2(kBFloat16, kHalf, mat.scalar_type(), \"addmv_impl_cpu\", [&] {\n        auto beta = beta_.to<scalar_t>();\n        auto alpha = alpha_.to<scalar_t>();\n        if (mat.stride(0) == 1 && lda_cond(mat.size(0), mat.size(1), mat.stride(1))) {\n          gemv<scalar_t>('n', mat.size(0), mat.size(1), alpha, mat.const_data_ptr<scalar_t>(), mat.stride(1),\n              vec.const_data_ptr<scalar_t>(), vec.stride(0), beta, result.mutable_data_ptr<scalar_t>(), r_stride);\n        }\n        else if (mat.stride(1) == 1 && lda_cond(mat.size(1), mat.size(0), mat.stride(0))) {\n          gemv<scalar_t>('t', mat.size(1), mat.size(0), alpha, mat.const_data_ptr<scalar_t>(), mat.stride(0),\n              vec.const_data_ptr<scalar_t>(), vec.stride(0), beta, result.mutable_data_ptr<scalar_t>(), r_stride);\n        }\n        else {\n          Tensor cmat = mat.contiguous();\n          gemv<scalar_t>('t', mat.size(1), mat.size(0), alpha, cmat.const_data_ptr<scalar_t>(), cmat.stride(0),\n              vec.const_data_ptr<scalar_t>(), vec.stride(0), beta, result.mutable_data_ptr<scalar_t>(), r_stride);\n        }\n      });\n    }\n  }\n}\n"
    }
  },
  "torch.addr": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "addr",
      "file": "aten/src/ATen/native/LinearAlgebra.cpp",
      "start_line": 1194,
      "end_line": 1205,
      "code": "Tensor addr(const Tensor& self,\n            const Tensor& vec1, const Tensor& vec2,\n            const Scalar& beta, const Scalar& alpha) {\n  Tensor result;\n  auto iter = build_addr_iter(result, self, vec1, vec2);\n\n  check_addr_scalar(iter.dtype(), beta, \"beta\");\n  check_addr_scalar(iter.dtype(), alpha, \"alpha\");\n\n  addr_stub(iter.device_type(), iter, beta, alpha);\n  return iter.output();\n}\n"
    }
  },
  "torch.baddbmm": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "baddbmm_out_cpu",
      "file": "aten/src/ATen/native/LinearAlgebra.cpp",
      "start_line": 1874,
      "end_line": 1880,
      "code": "TORCH_IMPL_FUNC(baddbmm_out_cpu)\n(const Tensor & self, const Tensor & batch1, const Tensor & batch2, const Scalar& beta, const Scalar& alpha, const Tensor& result) {\n    bool self_is_conj = result.is_conj();\n    conjugate_mutable_input_if_needed(result, self_is_conj);\n    bmm_out_or_baddbmm_(result, batch1.resolve_conj(), batch2.resolve_conj(), beta, alpha, false);\n    conjugate_mutable_input_if_needed(result, self_is_conj);\n  }\n"
    }
  },
  "torch.bmm": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "bmm_sparse_cpu",
      "file": "aten/src/ATen/native/sparse/SparseTensorMath.cpp",
      "start_line": 1898,
      "end_line": 1901,
      "code": "Tensor bmm_sparse_cpu(const SparseTensor& self, const Tensor& mat2) {\n  Tensor result = at::empty({}, mat2.options());\n  return bmm_out_sparse_cpu(self, mat2, result);\n}\n"
    }
  },
  "torch.chain_matmul": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\functional.py",
      "start_line": 1991,
      "end_line": 2035,
      "code": "def chain_matmul(*matrices, out=None):\n    # This wrapper exists to support variadic args.\n    if has_torch_function(matrices):\n        return handle_torch_function(chain_matmul, matrices, *matrices)\n\n    if out is None:\n        return _VF.chain_matmul(matrices)  # type: ignore[attr-defined]\n    else:\n        return _VF.chain_matmul(matrices, out=out)  # type: ignore[attr-defined]\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.cholesky": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "cholesky",
      "file": "aten/src/ATen/native/BatchLinearAlgebra.cpp",
      "start_line": 1690,
      "end_line": 1723,
      "code": "Tensor cholesky(const Tensor &self, bool upper) {\n   TORCH_WARN_ONCE(\n    \"torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be \",\n    \"removed in a future PyTorch release.\\n\",\n    \"L = torch.cholesky(A)\\n\",\n    \"should be replaced with\\n\",\n    \"L = torch.linalg.cholesky(A)\\n\",\n    \"and\\n\"\n    \"U = torch.cholesky(A, upper=True)\\n\",\n    \"should be replaced with\\n\",\n    \"U = torch.linalg.cholesky(A).mH\\n\"\n    \"This transform will produce equivalent results for all valid (symmetric positive definite) inputs.\"\n  );\n  if (self.numel() == 0) {\n    return at::empty_like(self, LEGACY_CONTIGUOUS_MEMORY_FORMAT);\n  }\n  squareCheckInputs(self, \"cholesky\");\n\n  auto raw_cholesky_output = cloneBatchedColumnMajor(self);\n  auto info_shape = IntArrayRef(\n      self.sizes().cbegin(), self.sizes().cend() - 2); // self.shape[:-2]\n  auto info = at::empty({info_shape}, self.options().dtype(kInt));\n\n  // fill the raw_cholesky_output with the result\n  cholesky_stub(self.device().type(), raw_cholesky_output, info, upper);\n\n  at::_linalg_check_errors(info, \"cholesky\", self.dim() == 2);\n\n  if (upper) {\n    return raw_cholesky_output.triu_();\n  } else {\n    return raw_cholesky_output.tril_();\n  }\n}\n"
    }
  },
  "torch.cholesky_inverse": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "cholesky_inverse",
      "file": "aten/src/ATen/native/BatchLinearAlgebra.cpp",
      "start_line": 1869,
      "end_line": 1873,
      "code": "Tensor cholesky_inverse(const Tensor &input, bool upper) {\n  Tensor result = at::empty({0}, input.options());\n  result = at::cholesky_inverse_out(result, input, upper);\n  return result;\n}\n"
    }
  },
  "torch.cholesky_solve": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "cholesky_solve",
      "file": "aten/src/ATen/native/BatchLinearAlgebra.cpp",
      "start_line": 1668,
      "end_line": 1675,
      "code": "Tensor cholesky_solve(const Tensor& self, const Tensor& A, bool upper) {\n  TORCH_CHECK(self.dim() >= 2,\n           \"b should have at least 2 dimensions, but has \", self.dim(), \" dimensions instead\");\n  TORCH_CHECK(A.dim() >= 2,\n           \"u should have at least 2 dimensions, but has \", A.dim(), \" dimensions instead\");\n  auto [self_broadcasted, A_broadcasted] = _linalg_broadcast_batch_dims(self, A, \"cholesky_solve\");\n  return at::_cholesky_solve_helper(self_broadcasted, A_broadcasted, upper);\n}\n"
    }
  },
  "torch.dot": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "dot",
      "file": "aten/src/ATen/cuda/CUDABlas.cpp",
      "start_line": 1921,
      "end_line": 1923,
      "code": "void dot<double>(CUDABLAS_DOT_ARGTYPES(double)) {\n  TORCH_CUDABLAS_CHECK(cublasDdot(handle, n, x, incx, y, incy, result));\n}\n"
    }
  },
  "torch.geqrf": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "geqrf",
      "file": "aten/src/ATen/native/BatchLinearAlgebra.cpp",
      "start_line": 2344,
      "end_line": 2349,
      "code": "std::tuple<Tensor, Tensor> geqrf(const Tensor& input) {\n  Tensor QR = at::empty({0}, input.options());\n  Tensor tau = at::empty({0}, input.options());\n  std::tie(QR, tau) = at::geqrf_outf(input, QR, tau);\n  return std::make_tuple(std::move(QR), std::move(tau));\n}\n"
    }
  },
  "torch.ger": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.outer": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.inner": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.inverse": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.det": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "detach",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 3761,
      "end_line": 3769,
      "code": "Tensor detach(const Tensor& self) {\n  // NB: detach() is not the same thing as alias()! The main difference is that\n  // detach does not allow metadata change while alias does.\n  return Tensor(self.getIntrusivePtr()->shallow_copy_and_detach(\n    // NB: The ADInplaceOrView logic will overwrite these with the\n    // appropriate values if it runs; otherwise these are the values.\n    /*version_counter=*/0,\n    /*allow_tensor_metadata_change=*/false));\n}\n"
    }
  },
  "torch.logdet": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.slogdet": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.lu": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_jit_internal.py",
      "start_line": 614,
      "end_line": 624,
      "code": "def fn(*args, **kwargs):\n    dispatch_flag = default\n    if arg_name in kwargs:\n        dispatch_flag = kwargs[arg_name]\n    elif arg_index < len(args):\n        dispatch_flag = args[arg_index]\n\n    if dispatch_flag:\n        return if_true(*args, **kwargs)\n    else:\n        return if_false(*args, **kwargs)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.lu_solve": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.lu_unpack": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "lu_unpack_out",
      "file": "aten/src/ATen/native/BatchLinearAlgebra.cpp",
      "start_line": 2043,
      "end_line": 2099,
      "code": "TORCH_IMPL_FUNC(lu_unpack_out)(const Tensor& LU,\n                               const Tensor& pivots,\n                               bool unpack_lu,\n                               bool unpack_pivots,\n                               const Tensor& P,\n                               const Tensor& L,\n                               const Tensor& U) {\n  const auto m = LU.sizes().end()[-2];\n  const auto n = LU.sizes().end()[-1];\n\n  // A.shape[-2:] == (m, n)\n  // P.shape[-2:] == (m, m)\n  // L.shape[-2:] == (m, k)\n  // U.shape[-2:] == (k, n)\n  // with k = min(m, n)\n\n  if (unpack_lu) {\n    if (m > n || LU.is_same(L)) {\n      // The order of triu and tril is important as we may have LU.is_same(L)\n      at::triu_out(const_cast<Tensor&>(U), m == n ? LU : LU.narrow(-2, 0, n), 0);\n      at::tril_out(const_cast<Tensor&>(L), LU, -1);\n      L.diagonal(0, -2, -1).fill_(1.);\n    } else {\n      // The order of triu and tril is important as we may have LU.is_same(U)\n      at::tril_out(const_cast<Tensor&>(L), m == n ? LU : LU.narrow(-1, 0, m), -1);\n      L.diagonal(0, -2, -1).fill_(1.);\n      at::triu_out(const_cast<Tensor&>(U), LU, 0);\n    }\n  }\n  if (unpack_pivots) {\n    // lu_factor_ex returns an int32 1-based indexing, which is what we have in `pivots`\n    // We transform that to a proper permutation of the indices {0, ..., m-1}\n    const auto perm_sizes = IntArrayRef(P.sizes().data(), P.dim() - 1);\n\n    // Fill `perm` with the identity permutation (perhaps batched)\n    const auto perm = at::arange(m, pivots.options().memory_format(at::MemoryFormat::Contiguous).dtype(kLong))\n                        .expand(perm_sizes)\n                        .contiguous();\n\n    // Note that perm is of type kLong and pivots is a 1-indexed kInt.\n    // This is taken into account in the unpack_pivots kernel\n    auto iter = TensorIteratorConfig()\n      .set_check_mem_overlap(false)\n      .check_all_same_dtype(false)\n      .resize_outputs(false)\n      .declare_static_shape(pivots.sizes(), /*squash_dims=*/pivots.dim() - 1)\n      .add_output(perm)\n      .add_owned_const_input(pivots.contiguous())\n      .build();\n\n    unpack_pivots_stub(pivots.device().type(), iter, std::min(m, n), m);\n\n    // Transform the permutation into a permutation matrix\n    P.zero_();\n    P.scatter_(-2, perm.unsqueeze(-2), 1.);\n  }\n}\n"
    }
  },
  "torch.matmul": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "matmul",
      "file": "aten/src/ATen/native/LinearAlgebra.cpp",
      "start_line": 2178,
      "end_line": 2184,
      "code": "Tensor matmul(const Tensor & tensor1, const Tensor & tensor2) {\n  auto maybe_outnames = namedinference::compute_matmul_outnames(tensor1, tensor2);\n  at::Tensor result, unused;\n  result = at::native::_matmul_impl(unused, tensor1, tensor2);\n  namedinference::propagate_names_if_nonempty(result, maybe_outnames);\n  return result;\n}\n"
    }
  },
  "torch.matrix_power": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.matrix_exp": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.mm": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "_sparse_mm",
      "file": "aten/src/ATen/native/sparse/SparseTensorMath.cpp",
      "start_line": 1371,
      "end_line": 1384,
      "code": "Tensor _sparse_mm(\n  const Tensor& mat1,\n  const Tensor& mat2\n) {\n  if (mat1.is_sparse() && mat2.is_sparse()) {\n    return at::_sparse_sparse_matmul(mat1, mat2);\n  }\n  if (mat1.is_sparse() || at::sparse_csr::is_sparse_compressed(mat1)) {\n    Tensor t = at::zeros({mat1.size(-2), mat2.size(-1)}, mat2.options());\n    return at::_sparse_addmm(t, mat1, mat2, 0, 1);\n  }\n  Tensor t = at::zeros({mat1.size(-2), mat2.size(-1)}, mat1.options());\n  return at::_sparse_addmm(t.transpose(-2, -1), mat2.transpose(-2, -1), mat1.transpose(-2, -1), 0, 1).transpose(-2, -1);\n}\n"
    }
  },
  "torch.mv": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "mv",
      "file": "aten/src/ATen/mkl/SparseBlas.cpp",
      "start_line": 120,
      "end_line": 123,
      "code": "void mv<float>(MKL_SPARSE_MV_ARGTYPES(float)) {\n  TORCH_MKLSPARSE_CHECK(\n      mkl_sparse_s_mv(operation, alpha, A, descr, x, beta, y));\n}\n"
    }
  },
  "torch.orgqr": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.ormqr": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "ormqr",
      "file": "aten/src/ATen/native/BatchLinearAlgebra.cpp",
      "start_line": 2717,
      "end_line": 2721,
      "code": "Tensor ormqr(const Tensor& input, const Tensor& tau, const Tensor& other, bool left, bool transpose) {\n  Tensor result = at::empty({0}, input.options());\n  result = at::native::ormqr_out(input, tau, other, left, transpose, result);\n  return result;\n}\n"
    }
  },
  "torch.pinverse": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.qr": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.svd": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.svd_lowrank": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_lowrank.py",
      "start_line": 86,
      "end_line": 147,
      "code": "def svd_lowrank(\n    A: Tensor,\n    q: Optional[int] = 6,\n    niter: Optional[int] = 2,\n    M: Optional[Tensor] = None,\n) -> Tuple[Tensor, Tensor, Tensor]:\n    if not torch.jit.is_scripting():\n        tensor_ops = (A, M)\n        if not set(map(type, tensor_ops)).issubset(\n            (torch.Tensor, type(None))\n        ) and has_torch_function(tensor_ops):\n            return handle_torch_function(\n                svd_lowrank, tensor_ops, A, q=q, niter=niter, M=M\n            )\n    return _svd_lowrank(A, q=q, niter=niter, M=M)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.pca_lowrank": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_lowrank.py",
      "start_line": 184,
      "end_line": 294,
      "code": "def pca_lowrank(\n    A: Tensor,\n    q: Optional[int] = None,\n    center: bool = True,\n    niter: int = 2,\n) -> Tuple[Tensor, Tensor, Tensor]:\n\n    if not torch.jit.is_scripting():\n        if type(A) is not torch.Tensor and has_torch_function((A,)):\n            return handle_torch_function(\n                pca_lowrank, (A,), A, q=q, center=center, niter=niter\n            )\n\n    (m, n) = A.shape[-2:]\n\n    if q is None:\n        q = min(6, m, n)\n    elif not (q >= 0 and q <= min(m, n)):\n        raise ValueError(\n            f\"q(={q}) must be non-negative integer and not greater than min(m, n)={min(m, n)}\"\n        )\n    if not (niter >= 0):\n        raise ValueError(f\"niter(={niter}) must be non-negative integer\")\n\n    dtype = _utils.get_floating_dtype(A)\n\n    if not center:\n        return _svd_lowrank(A, q, niter=niter, M=None)\n\n    if _utils.is_sparse(A):\n        if len(A.shape) != 2:\n            raise ValueError(\"pca_lowrank input is expected to be 2-dimensional tensor\")\n        c = torch.sparse.sum(A, dim=(-2,)) / m\n        # reshape c\n        column_indices = c.indices()[0]\n        indices = torch.zeros(\n            2,\n            len(column_indices),\n            dtype=column_indices.dtype,\n            device=column_indices.device,\n        )\n        indices[0] = column_indices\n        C_t = torch.sparse_coo_tensor(\n            indices, c.values(), (n, 1), dtype=dtype, device=A.device\n        )\n\n        ones_m1_t = torch.ones(A.shape[:-2] + (1, m), dtype=dtype, device=A.device)\n        M = torch.sparse.mm(C_t, ones_m1_t).mT\n        return _svd_lowrank(A, q, niter=niter, M=M)\n    else:\n        C = A.mean(dim=(-2,), keepdim=True)\n        return _svd_lowrank(A - C, q, niter=niter, M=None)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.lobpcg": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\_lobpcg.py",
      "start_line": 345,
      "end_line": 579,
      "code": "def lobpcg(\n    A: Tensor,\n    k: Optional[int] = None,\n    B: Optional[Tensor] = None,\n    X: Optional[Tensor] = None,\n    n: Optional[int] = None,\n    iK: Optional[Tensor] = None,\n    niter: Optional[int] = None,\n    tol: Optional[float] = None,\n    largest: Optional[bool] = None,\n    method: Optional[str] = None,\n    tracker: None = None,\n    ortho_iparams: Optional[Dict[str, int]] = None,\n    ortho_fparams: Optional[Dict[str, float]] = None,\n    ortho_bparams: Optional[Dict[str, bool]] = None,\n) -> Tuple[Tensor, Tensor]:\n\n    if not torch.jit.is_scripting():\n        tensor_ops = (A, B, X, iK)\n        if not set(map(type, tensor_ops)).issubset(\n            (torch.Tensor, type(None))\n        ) and has_torch_function(tensor_ops):\n            return handle_torch_function(\n                lobpcg,\n                tensor_ops,\n                A,\n                k=k,\n                B=B,\n                X=X,\n                n=n,\n                iK=iK,\n                niter=niter,\n                tol=tol,\n                largest=largest,\n                method=method,\n                tracker=tracker,\n                ortho_iparams=ortho_iparams,\n                ortho_fparams=ortho_fparams,\n                ortho_bparams=ortho_bparams,\n            )\n\n    if not torch._jit_internal.is_scripting():\n        if A.requires_grad or (B is not None and B.requires_grad):\n            # While it is expected that `A` is symmetric,\n            # the `A_grad` might be not. Therefore we perform the trick below,\n            # so that `A_grad` becomes symmetric.\n            # The symmetrization is important for first-order optimization methods,\n            # so that (A - alpha * A_grad) is still a symmetric matrix.\n            # Same holds for `B`.\n            A_sym = (A + A.mT) / 2\n            B_sym = (B + B.mT) / 2 if (B is not None) else None\n\n            return LOBPCGAutogradFunction.apply(\n                A_sym,\n                k,\n                B_sym,\n                X,\n                n,\n                iK,\n                niter,\n                tol,\n                largest,\n                method,\n                tracker,\n                ortho_iparams,\n                ortho_fparams,\n                ortho_bparams,\n            )\n    else:\n        if A.requires_grad or (B is not None and B.requires_grad):\n            raise RuntimeError(\n                \"Script and require grads is not supported atm.\"\n                \"If you just want to do the forward, use .detach()\"\n                \"on A and B before calling into lobpcg\"\n            )\n\n    return _lobpcg(\n        A,\n        k,\n        B,\n        X,\n        n,\n        iK,\n        niter,\n        tol,\n        largest,\n        method,\n        tracker,\n        ortho_iparams,\n        ortho_fparams,\n        ortho_bparams,\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.trapz": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.triangular_solve": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "triangular_solve_out",
      "file": "aten/src/ATen/native/BatchLinearAlgebra.cpp",
      "start_line": 2238,
      "end_line": 2255,
      "code": "TORCH_IMPL_FUNC(triangular_solve_out)(const Tensor& self, const Tensor& A, bool upper, bool transpose, bool unitriangular, const Tensor& result, const Tensor& clone_A) {\n  auto [self_broadcast, A_broadcast] = _linalg_broadcast_batch_dims(self, A, \"triangular_solve\");\n\n  bool copy_needed = !result.transpose(-2, -1).is_contiguous();\n  copy_needed |= !clone_A.transpose(-2, -1).is_contiguous();\n\n  if (copy_needed) {\n    Tensor result_tmp = at::empty({0}, self.options());\n    Tensor clone_A_tmp = at::empty({0}, A.options());\n\n    triangular_solve_out_impl(result_tmp, clone_A_tmp, A_broadcast, self_broadcast, upper, transpose, unitriangular);\n\n    result.copy_(result_tmp);\n    clone_A.copy_(clone_A_tmp);\n  } else {\n    triangular_solve_out_impl(result, clone_A, A_broadcast, self_broadcast, upper, transpose, unitriangular);\n  }\n}\n"
    }
  },
  "torch.vdot": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": "vdot",
      "file": "aten/src/ATen/cuda/CUDABlas.cpp",
      "start_line": 1977,
      "end_line": 1981,
      "code": "void vdot<c10::complex<float>>(CUDABLAS_DOT_ARGTYPES(c10::complex<float>)) {\n  TORCH_CUDABLAS_CHECK(cublasCdotc(handle, n, reinterpret_cast<const cuComplex*>(x),\n                                   incx, reinterpret_cast<const cuComplex*>(y), incy,\n                                   reinterpret_cast<cuComplex*>(result)));\n}\n"
    }
  },
  "torch.compiled_with_cxx11_abi": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\__init__.py",
      "start_line": 2112,
      "end_line": 2114,
      "code": "def compiled_with_cxx11_abi() -> builtins.bool:\n    return _C._GLIBCXX_USE_CXX11_ABI\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.result_type": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.can_cast": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.promote_types": {
    "python": {
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.use_deterministic_algorithms": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\__init__.py",
      "start_line": 1200,
      "end_line": 1339,
      "code": "def use_deterministic_algorithms(\n    mode: builtins.bool,\n    *,\n    warn_only: builtins.bool = False,\n) -> None:\n    _C._set_deterministic_algorithms(mode, warn_only=warn_only)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.are_deterministic_algorithms_enabled": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\__init__.py",
      "start_line": 1342,
      "end_line": 1346,
      "code": "def are_deterministic_algorithms_enabled() -> builtins.bool:\n    return _C._get_deterministic_algorithms()\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch._assert": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\__init__.py",
      "start_line": 2032,
      "end_line": 2040,
      "code": "def _assert(condition, message):\n    if type(condition) is not torch.Tensor and overrides.has_torch_function(\n        (condition,)\n    ):\n        return overrides.handle_torch_function(\n            _assert, (condition,), condition, message\n        )\n    assert condition, message\n"
    },
    "cpp": {
      "function": "_assert_async_cpu",
      "file": "aten/src/ATen/native/TensorCompare.cpp",
      "start_line": 421,
      "end_line": 423,
      "code": "void _assert_async_cpu(const Tensor& self) {\n  TORCH_CHECK(native::is_nonzero(self), \"Expected Tensor with single nonzero value, but got zero\");\n}\n"
    }
  },
  "torch.nn.Sequential": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\container.py",
      "start_line": 64,
      "end_line": 278,
      "code": "class Sequential(Module):\n\n    _modules: Dict[str, Module]  # type: ignore[assignment]\n\n    @overload\n    def __init__(self, *args: Module) -> None:\n        ...\n\n    @overload\n    def __init__(self, arg: \"OrderedDict[str, Module]\") -> None:\n        ...\n\n    def __init__(self, *args):\n        super().__init__()\n        if len(args) == 1 and isinstance(args[0], OrderedDict):\n            for key, module in args[0].items():\n                self.add_module(key, module)\n        else:\n            for idx, module in enumerate(args):\n                self.add_module(str(idx), module)\n\n    def _get_item_by_idx(self, iterator, idx) -> T:  # type: ignore[misc, type-var]\n        \"\"\"Get the idx-th item of the iterator.\"\"\"\n        size = len(self)\n        idx = operator.index(idx)\n        if not -size <= idx < size:\n            raise IndexError(f\"index {idx} is out of range\")\n        idx %= size\n        return next(islice(iterator, idx, None))\n\n    @_copy_to_script_wrapper\n    def __getitem__(self, idx: Union[slice, int]) -> Union[\"Sequential\", T]:\n        if isinstance(idx, slice):\n            return self.__class__(OrderedDict(list(self._modules.items())[idx]))\n        else:\n            return self._get_item_by_idx(self._modules.values(), idx)\n\n    def __setitem__(self, idx: int, module: Module) -> None:\n        key: str = self._get_item_by_idx(self._modules.keys(), idx)\n        return setattr(self, key, module)\n\n    def __delitem__(self, idx: Union[slice, int]) -> None:\n        if isinstance(idx, slice):\n            for key in list(self._modules.keys())[idx]:\n                delattr(self, key)\n        else:\n            key = self._get_item_by_idx(self._modules.keys(), idx)\n            delattr(self, key)\n        # To preserve numbering\n        str_indices = [str(i) for i in range(len(self._modules))]\n        self._modules = OrderedDict(list(zip(str_indices, self._modules.values())))\n\n    @_copy_to_script_wrapper\n    def __len__(self) -> int:\n        return len(self._modules)\n\n    def __add__(self, other) -> \"Sequential\":\n        if isinstance(other, Sequential):\n            ret = Sequential()\n            for layer in self:\n                ret.append(layer)\n            for layer in other:\n                ret.append(layer)\n            return ret\n        else:\n            raise ValueError(\n                \"add operator supports only objects \"\n                f\"of Sequential class, but {str(type(other))} is given.\"\n            )\n\n    def pop(self, key: Union[int, slice]) -> Module:\n        v = self[key]\n        del self[key]\n        return v\n\n    def __iadd__(self, other) -> Self:\n        if isinstance(other, Sequential):\n            offset = len(self)\n            for i, module in enumerate(other):\n                self.add_module(str(i + offset), module)\n            return self\n        else:\n            raise ValueError(\n                \"add operator supports only objects \"\n                f\"of Sequential class, but {str(type(other))} is given.\"\n            )\n\n    def __mul__(self, other: int) -> \"Sequential\":\n        if not isinstance(other, int):\n            raise TypeError(\n                f\"unsupported operand type(s) for *: {type(self)} and {type(other)}\"\n            )\n        elif other <= 0:\n            raise ValueError(\n                f\"Non-positive multiplication factor {other} for {type(self)}\"\n            )\n        else:\n            combined = Sequential()\n            offset = 0\n            for _ in range(other):\n                for module in self:\n                    combined.add_module(str(offset), module)\n                    offset += 1\n            return combined\n\n    def __rmul__(self, other: int) -> \"Sequential\":\n        return self.__mul__(other)\n\n    def __imul__(self, other: int) -> Self:\n        if not isinstance(other, int):\n            raise TypeError(\n                f\"unsupported operand type(s) for *: {type(self)} and {type(other)}\"\n            )\n        elif other <= 0:\n            raise ValueError(\n                f\"Non-positive multiplication factor {other} for {type(self)}\"\n            )\n        else:\n            len_original = len(self)\n            offset = len(self)\n            for _ in range(other - 1):\n                for i in range(len_original):\n                    self.add_module(str(i + offset), self._modules[str(i)])\n                offset += len_original\n            return self\n\n    @_copy_to_script_wrapper\n    def __dir__(self):\n        keys = super().__dir__()\n        keys = [key for key in keys if not key.isdigit()]\n        return keys\n\n    @_copy_to_script_wrapper\n    def __iter__(self) -> Iterator[Module]:\n        return iter(self._modules.values())\n\n    # NB: We can't really type check this function as the type of input\n    # may change dynamically (as is tested in\n    # TestScript.test_sequential_intermediary_types).  Cannot annotate\n    # with Any as TorchScript expects a more precise type\n    def forward(self, input):\n        for module in self:\n            input = module(input)\n        return input\n\n    def append(self, module: Module) -> \"Sequential\":\n        r\"\"\"Append a given module to the end.\n\n        Args:\n            module (nn.Module): module to append\n        \"\"\"\n        self.add_module(str(len(self)), module)\n        return self\n\n    def insert(self, index: int, module: Module) -> \"Sequential\":\n        if not isinstance(module, Module):\n            raise AssertionError(f\"module should be of type: {Module}\")\n        n = len(self._modules)\n        if not (-n <= index <= n):\n            raise IndexError(f\"Index out of range: {index}\")\n        if index < 0:\n            index += n\n        for i in range(n, index, -1):\n            self._modules[str(i)] = self._modules[str(i - 1)]\n        self._modules[str(index)] = module\n        return self\n\n    def extend(self, sequential) -> \"Sequential\":\n        for layer in sequential:\n            self.append(layer)\n        return self\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ModuleList": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\container.py",
      "start_line": 281,
      "end_line": 446,
      "code": "class ModuleList(Module):\n\n    _modules: Dict[str, Module]  # type: ignore[assignment]\n\n    def __init__(self, modules: Optional[Iterable[Module]] = None) -> None:\n        super().__init__()\n        if modules is not None:\n            self += modules\n\n    def _get_abs_string_index(self, idx):\n        \"\"\"Get the absolute index for the list of modules.\"\"\"\n        idx = operator.index(idx)\n        if not (-len(self) <= idx < len(self)):\n            raise IndexError(f\"index {idx} is out of range\")\n        if idx < 0:\n            idx += len(self)\n        return str(idx)\n\n    @overload\n    def __getitem__(self, idx: slice) -> \"ModuleList\":\n        ...\n\n    @overload\n    def __getitem__(self, idx: int) -> Module:\n        ...\n\n    @_copy_to_script_wrapper\n    def __getitem__(self, idx: Union[int, slice]) -> Union[Module, \"ModuleList\"]:\n        if isinstance(idx, slice):\n            return self.__class__(list(self._modules.values())[idx])\n        else:\n            return self._modules[self._get_abs_string_index(idx)]\n\n    def __setitem__(self, idx: int, module: Module) -> None:\n        idx = self._get_abs_string_index(idx)\n        return setattr(self, str(idx), module)\n\n    def __delitem__(self, idx: Union[int, slice]) -> None:\n        if isinstance(idx, slice):\n            for k in range(len(self._modules))[idx]:\n                delattr(self, str(k))\n        else:\n            delattr(self, self._get_abs_string_index(idx))\n        # To preserve numbering, self._modules is being reconstructed with modules after deletion\n        str_indices = [str(i) for i in range(len(self._modules))]\n        self._modules = OrderedDict(list(zip(str_indices, self._modules.values())))\n\n    @_copy_to_script_wrapper\n    def __len__(self) -> int:\n        return len(self._modules)\n\n    @_copy_to_script_wrapper\n    def __iter__(self) -> Iterator[Module]:\n        return iter(self._modules.values())\n\n    def __iadd__(self, modules: Iterable[Module]) -> Self:\n        return self.extend(modules)\n\n    def __add__(self, other: Iterable[Module]) -> \"ModuleList\":\n        combined = ModuleList()\n        for i, module in enumerate(chain(self, other)):\n            combined.add_module(str(i), module)\n        return combined\n\n    def __repr__(self):\n        \"\"\"Return a custom repr for ModuleList that compresses repeated module representations.\"\"\"\n        list_of_reprs = [repr(item) for item in self]\n        if len(list_of_reprs) == 0:\n            return self._get_name() + \"()\"\n\n        start_end_indices = [[0, 0]]\n        repeated_blocks = [list_of_reprs[0]]\n        for i, r in enumerate(list_of_reprs[1:], 1):\n            if r == repeated_blocks[-1]:\n                start_end_indices[-1][1] += 1\n                continue\n\n            start_end_indices.append([i, i])\n            repeated_blocks.append(r)\n\n        lines = []\n        main_str = self._get_name() + \"(\"\n        for (start_id, end_id), b in zip(start_end_indices, repeated_blocks):\n            local_repr = f\"({start_id}): {b}\"  # default repr\n\n            if start_id != end_id:\n                n = end_id - start_id + 1\n                local_repr = f\"({start_id}-{end_id}): {n} x {b}\"\n\n            local_repr = _addindent(local_repr, 2)\n            lines.append(local_repr)\n\n        main_str += \"\\n  \" + \"\\n  \".join(lines) + \"\\n\"\n        main_str += \")\"\n        return main_str\n\n    @_copy_to_script_wrapper\n    def __dir__(self):\n        keys = super().__dir__()\n        keys = [key for key in keys if not key.isdigit()]\n        return keys\n\n    def insert(self, index: int, module: Module) -> None:\n        r\"\"\"Insert a given module before a given index in the list.\n\n        Args:\n            index (int): index to insert.\n            module (nn.Module): module to insert\n        \"\"\"\n        for i in range(len(self._modules), index, -1):\n            self._modules[str(i)] = self._modules[str(i - 1)]\n        self._modules[str(index)] = module\n\n    def append(self, module: Module) -> \"ModuleList\":\n        r\"\"\"Append a given module to the end of the list.\n\n        Args:\n            module (nn.Module): module to append\n        \"\"\"\n        self.add_module(str(len(self)), module)\n        return self\n\n    def pop(self, key: Union[int, slice]) -> Module:\n        v = self[key]\n        del self[key]\n        return v\n\n    def extend(self, modules: Iterable[Module]) -> Self:\n        r\"\"\"Append modules from a Python iterable to the end of the list.\n\n        Args:\n            modules (iterable): iterable of modules to append\n        \"\"\"\n        if not isinstance(modules, container_abcs.Iterable):\n            raise TypeError(\n                \"ModuleList.extend should be called with an \"\n                \"iterable, but got \" + type(modules).__name__\n            )\n        offset = len(self)\n        for i, module in enumerate(modules):\n            self.add_module(str(offset + i), module)\n        return self\n\n    # remove forward alltogether to fallback on Module's _forward_unimplemented\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ModuleDict": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\container.py",
      "start_line": 449,
      "end_line": 588,
      "code": "class ModuleDict(Module):\n\n    _modules: Dict[str, Module]  # type: ignore[assignment]\n\n    def __init__(self, modules: Optional[Mapping[str, Module]] = None) -> None:\n        super().__init__()\n        if modules is not None:\n            self.update(modules)\n\n    @_copy_to_script_wrapper\n    def __getitem__(self, key: str) -> Module:\n        return self._modules[key]\n\n    def __setitem__(self, key: str, module: Module) -> None:\n        self.add_module(key, module)\n\n    def __delitem__(self, key: str) -> None:\n        del self._modules[key]\n\n    @_copy_to_script_wrapper\n    def __len__(self) -> int:\n        return len(self._modules)\n\n    @_copy_to_script_wrapper\n    def __iter__(self) -> Iterator[str]:\n        return iter(self._modules)\n\n    @_copy_to_script_wrapper\n    def __contains__(self, key: str) -> bool:\n        return key in self._modules\n\n    def clear(self) -> None:\n        \"\"\"Remove all items from the ModuleDict.\"\"\"\n        self._modules.clear()\n\n    def pop(self, key: str) -> Module:\n        r\"\"\"Remove key from the ModuleDict and return its module.\n\n        Args:\n            key (str): key to pop from the ModuleDict\n        \"\"\"\n        v = self[key]\n        del self[key]\n        return v\n\n    @_copy_to_script_wrapper\n    def keys(self) -> Iterable[str]:\n        r\"\"\"Return an iterable of the ModuleDict keys.\"\"\"\n        return self._modules.keys()\n\n    @_copy_to_script_wrapper\n    def items(self) -> Iterable[Tuple[str, Module]]:\n        r\"\"\"Return an iterable of the ModuleDict key/value pairs.\"\"\"\n        return self._modules.items()\n\n    @_copy_to_script_wrapper\n    def values(self) -> Iterable[Module]:\n        r\"\"\"Return an iterable of the ModuleDict values.\"\"\"\n        return self._modules.values()\n\n    def update(self, modules: Mapping[str, Module]) -> None:\n        r\"\"\"Update the :class:`~torch.nn.ModuleDict` with key-value pairs from a mapping, overwriting existing keys.\n\n        .. note::\n            If :attr:`modules` is an ``OrderedDict``, a :class:`~torch.nn.ModuleDict`, or\n            an iterable of key-value pairs, the order of new elements in it is preserved.\n\n        Args:\n            modules (iterable): a mapping (dictionary) from string to :class:`~torch.nn.Module`,\n                or an iterable of key-value pairs of type (string, :class:`~torch.nn.Module`)\n        \"\"\"\n        if not isinstance(modules, container_abcs.Iterable):\n            raise TypeError(\n                \"ModuleDict.update should be called with an \"\n                \"iterable of key/value pairs, but got \" + type(modules).__name__\n            )\n\n        if isinstance(modules, (OrderedDict, ModuleDict, container_abcs.Mapping)):\n            for key, module in modules.items():\n                self[key] = module\n        else:\n            # modules here can be a list with two items\n            for j, m in enumerate(modules):\n                if not isinstance(m, container_abcs.Iterable):\n                    raise TypeError(\n                        \"ModuleDict update sequence element \"\n                        \"#\" + str(j) + \" should be Iterable; is\" + type(m).__name__\n                    )\n                if not len(m) == 2:\n                    raise ValueError(\n                        \"ModuleDict update sequence element \"\n                        \"#\" + str(j) + \" has length \" + str(len(m)) + \"; 2 is required\"\n                    )\n                # modules can be Mapping (what it's typed at), or a list: [(name1, module1), (name2, module2)]\n                # that's too cumbersome to type correctly with overloads, so we add an ignore here\n                self[m[0]] = m[1]  # type: ignore[assignment]\n\n    # remove forward alltogether to fallback on Module's _forward_unimplemented\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ParameterList": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\container.py",
      "start_line": 591,
      "end_line": 732,
      "code": "class ParameterList(Module):\n\n    def __init__(self, values: Optional[Iterable[Any]] = None) -> None:\n        super().__init__()\n        self._size = 0\n        if values is not None:\n            self += values\n\n    def _get_abs_string_index(self, idx):\n        \"\"\"Get the absolute index for the list of modules.\"\"\"\n        idx = operator.index(idx)\n        if not (-len(self) <= idx < len(self)):\n            raise IndexError(f\"index {idx} is out of range\")\n        if idx < 0:\n            idx += len(self)\n        return str(idx)\n\n    @overload\n    def __getitem__(self, idx: int) -> Any:\n        ...\n\n    @overload\n    def __getitem__(self: T, idx: slice) -> T:\n        ...\n\n    def __getitem__(self, idx):\n        if isinstance(idx, slice):\n            start, stop, step = idx.indices(len(self))\n            out = self.__class__()\n            for i in range(start, stop, step):\n                out.append(self[i])\n            return out\n        else:\n            idx = self._get_abs_string_index(idx)\n            return getattr(self, str(idx))\n\n    def __setitem__(self, idx: int, param: Any) -> None:\n        # Note that all other function that add an entry to the list part of\n        # the ParameterList end up here. So this is the only place where we need\n        # to wrap things into Parameter if needed.\n        # Objects added via setattr() are not in the list part and thus won't\n        # call into this function.\n        idx = self._get_abs_string_index(idx)\n        if isinstance(param, torch.Tensor) and not isinstance(param, Parameter):\n            param = Parameter(param)\n        return setattr(self, str(idx), param)\n\n    def __len__(self) -> int:\n        return self._size\n\n    def __iter__(self) -> Iterator[Any]:\n        return iter(self[i] for i in range(len(self)))\n\n    def __iadd__(self, parameters: Iterable[Any]) -> Self:\n        return self.extend(parameters)\n\n    def __dir__(self):\n        keys = super().__dir__()\n        keys = [key for key in keys if not key.isdigit()]\n        return keys\n\n    def append(self, value: Any) -> \"ParameterList\":\n        \"\"\"Append a given value at the end of the list.\n\n        Args:\n            value (Any): value to append\n        \"\"\"\n        new_idx = len(self)\n        self._size += 1\n        self[new_idx] = value\n        return self\n\n    def extend(self, values: Iterable[Any]) -> Self:\n        \"\"\"Append values from a Python iterable to the end of the list.\n\n        Args:\n            values (iterable): iterable of values to append\n        \"\"\"\n        # Tensor is an iterable but we never want to unpack it here\n        if not isinstance(values, container_abcs.Iterable) or isinstance(\n            values, torch.Tensor\n        ):\n            raise TypeError(\n                \"ParameterList.extend should be called with an \"\n                \"iterable, but got \" + type(values).__name__\n            )\n        for value in values:\n            self.append(value)\n        return self\n\n    def extra_repr(self) -> str:\n        child_lines = []\n        for k, p in enumerate(self):\n            if isinstance(p, torch.Tensor):\n                size_str = \"x\".join(str(size) for size in p.size())\n                if p.device.type in [\"cuda\", torch._C._get_privateuse1_backend_name()]:\n                    device_str = f\" ({p.device})\"\n                else:\n                    device_str = \"\"\n                parastr = \"{} containing: [{} of size {}{}]\".format(\n                    \"Parameter\" if isinstance(p, Parameter) else \"Tensor\",\n                    p.dtype,\n                    size_str,\n                    device_str,\n                )\n                child_lines.append(\"  (\" + str(k) + \"): \" + parastr)\n            else:\n                child_lines.append(\n                    \"  (\" + str(k) + \"): Object of type: \" + type(p).__name__\n                )\n\n        tmpstr = \"\\n\".join(child_lines)\n        return tmpstr\n\n    def __call__(self, *args, **kwargs):\n        raise RuntimeError(\"ParameterList should not be called.\")\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ParameterDict": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\container.py",
      "start_line": 735,
      "end_line": 976,
      "code": "class ParameterDict(Module):\n\n    def __init__(self, parameters: Any = None) -> None:\n        super().__init__()\n        self._keys: Dict[str, None] = {}\n        if parameters is not None:\n            self.update(parameters)\n\n    def _key_to_attr(self, key: str) -> str:\n        if not isinstance(key, str):\n            raise TypeError(\n                \"Index given to ParameterDict cannot be used as a key as it is \"\n                f\"not a string (type is '{type(key).__name__}'). Open an issue on \"\n                \"github if you need non-string keys.\"\n            )\n        else:\n            # Use the key as-is so that `.named_parameters()` returns the right thing\n            return key\n\n    def __getitem__(self, key: str) -> Any:\n        attr = self._key_to_attr(key)\n        return getattr(self, attr)\n\n    def __setitem__(self, key: str, value: Any) -> None:\n        # Note that all other function that add an entry to the dictionary part of\n        # the ParameterDict end up here. So this is the only place where we need\n        # to wrap things into Parameter if needed.\n        # Objects added via setattr() are not in the dictionary part and thus won't\n        # call into this function.\n        self._keys[key] = None\n        attr = self._key_to_attr(key)\n        if isinstance(value, torch.Tensor) and not isinstance(value, Parameter):\n            value = Parameter(value)\n        setattr(self, attr, value)\n\n    def __delitem__(self, key: str) -> None:\n        del self._keys[key]\n        attr = self._key_to_attr(key)\n        delattr(self, attr)\n\n    def __len__(self) -> int:\n        return len(self._keys)\n\n    def __iter__(self) -> Iterator[str]:\n        return iter(self._keys)\n\n    def __reversed__(self) -> Iterator[str]:\n        return reversed(list(self._keys))\n\n    def copy(self) -> \"ParameterDict\":\n        \"\"\"Return a copy of this :class:`~torch.nn.ParameterDict` instance.\"\"\"\n        # We have to use an OrderedDict because the ParameterDict constructor\n        # behaves differently on plain dict vs OrderedDict\n        return ParameterDict(OrderedDict((k, self[k]) for k in self._keys))\n\n    def __contains__(self, key: str) -> bool:\n        return key in self._keys\n\n    def setdefault(self, key: str, default: Optional[Any] = None) -> Any:\n        \"\"\"Set the default for a key in the Parameterdict.\n\n        If key is in the ParameterDict, return its value.\n        If not, insert `key` with a parameter `default` and return `default`.\n        `default` defaults to `None`.\n\n        Args:\n            key (str): key to set default for\n            default (Any): the parameter set to the key\n        \"\"\"\n        if key not in self:\n            self[key] = default\n        return self[key]\n\n    def clear(self) -> None:\n        \"\"\"Remove all items from the ParameterDict.\"\"\"\n        for k in self._keys.copy():\n            del self[k]\n\n    def pop(self, key: str) -> Any:\n        r\"\"\"Remove key from the ParameterDict and return its parameter.\n\n        Args:\n            key (str): key to pop from the ParameterDict\n        \"\"\"\n        v = self[key]\n        del self[key]\n        return v\n\n    def popitem(self) -> Tuple[str, Any]:\n        \"\"\"Remove and return the last inserted `(key, parameter)` pair from the ParameterDict.\"\"\"\n        k, _ = self._keys.popitem()\n        # We need the key in the _keys to be able to access/del\n        self._keys[k] = None\n        val = self[k]\n        del self[k]\n        return k, val\n\n    def get(self, key: str, default: Optional[Any] = None) -> Any:\n        r\"\"\"Return the parameter associated with key if present. Otherwise return default if provided, None if not.\n\n        Args:\n            key (str): key to get from the ParameterDict\n            default (Parameter, optional): value to return if key not present\n        \"\"\"\n        return self[key] if key in self else default\n\n    def fromkeys(\n        self, keys: Iterable[str], default: Optional[Any] = None\n    ) -> \"ParameterDict\":\n        r\"\"\"Return a new ParameterDict with the keys provided.\n\n        Args:\n            keys (iterable, string): keys to make the new ParameterDict from\n            default (Parameter, optional): value to set for all keys\n        \"\"\"\n        return ParameterDict((k, default) for k in keys)\n\n    def keys(self) -> Iterable[str]:\n        r\"\"\"Return an iterable of the ParameterDict keys.\"\"\"\n        return self._keys.keys()\n\n    def items(self) -> Iterable[Tuple[str, Any]]:\n        r\"\"\"Return an iterable of the ParameterDict key/value pairs.\"\"\"\n        return ((k, self[k]) for k in self._keys)\n\n    def values(self) -> Iterable[Any]:\n        r\"\"\"Return an iterable of the ParameterDict values.\"\"\"\n        return (self[k] for k in self._keys)\n\n    def update(self, parameters: Union[Mapping[str, Any], \"ParameterDict\"]) -> None:\n        r\"\"\"Update the :class:`~torch.nn.ParameterDict` with key-value pairs from ``parameters``, overwriting existing keys.\n\n        .. note::\n            If :attr:`parameters` is an ``OrderedDict``, a :class:`~torch.nn.ParameterDict`, or\n            an iterable of key-value pairs, the order of new elements in it is preserved.\n\n        Args:\n            parameters (iterable): a mapping (dictionary) from string to\n                :class:`~torch.nn.Parameter`, or an iterable of\n                key-value pairs of type (string, :class:`~torch.nn.Parameter`)\n        \"\"\"\n        if not isinstance(parameters, container_abcs.Iterable):\n            raise TypeError(\n                \"ParametersDict.update should be called with an \"\n                \"iterable of key/value pairs, but got \" + type(parameters).__name__\n            )\n\n        if isinstance(parameters, (OrderedDict, ParameterDict)):\n            for key, parameter in parameters.items():\n                self[key] = parameter\n        elif isinstance(parameters, container_abcs.Mapping):\n            for key, parameter in sorted(parameters.items()):\n                self[key] = parameter\n        else:\n            for j, p in enumerate(parameters):\n                if not isinstance(p, container_abcs.Iterable):\n                    raise TypeError(\n                        \"ParameterDict update sequence element \"\n                        \"#\" + str(j) + \" should be Iterable; is\" + type(p).__name__\n                    )\n                if not len(p) == 2:\n                    raise ValueError(\n                        \"ParameterDict update sequence element \"\n                        \"#\" + str(j) + \" has length \" + str(len(p)) + \"; 2 is required\"\n                    )\n                # parameters as length-2 list too cumbersome to type, see ModuleDict.update comment\n                self[p[0]] = p[1]  # type: ignore[assignment]\n\n    def extra_repr(self) -> str:\n        child_lines = []\n        for k, p in self.items():\n            if isinstance(p, torch.Tensor):\n                size_str = \"x\".join(str(size) for size in p.size())\n                if p.device.type in [\"cuda\", torch._C._get_privateuse1_backend_name()]:\n                    device_str = f\" ({p.device})\"\n                else:\n                    device_str = \"\"\n                parastr = \"{} containing: [{} of size {}{}]\".format(\n                    \"Parameter\" if isinstance(p, Parameter) else \"Tensor\",\n                    torch.typename(p),\n                    size_str,\n                    device_str,\n                )\n                child_lines.append(\"  (\" + str(k) + \"): \" + parastr)\n            else:\n                child_lines.append(\n                    \"  (\" + str(k) + \"): Object of type: \" + type(p).__name__\n                )\n        tmpstr = \"\\n\".join(child_lines)\n        return tmpstr\n\n    def __call__(self, input):\n        raise RuntimeError(\"ParameterDict should not be called.\")\n\n    def __or__(self, other: \"ParameterDict\") -> \"ParameterDict\":\n        copy = self.copy()\n        copy.update(other)\n        return copy\n\n    def __ror__(self, other: \"ParameterDict\") -> \"ParameterDict\":\n        copy = other.copy()\n        copy.update(self)\n        return copy\n\n    def __ior__(self, other: \"ParameterDict\") -> Self:\n        self.update(other)\n        return self\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.modules.module.register_module_forward_pre_hook": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\module.py",
      "start_line": 211,
      "end_line": 240,
      "code": "def register_module_forward_pre_hook(hook: Callable[..., None]) -> RemovableHandle:\n    handle = RemovableHandle(_global_forward_pre_hooks)\n    _global_forward_pre_hooks[handle.id] = hook\n    return handle\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.modules.module.register_module_forward_hook": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\module.py",
      "start_line": 243,
      "end_line": 285,
      "code": "def register_module_forward_hook(\n    hook: Callable[..., None],\n    *,\n    always_call: bool = False,\n) -> RemovableHandle:\n    handle = RemovableHandle(\n        _global_forward_hooks, extra_dict=_global_forward_hooks_always_called\n    )\n    _global_forward_hooks[handle.id] = hook\n    if always_call:\n        _global_forward_hooks_always_called[handle.id] = True\n    return handle\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.modules.module.register_module_backward_hook": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\module.py",
      "start_line": 288,
      "end_line": 314,
      "code": "def register_module_backward_hook(\n    hook: Callable[[\"Module\", _grad_t, _grad_t], Union[None, _grad_t]],\n) -> RemovableHandle:\n    global _global_is_full_backward_hook\n    if _global_is_full_backward_hook is True:\n        raise RuntimeError(\n            \"Cannot use both regular backward hooks and full backward hooks as a \"\n            \"global Module hook. Please use only one of them.\"\n        )\n\n    _global_is_full_backward_hook = False\n\n    handle = RemovableHandle(_global_backward_hooks)\n    _global_backward_hooks[handle.id] = hook\n    return handle\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Conv1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 214,
      "end_line": 375,
      "code": "class Conv1d(_ConvNd):\n    __doc__ = (\n        + r\"\"\"\n\n    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\n    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\n    * :attr:`stride` controls the stride for the cross-correlation, a single\n      number or a one-element tuple.\n\n    * :attr:`padding` controls the amount of padding applied to the input. It\n      can be either a string {{'valid', 'same'}} or a tuple of ints giving the\n      amount of implicit padding applied on both sides.\n\"\"\"\n        \"\"\"\n    * :attr:`dilation` controls the spacing between the kernel points; also\n      known as the \\u00e0 trous algorithm. It is harder to describe, but this `link`_\n      has a nice visualization of what :attr:`dilation` does.\n\"\"\"\n        r\"\"\"\n    {groups_note}\n\n    Note:\n        {depthwise_separable_note}\n    Note:\n        {cudnn_reproducibility_note}\n\n    Note:\n        ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n        the input so the output has the shape as the input. However, this mode\n        doesn't support any stride values other than 1.\n\n    Note:\n        This module supports complex data types i.e. ``complex32, complex64, complex128``.\n\n    Args:\n        in_channels (int): Number of channels in the input image\n        out_channels (int): Number of channels produced by the convolution\n        kernel_size (int or tuple): Size of the convolving kernel\n        stride (int or tuple, optional): Stride of the convolution. Default: 1\n        padding (int, tuple or str, optional): Padding added to both sides of\n            the input. Default: 0\n        dilation (int or tuple, optional): Spacing between kernel\n            elements. Default: 1\n        groups (int, optional): Number of blocked connections from input\n            channels to output channels. Default: 1\n        bias (bool, optional): If ``True``, adds a learnable bias to the\n            output. Default: ``True``\n        padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n            ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n\n    \"\"\".format(\n            **reproducibility_notes, **convolution_notes\n        )\n        + r\"\"\"\n\n    Shape:\n        - Input: :math:`(N, C_{in}, L_{in})` or :math:`(C_{in}, L_{in})`\n        - Output: :math:`(N, C_{out}, L_{out})` or :math:`(C_{out}, L_{out})`, where\n\n          .. math::\n              L_{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n                        \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\n\n    Attributes:\n        weight (Tensor): the learnable weights of the module of shape\n            :math:`(\\text{out\\_channels},\n            \\frac{\\text{in\\_channels}}{\\text{groups}}, \\text{kernel\\_size})`.\n            The values of these weights are sampled from\n            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n            :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n        bias (Tensor):   the learnable bias of the module of shape\n            (out_channels). If :attr:`bias` is ``True``, then the values of these weights are\n            sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n            :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n\n    Examples::\n\n        >>> m = nn.Conv1d(16, 33, 3, stride=2)\n        >>> input = torch.randn(20, 16, 50)\n        >>> output = m(input)\n\n    .. _cross-correlation:\n        https://en.wikipedia.org/wiki/Cross-correlation\n\n    .. _link:\n        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n    \"\"\"\n    )\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: _size_1_t,\n        stride: _size_1_t = 1,\n        padding: Union[str, _size_1_t] = 0,\n        dilation: _size_1_t = 1,\n        groups: int = 1,\n        bias: bool = True,\n        padding_mode: str = \"zeros\",  # TODO: refine this type\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        # we create new variables below to make mypy happy since kernel_size has\n        # type Union[int, Tuple[int]] and kernel_size_ has type Tuple[int]\n        kernel_size_ = _single(kernel_size)\n        stride_ = _single(stride)\n        padding_ = padding if isinstance(padding, str) else _single(padding)\n        dilation_ = _single(dilation)\n        super().__init__(\n            in_channels,\n            out_channels,\n            kernel_size_,\n            stride_,\n            padding_,\n            dilation_,\n            False,\n            _single(0),\n            groups,\n            bias,\n            padding_mode,\n            **factory_kwargs,\n        )\n\n    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n        if self.padding_mode != \"zeros\":\n            return F.conv1d(\n                F.pad(\n                    input, self._reversed_padding_repeated_twice, mode=self.padding_mode\n                ),\n                weight,\n                bias,\n                self.stride,\n                _single(0),\n                self.dilation,\n                self.groups,\n            )\n        return F.conv1d(\n            input, weight, bias, self.stride, self.padding, self.dilation, self.groups\n        )\n\n    def forward(self, input: Tensor) -> Tensor:\n        return self._conv_forward(input, self.weight, self.bias)\n"
    },
    "cpp": {
      "function": "conv1d_symint",
      "file": "aten/src/ATen/native/Convolution.cpp",
      "start_line": 915,
      "end_line": 938,
      "code": "at::Tensor conv1d_symint(\n    const Tensor& input_, const Tensor& weight, const std::optional<Tensor>& bias_opt,\n    SymIntArrayRef stride, SymIntArrayRef padding, SymIntArrayRef dilation, c10::SymInt groups) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> bias_maybe_owned = at::borrow_from_optional_tensor(bias_opt);\n  const Tensor& bias = *bias_maybe_owned;\n\n  TORCH_CHECK(\n    !bias.defined() || bias.dtype() == input_.dtype(),\n    \"Input type (\",\n    input_.dtype().name(),\n    \") and bias type (\",\n    bias.dtype().name(),\n    \") should be the same\");\n\n  auto [input, is_batched] = batchify(input_, /*num_spatial_dims=*/ 1, \"conv1d\");\n  Tensor output;\n  if (at::isComplexType(input_.scalar_type())) {\n    output = complex_convolution(input, weight, bias, stride, padding, dilation, false, {0}, groups);\n  } else {\n    output = at::convolution_symint(input, weight, bias, stride, padding, dilation, false, {0}, groups);\n  }\n  return is_batched ? std::move(output) : output.squeeze(0);\n}\n"
    }
  },
  "torch.nn.Conv2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 378,
      "end_line": 554,
      "code": "class Conv2d(_ConvNd):\n    __doc__ = (\n        + r\"\"\"\n\n    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\n    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\n    * :attr:`stride` controls the stride for the cross-correlation, a single\n      number or a tuple.\n\n    * :attr:`padding` controls the amount of padding applied to the input. It\n      can be either a string {{'valid', 'same'}} or an int / a tuple of ints giving the\n      amount of implicit padding applied on both sides.\n\"\"\"\n        \"\"\"\n    * :attr:`dilation` controls the spacing between the kernel points; also\n      known as the \\u00e0 trous algorithm. It is harder to describe, but this `link`_\n      has a nice visualization of what :attr:`dilation` does.\n\"\"\"\n        r\"\"\"\n\n    {groups_note}\n\n    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n\n        - a single ``int`` -- in which case the same value is used for the height and width dimension\n        - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n          and the second `int` for the width dimension\n\n    Note:\n        {depthwise_separable_note}\n\n    Note:\n        {cudnn_reproducibility_note}\n\n    Note:\n        ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n        the input so the output has the shape as the input. However, this mode\n        doesn't support any stride values other than 1.\n\n    Note:\n        This module supports complex data types i.e. ``complex32, complex64, complex128``.\n\n    Args:\n        in_channels (int): Number of channels in the input image\n        out_channels (int): Number of channels produced by the convolution\n        kernel_size (int or tuple): Size of the convolving kernel\n        stride (int or tuple, optional): Stride of the convolution. Default: 1\n        padding (int, tuple or str, optional): Padding added to all four sides of\n            the input. Default: 0\n        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n        groups (int, optional): Number of blocked connections from input\n            channels to output channels. Default: 1\n        bias (bool, optional): If ``True``, adds a learnable bias to the\n            output. Default: ``True``\n        padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n            ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n    \"\"\".format(\n            **reproducibility_notes, **convolution_notes\n        )\n        + r\"\"\"\n\n    Shape:\n        - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n        - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n\n          .. math::\n              H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n                        \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n\n          .. math::\n              W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n                        \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n\n    Attributes:\n        weight (Tensor): the learnable weights of the module of shape\n            :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n            :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n            The values of these weights are sampled from\n            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n            :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n        bias (Tensor):   the learnable bias of the module of shape\n            (out_channels). If :attr:`bias` is ``True``,\n            then the values of these weights are\n            sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n            :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n\n    Examples:\n\n        >>> # With square kernels and equal stride\n        >>> m = nn.Conv2d(16, 33, 3, stride=2)\n        >>> # non-square kernels and unequal stride and with padding\n        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n        >>> # non-square kernels and unequal stride and with padding and dilation\n        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n        >>> input = torch.randn(20, 16, 50, 100)\n        >>> output = m(input)\n\n    .. _cross-correlation:\n        https://en.wikipedia.org/wiki/Cross-correlation\n\n    .. _link:\n        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n    \"\"\"\n    )\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: _size_2_t,\n        stride: _size_2_t = 1,\n        padding: Union[str, _size_2_t] = 0,\n        dilation: _size_2_t = 1,\n        groups: int = 1,\n        bias: bool = True,\n        padding_mode: str = \"zeros\",  # TODO: refine this type\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        kernel_size_ = _pair(kernel_size)\n        stride_ = _pair(stride)\n        padding_ = padding if isinstance(padding, str) else _pair(padding)\n        dilation_ = _pair(dilation)\n        super().__init__(\n            in_channels,\n            out_channels,\n            kernel_size_,\n            stride_,\n            padding_,\n            dilation_,\n            False,\n            _pair(0),\n            groups,\n            bias,\n            padding_mode,\n            **factory_kwargs,\n        )\n\n    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n        if self.padding_mode != \"zeros\":\n            return F.conv2d(\n                F.pad(\n                    input, self._reversed_padding_repeated_twice, mode=self.padding_mode\n                ),\n                weight,\n                bias,\n                self.stride,\n                _pair(0),\n                self.dilation,\n                self.groups,\n            )\n        return F.conv2d(\n            input, weight, bias, self.stride, self.padding, self.dilation, self.groups\n        )\n\n    def forward(self, input: Tensor) -> Tensor:\n        return self._conv_forward(input, self.weight, self.bias)\n"
    },
    "cpp": {
      "function": "conv2d_symint",
      "file": "aten/src/ATen/native/Convolution.cpp",
      "start_line": 940,
      "end_line": 963,
      "code": "at::Tensor conv2d_symint(\n    const Tensor& input_, const Tensor& weight, const std::optional<Tensor>& bias_opt,\n    SymIntArrayRef stride, SymIntArrayRef padding, SymIntArrayRef dilation, c10::SymInt groups) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> bias_maybe_owned = at::borrow_from_optional_tensor(bias_opt);\n  const Tensor& bias = *bias_maybe_owned;\n\n  TORCH_CHECK(\n    !bias.defined() || bias.dtype() == input_.dtype(),\n    \"Input type (\",\n    input_.dtype().name(),\n    \") and bias type (\",\n    bias.dtype().name(),\n    \") should be the same\");\n\n  auto [input, is_batched] = batchify(input_, /*num_spatial_dims=*/ 2, \"conv2d\");\n  Tensor output;\n  if (at::isComplexType(input_.scalar_type())) {\n    output = complex_convolution(input, weight, bias, stride, padding, dilation, false, {{0, 0}}, groups);\n  } else {\n    output = at::convolution_symint(input, weight, bias, stride, padding, dilation, false, {{0, 0}}, groups);\n  }\n  return is_batched ? std::move(output) : output.squeeze(0);\n}\n"
    }
  },
  "torch.nn.Conv3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 557,
      "end_line": 725,
      "code": "class Conv3d(_ConvNd):\n    __doc__ = (\n        + r\"\"\"\n\n    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\n    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\n    * :attr:`stride` controls the stride for the cross-correlation.\n\n    * :attr:`padding` controls the amount of padding applied to the input. It\n      can be either a string {{'valid', 'same'}} or a tuple of ints giving the\n      amount of implicit padding applied on both sides.\n\"\"\"\n        \"\"\"\n    * :attr:`dilation` controls the spacing between the kernel points; also known as the \\u00e0 trous algorithm.\n      It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.\n\"\"\"\n        r\"\"\"\n\n    {groups_note}\n\n    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n\n        - a single ``int`` -- in which case the same value is used for the depth, height and width dimension\n        - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,\n          the second `int` for the height dimension and the third `int` for the width dimension\n\n    Note:\n        {depthwise_separable_note}\n\n    Note:\n        {cudnn_reproducibility_note}\n\n    Note:\n        ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n        the input so the output has the shape as the input. However, this mode\n        doesn't support any stride values other than 1.\n\n    Note:\n        This module supports complex data types i.e. ``complex32, complex64, complex128``.\n\n    Args:\n        in_channels (int): Number of channels in the input image\n        out_channels (int): Number of channels produced by the convolution\n        kernel_size (int or tuple): Size of the convolving kernel\n        stride (int or tuple, optional): Stride of the convolution. Default: 1\n        padding (int, tuple or str, optional): Padding added to all six sides of\n            the input. Default: 0\n        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n        groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n        padding_mode (str, optional): ``'zeros'``, ``'reflect'``, ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n    \"\"\".format(\n            **reproducibility_notes, **convolution_notes\n        )\n        + r\"\"\"\n\n    Shape:\n        - Input: :math:`(N, C_{in}, D_{in}, H_{in}, W_{in})` or :math:`(C_{in}, D_{in}, H_{in}, W_{in})`\n        - Output: :math:`(N, C_{out}, D_{out}, H_{out}, W_{out})` or :math:`(C_{out}, D_{out}, H_{out}, W_{out})`,\n          where\n\n          .. math::\n              D_{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n                    \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n\n          .. math::\n              H_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n                    \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n\n          .. math::\n              W_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] - \\text{dilation}[2]\n                    \\times (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor\n\n    Attributes:\n        weight (Tensor): the learnable weights of the module of shape\n                         :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n                         :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]}, \\text{kernel\\_size[2]})`.\n                         The values of these weights are sampled from\n                         :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                         :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}`\n        bias (Tensor):   the learnable bias of the module of shape (out_channels). If :attr:`bias` is ``True``,\n                         then the values of these weights are\n                         sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                         :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}`\n\n    Examples::\n\n        >>> # With square kernels and equal stride\n        >>> m = nn.Conv3d(16, 33, 3, stride=2)\n        >>> # non-square kernels and unequal stride and with padding\n        >>> m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0))\n        >>> input = torch.randn(20, 16, 10, 50, 100)\n        >>> output = m(input)\n\n    .. _cross-correlation:\n        https://en.wikipedia.org/wiki/Cross-correlation\n\n    .. _link:\n        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n    \"\"\"\n    )\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: _size_3_t,\n        stride: _size_3_t = 1,\n        padding: Union[str, _size_3_t] = 0,\n        dilation: _size_3_t = 1,\n        groups: int = 1,\n        bias: bool = True,\n        padding_mode: str = \"zeros\",\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        kernel_size_ = _triple(kernel_size)\n        stride_ = _triple(stride)\n        padding_ = padding if isinstance(padding, str) else _triple(padding)\n        dilation_ = _triple(dilation)\n        super().__init__(\n            in_channels,\n            out_channels,\n            kernel_size_,\n            stride_,\n            padding_,\n            dilation_,\n            False,\n            _triple(0),\n            groups,\n            bias,\n            padding_mode,\n            **factory_kwargs,\n        )\n\n    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n        if self.padding_mode != \"zeros\":\n            return F.conv3d(\n                F.pad(\n                    input, self._reversed_padding_repeated_twice, mode=self.padding_mode\n                ),\n                weight,\n                bias,\n                self.stride,\n                _triple(0),\n                self.dilation,\n                self.groups,\n            )\n        return F.conv3d(\n            input, weight, bias, self.stride, self.padding, self.dilation, self.groups\n        )\n\n    def forward(self, input: Tensor) -> Tensor:\n        return self._conv_forward(input, self.weight, self.bias)\n"
    },
    "cpp": {
      "function": "conv3d_symint",
      "file": "aten/src/ATen/native/Convolution.cpp",
      "start_line": 965,
      "end_line": 988,
      "code": "at::Tensor conv3d_symint(\n    const Tensor& input_, const Tensor& weight, const std::optional<Tensor>& bias_opt,\n    SymIntArrayRef stride, SymIntArrayRef padding, SymIntArrayRef dilation, c10::SymInt groups) {\n  // See [Note: hacky wrapper removal for optional tensor]\n  c10::MaybeOwned<Tensor> bias_maybe_owned = at::borrow_from_optional_tensor(bias_opt);\n  const Tensor& bias = *bias_maybe_owned;\n\n  TORCH_CHECK(\n    !bias.defined() || bias.dtype() == input_.dtype(),\n    \"Input type (\",\n    input_.dtype().name(),\n    \") and bias type (\",\n    bias.dtype().name(),\n    \") should be the same\");\n\n  auto [input, is_batched] = batchify(input_, /*num_spatial_dims=*/ 3, \"conv3d\");\n  Tensor output;\n  if (at::isComplexType(input_.scalar_type())) {\n    output = complex_convolution(input, weight, bias, stride, padding, dilation, false, {{0, 0, 0}}, groups);\n  } else {\n    output = at::convolution_symint(input, weight, bias, stride, padding, dilation, false, {{0, 0, 0}}, groups);\n  }\n  return is_batched ? std::move(output) : output.squeeze(0);\n}\n"
    }
  },
  "torch.nn.ConvTranspose1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 822,
      "end_line": 983,
      "code": "class ConvTranspose1d(_ConvTransposeNd):\n    __doc__ = (\n        \"\"\"\n    * :attr:`dilation` controls the spacing between the kernel points; also known as the \\u00e0 trous algorithm.\n      It is harder to describe, but the link `here`_ has a nice visualization of what :attr:`dilation` does.\n\"\"\"\n        r\"\"\"\n    {groups_note}\n\n    Note:\n        The :attr:`padding` argument effectively adds ``dilation * (kernel_size - 1) - padding``\n        amount of zero padding to both sizes of the input. This is set so that\n        when a :class:`~torch.nn.Conv1d` and a :class:`~torch.nn.ConvTranspose1d`\n        are initialized with same parameters, they are inverses of each other in\n        regard to the input and output shapes. However, when ``stride > 1``,\n        :class:`~torch.nn.Conv1d` maps multiple input shapes to the same output\n        shape. :attr:`output_padding` is provided to resolve this ambiguity by\n        effectively increasing the calculated output shape on one side. Note\n        that :attr:`output_padding` is only used to find output shape, but does\n        not actually add zero-padding to output.\n\n    Note:\n        In some circumstances when using the CUDA backend with CuDNN, this operator\n        may select a nondeterministic algorithm to increase performance. If this is\n        undesirable, you can try to make the operation deterministic (potentially at\n        a performance cost) by setting ``torch.backends.cudnn.deterministic =\n        True``.\n        Please see the notes on :doc:`/notes/randomness` for background.\n\n\n    Args:\n        in_channels (int): Number of channels in the input image\n        out_channels (int): Number of channels produced by the convolution\n        kernel_size (int or tuple): Size of the convolving kernel\n        stride (int or tuple, optional): Stride of the convolution. Default: 1\n        padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding\n            will be added to both sides of the input. Default: 0\n        output_padding (int or tuple, optional): Additional size added to one side\n            of the output shape. Default: 0\n        groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n    \"\"\".format(\n            **reproducibility_notes, **convolution_notes\n        )\n        + r\"\"\"\n\n    Shape:\n        - Input: :math:`(N, C_{in}, L_{in})` or :math:`(C_{in}, L_{in})`\n        - Output: :math:`(N, C_{out}, L_{out})` or :math:`(C_{out}, L_{out})`, where\n\n          .. math::\n              L_{out} = (L_{in} - 1) \\times \\text{stride} - 2 \\times \\text{padding} + \\text{dilation}\n                        \\times (\\text{kernel\\_size} - 1) + \\text{output\\_padding} + 1\n\n    Attributes:\n        weight (Tensor): the learnable weights of the module of shape\n                         :math:`(\\text{in\\_channels}, \\frac{\\text{out\\_channels}}{\\text{groups}},`\n                         :math:`\\text{kernel\\_size})`.\n                         The values of these weights are sampled from\n                         :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                         :math:`k = \\frac{groups}{C_\\text{out} * \\text{kernel\\_size}}`\n        bias (Tensor):   the learnable bias of the module of shape (out_channels).\n                         If :attr:`bias` is ``True``, then the values of these weights are\n                         sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                         :math:`k = \\frac{groups}{C_\\text{out} * \\text{kernel\\_size}}`\n\n    .. _`here`:\n        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n\n    .. _`Deconvolutional Networks`:\n        https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf\n    \"\"\"\n    )\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: _size_1_t,\n        stride: _size_1_t = 1,\n        padding: _size_1_t = 0,\n        output_padding: _size_1_t = 0,\n        groups: int = 1,\n        bias: bool = True,\n        dilation: _size_1_t = 1,\n        padding_mode: str = \"zeros\",\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        kernel_size = _single(kernel_size)\n        stride = _single(stride)\n        padding = _single(padding)\n        dilation = _single(dilation)\n        output_padding = _single(output_padding)\n        super().__init__(\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride,\n            padding,\n            dilation,\n            True,\n            output_padding,\n            groups,\n            bias,\n            padding_mode,\n            **factory_kwargs,\n        )\n\n    def forward(self, input: Tensor, output_size: Optional[List[int]] = None) -> Tensor:\n        if self.padding_mode != \"zeros\":\n            raise ValueError(\n                \"Only `zeros` padding mode is supported for ConvTranspose1d\"\n            )\n\n        assert isinstance(self.padding, tuple)\n        # One cannot replace List by Tuple or Sequence in \"_output_padding\" because\n        # TorchScript does not support `Sequence[T]` or `Tuple[T, ...]`.\n        num_spatial_dims = 1\n        output_padding = self._output_padding(\n            input,\n            output_size,\n            self.stride,  # type: ignore[arg-type]\n            self.padding,  # type: ignore[arg-type]\n            self.kernel_size,  # type: ignore[arg-type]\n            num_spatial_dims,\n            self.dilation,  # type: ignore[arg-type]\n        )\n        return F.conv_transpose1d(\n            input,\n            self.weight,\n            self.bias,\n            self.stride,\n            self.padding,\n            output_padding,\n            self.groups,\n            self.dilation,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ConvTranspose2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 986,
      "end_line": 1171,
      "code": "class ConvTranspose2d(_ConvTransposeNd):\n    __doc__ = (\n        \"\"\"\n    * :attr:`dilation` controls the spacing between the kernel points; also known as the \\u00e0 trous algorithm.\n      It is harder to describe, but the link `here`_ has a nice visualization of what :attr:`dilation` does.\n\"\"\"\n        r\"\"\"\n    {groups_note}\n\n    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`output_padding`\n    can either be:\n\n        - a single ``int`` -- in which case the same value is used for the height and width dimensions\n        - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n          and the second `int` for the width dimension\n\n    Note:\n        The :attr:`padding` argument effectively adds ``dilation * (kernel_size - 1) - padding``\n        amount of zero padding to both sizes of the input. This is set so that\n        when a :class:`~torch.nn.Conv2d` and a :class:`~torch.nn.ConvTranspose2d`\n        are initialized with same parameters, they are inverses of each other in\n        regard to the input and output shapes. However, when ``stride > 1``,\n        :class:`~torch.nn.Conv2d` maps multiple input shapes to the same output\n        shape. :attr:`output_padding` is provided to resolve this ambiguity by\n        effectively increasing the calculated output shape on one side. Note\n        that :attr:`output_padding` is only used to find output shape, but does\n        not actually add zero-padding to output.\n\n    Note:\n        {cudnn_reproducibility_note}\n\n    Args:\n        in_channels (int): Number of channels in the input image\n        out_channels (int): Number of channels produced by the convolution\n        kernel_size (int or tuple): Size of the convolving kernel\n        stride (int or tuple, optional): Stride of the convolution. Default: 1\n        padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding\n            will be added to both sides of each dimension in the input. Default: 0\n        output_padding (int or tuple, optional): Additional size added to one side\n            of each dimension in the output shape. Default: 0\n        groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n    \"\"\".format(\n            **reproducibility_notes, **convolution_notes\n        )\n        + r\"\"\"\n\n    Shape:\n        - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n        - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n\n        .. math::\n              H_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0]\n                        \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1\n        .. math::\n              W_{out} = (W_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1]\n                        \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1\n\n    Attributes:\n        weight (Tensor): the learnable weights of the module of shape\n                         :math:`(\\text{in\\_channels}, \\frac{\\text{out\\_channels}}{\\text{groups}},`\n                         :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n                         The values of these weights are sampled from\n                         :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                         :math:`k = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n        bias (Tensor):   the learnable bias of the module of shape (out_channels)\n                         If :attr:`bias` is ``True``, then the values of these weights are\n                         sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                         :math:`k = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n\n    Examples::\n\n        >>> # With square kernels and equal stride\n        >>> m = nn.ConvTranspose2d(16, 33, 3, stride=2)\n        >>> # non-square kernels and unequal stride and with padding\n        >>> m = nn.ConvTranspose2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n        >>> input = torch.randn(20, 16, 50, 100)\n        >>> output = m(input)\n        >>> # exact output size can be also specified as an argument\n        >>> input = torch.randn(1, 16, 12, 12)\n        >>> downsample = nn.Conv2d(16, 16, 3, stride=2, padding=1)\n        >>> upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1)\n        >>> h = downsample(input)\n        >>> h.size()\n        torch.Size([1, 16, 6, 6])\n        >>> output = upsample(h, output_size=input.size())\n        >>> output.size()\n        torch.Size([1, 16, 12, 12])\n\n    .. _`here`:\n        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n\n    .. _`Deconvolutional Networks`:\n        https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf\n    \"\"\"\n    )\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: _size_2_t,\n        stride: _size_2_t = 1,\n        padding: _size_2_t = 0,\n        output_padding: _size_2_t = 0,\n        groups: int = 1,\n        bias: bool = True,\n        dilation: _size_2_t = 1,\n        padding_mode: str = \"zeros\",\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        kernel_size = _pair(kernel_size)\n        stride = _pair(stride)\n        padding = _pair(padding)\n        dilation = _pair(dilation)\n        output_padding = _pair(output_padding)\n        super().__init__(\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride,\n            padding,\n            dilation,\n            True,\n            output_padding,\n            groups,\n            bias,\n            padding_mode,\n            **factory_kwargs,\n        )\n\n    def forward(self, input: Tensor, output_size: Optional[List[int]] = None) -> Tensor:\n        if self.padding_mode != \"zeros\":\n            raise ValueError(\n                \"Only `zeros` padding mode is supported for ConvTranspose2d\"\n            )\n\n        assert isinstance(self.padding, tuple)\n        # One cannot replace List by Tuple or Sequence in \"_output_padding\" because\n        # TorchScript does not support `Sequence[T]` or `Tuple[T, ...]`.\n        num_spatial_dims = 2\n        output_padding = self._output_padding(\n            input,\n            output_size,\n            self.stride,  # type: ignore[arg-type]\n            self.padding,  # type: ignore[arg-type]\n            self.kernel_size,  # type: ignore[arg-type]\n            num_spatial_dims,\n            self.dilation,  # type: ignore[arg-type]\n        )\n\n        return F.conv_transpose2d(\n            input,\n            self.weight,\n            self.bias,\n            self.stride,\n            self.padding,\n            output_padding,\n            self.groups,\n            self.dilation,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ConvTranspose3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 1174,
      "end_line": 1356,
      "code": "class ConvTranspose3d(_ConvTransposeNd):\n    __doc__ = (\n        \"\"\"\n    * :attr:`dilation` controls the spacing between the kernel points; also known as the \\u00e0 trous algorithm.\n      It is harder to describe, but the link `here`_ has a nice visualization of what :attr:`dilation` does.\n\"\"\"\n        r\"\"\"\n    {groups_note}\n\n    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`output_padding`\n    can either be:\n\n        - a single ``int`` -- in which case the same value is used for the depth, height and width dimensions\n        - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,\n          the second `int` for the height dimension and the third `int` for the width dimension\n\n    Note:\n        The :attr:`padding` argument effectively adds ``dilation * (kernel_size - 1) - padding``\n        amount of zero padding to both sizes of the input. This is set so that\n        when a :class:`~torch.nn.Conv3d` and a :class:`~torch.nn.ConvTranspose3d`\n        are initialized with same parameters, they are inverses of each other in\n        regard to the input and output shapes. However, when ``stride > 1``,\n        :class:`~torch.nn.Conv3d` maps multiple input shapes to the same output\n        shape. :attr:`output_padding` is provided to resolve this ambiguity by\n        effectively increasing the calculated output shape on one side. Note\n        that :attr:`output_padding` is only used to find output shape, but does\n        not actually add zero-padding to output.\n\n    Note:\n        {cudnn_reproducibility_note}\n\n    Args:\n        in_channels (int): Number of channels in the input image\n        out_channels (int): Number of channels produced by the convolution\n        kernel_size (int or tuple): Size of the convolving kernel\n        stride (int or tuple, optional): Stride of the convolution. Default: 1\n        padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding\n            will be added to both sides of each dimension in the input. Default: 0\n        output_padding (int or tuple, optional): Additional size added to one side\n            of each dimension in the output shape. Default: 0\n        groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n    \"\"\".format(\n            **reproducibility_notes, **convolution_notes\n        )\n        + r\"\"\"\n\n    Shape:\n        - Input: :math:`(N, C_{in}, D_{in}, H_{in}, W_{in})` or :math:`(C_{in}, D_{in}, H_{in}, W_{in})`\n        - Output: :math:`(N, C_{out}, D_{out}, H_{out}, W_{out})` or\n          :math:`(C_{out}, D_{out}, H_{out}, W_{out})`, where\n\n        .. math::\n              D_{out} = (D_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0]\n                        \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1\n        .. math::\n              H_{out} = (H_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1]\n                        \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1\n        .. math::\n              W_{out} = (W_{in} - 1) \\times \\text{stride}[2] - 2 \\times \\text{padding}[2] + \\text{dilation}[2]\n                        \\times (\\text{kernel\\_size}[2] - 1) + \\text{output\\_padding}[2] + 1\n\n\n    Attributes:\n        weight (Tensor): the learnable weights of the module of shape\n                         :math:`(\\text{in\\_channels}, \\frac{\\text{out\\_channels}}{\\text{groups}},`\n                         :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]}, \\text{kernel\\_size[2]})`.\n                         The values of these weights are sampled from\n                         :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                         :math:`k = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}`\n        bias (Tensor):   the learnable bias of the module of shape (out_channels)\n                         If :attr:`bias` is ``True``, then the values of these weights are\n                         sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n                         :math:`k = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}`\n\n    Examples::\n\n        >>> # With square kernels and equal stride\n        >>> m = nn.ConvTranspose3d(16, 33, 3, stride=2)\n        >>> # non-square kernels and unequal stride and with padding\n        >>> m = nn.ConvTranspose3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(0, 4, 2))\n        >>> input = torch.randn(20, 16, 10, 50, 100)\n        >>> output = m(input)\n\n    .. _`here`:\n        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n\n    .. _`Deconvolutional Networks`:\n        https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf\n    \"\"\"\n    )\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: _size_3_t,\n        stride: _size_3_t = 1,\n        padding: _size_3_t = 0,\n        output_padding: _size_3_t = 0,\n        groups: int = 1,\n        bias: bool = True,\n        dilation: _size_3_t = 1,\n        padding_mode: str = \"zeros\",\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        kernel_size = _triple(kernel_size)\n        stride = _triple(stride)\n        padding = _triple(padding)\n        dilation = _triple(dilation)\n        output_padding = _triple(output_padding)\n        super().__init__(\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride,\n            padding,\n            dilation,\n            True,\n            output_padding,\n            groups,\n            bias,\n            padding_mode,\n            **factory_kwargs,\n        )\n\n    def forward(self, input: Tensor, output_size: Optional[List[int]] = None) -> Tensor:\n        if self.padding_mode != \"zeros\":\n            raise ValueError(\n                \"Only `zeros` padding mode is supported for ConvTranspose3d\"\n            )\n\n        assert isinstance(self.padding, tuple)\n        # One cannot replace List by Tuple or Sequence in \"_output_padding\" because\n        # TorchScript does not support `Sequence[T]` or `Tuple[T, ...]`.\n        num_spatial_dims = 3\n        output_padding = self._output_padding(\n            input,\n            output_size,\n            self.stride,  # type: ignore[arg-type]\n            self.padding,  # type: ignore[arg-type]\n            self.kernel_size,  # type: ignore[arg-type]\n            num_spatial_dims,\n            self.dilation,  # type: ignore[arg-type]\n        )\n\n        return F.conv_transpose3d(\n            input,\n            self.weight,\n            self.bias,\n            self.stride,\n            self.padding,\n            output_padding,\n            self.groups,\n            self.dilation,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LazyConv1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 1455,
      "end_line": 1520,
      "code": "class LazyConv1d(_LazyConvXdMixin, Conv1d):  # type: ignore[misc]\n\n    # super class define this variable as None. \"type: ignore[..] is required\n    # since we are redefining the variable.\n    cls_to_become = Conv1d  # type: ignore[assignment]\n\n    def __init__(\n        self,\n        out_channels: int,\n        kernel_size: _size_1_t,\n        stride: _size_1_t = 1,\n        padding: _size_1_t = 0,\n        dilation: _size_1_t = 1,\n        groups: int = 1,\n        bias: bool = True,\n        padding_mode: str = \"zeros\",\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__(\n            0,\n            0,\n            kernel_size,\n            stride,\n            padding,\n            dilation,\n            groups,\n            # bias is hardcoded to False to avoid creating tensor\n            # that will soon be overwritten.\n            False,\n            padding_mode,\n            **factory_kwargs,\n        )\n        self.weight = UninitializedParameter(**factory_kwargs)\n        self.out_channels = out_channels\n        if bias:\n            self.bias = UninitializedParameter(**factory_kwargs)\n\n    def _get_num_spatial_dims(self) -> int:\n        return 1\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LazyConv2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 1524,
      "end_line": 1589,
      "code": "class LazyConv2d(_LazyConvXdMixin, Conv2d):  # type: ignore[misc]\n\n    # super class define this variable as None. \"type: ignore[..] is required\n    # since we are redefining the variable.\n    cls_to_become = Conv2d  # type: ignore[assignment]\n\n    def __init__(\n        self,\n        out_channels: int,\n        kernel_size: _size_2_t,\n        stride: _size_2_t = 1,\n        padding: _size_2_t = 0,\n        dilation: _size_2_t = 1,\n        groups: int = 1,\n        bias: bool = True,\n        padding_mode: str = \"zeros\",  # TODO: refine this type\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__(\n            0,\n            0,\n            kernel_size,\n            stride,\n            padding,\n            dilation,\n            groups,\n            # bias is hardcoded to False to avoid creating tensor\n            # that will soon be overwritten.\n            False,\n            padding_mode,\n            **factory_kwargs,\n        )\n        self.weight = UninitializedParameter(**factory_kwargs)\n        self.out_channels = out_channels\n        if bias:\n            self.bias = UninitializedParameter(**factory_kwargs)\n\n    def _get_num_spatial_dims(self) -> int:\n        return 2\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LazyConv3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 1593,
      "end_line": 1659,
      "code": "class LazyConv3d(_LazyConvXdMixin, Conv3d):  # type: ignore[misc]\n\n    # super class define this variable as None. \"type: ignore[..] is required\n    # since we are redefining the variable.\n    cls_to_become = Conv3d  # type: ignore[assignment]\n\n    def __init__(\n        self,\n        out_channels: int,\n        kernel_size: _size_3_t,\n        stride: _size_3_t = 1,\n        padding: _size_3_t = 0,\n        dilation: _size_3_t = 1,\n        groups: int = 1,\n        bias: bool = True,\n        padding_mode: str = \"zeros\",\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__(\n            0,\n            0,\n            kernel_size,\n            stride,\n            padding,\n            dilation,\n            groups,\n            # bias is hardcoded to False to avoid creating tensor\n            # that will soon be overwritten.\n            False,\n            padding_mode,\n            **factory_kwargs,\n        )\n        self.weight = UninitializedParameter(**factory_kwargs)\n        self.out_channels = out_channels\n        if bias:\n            self.bias = UninitializedParameter(**factory_kwargs)\n\n    def _get_num_spatial_dims(self) -> int:\n        return 3\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LazyConvTranspose1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 1663,
      "end_line": 1728,
      "code": "class LazyConvTranspose1d(_LazyConvXdMixin, ConvTranspose1d):  # type: ignore[misc]\n\n    # super class define this variable as None. \"type: ignore[..] is required\n    # since we are redefining the variable.\n    cls_to_become = ConvTranspose1d  # type: ignore[assignment]\n\n    def __init__(\n        self,\n        out_channels: int,\n        kernel_size: _size_1_t,\n        stride: _size_1_t = 1,\n        padding: _size_1_t = 0,\n        output_padding: _size_1_t = 0,\n        groups: int = 1,\n        bias: bool = True,\n        dilation: _size_1_t = 1,\n        padding_mode: str = \"zeros\",\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__(\n            0,\n            0,\n            kernel_size,\n            stride,\n            padding,\n            output_padding,\n            groups,\n            # bias is hardcoded to False to avoid creating tensor\n            # that will soon be overwritten.\n            False,\n            dilation,\n            padding_mode,\n            **factory_kwargs,\n        )\n        self.weight = UninitializedParameter(**factory_kwargs)\n        self.out_channels = out_channels\n        if bias:\n            self.bias = UninitializedParameter(**factory_kwargs)\n\n    def _get_num_spatial_dims(self) -> int:\n        return 1\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LazyConvTranspose2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 1732,
      "end_line": 1797,
      "code": "class LazyConvTranspose2d(_LazyConvXdMixin, ConvTranspose2d):  # type: ignore[misc]\n\n    # super class define this variable as None. \"type: ignore[..] is required\n    # since we are redefining the variable.\n    cls_to_become = ConvTranspose2d  # type: ignore[assignment]\n\n    def __init__(\n        self,\n        out_channels: int,\n        kernel_size: _size_2_t,\n        stride: _size_2_t = 1,\n        padding: _size_2_t = 0,\n        output_padding: _size_2_t = 0,\n        groups: int = 1,\n        bias: bool = True,\n        dilation: int = 1,\n        padding_mode: str = \"zeros\",\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__(\n            0,\n            0,\n            kernel_size,\n            stride,\n            padding,\n            output_padding,\n            groups,\n            # bias is hardcoded to False to avoid creating tensor\n            # that will soon be overwritten.\n            False,\n            dilation,\n            padding_mode,\n            **factory_kwargs,\n        )\n        self.weight = UninitializedParameter(**factory_kwargs)\n        self.out_channels = out_channels\n        if bias:\n            self.bias = UninitializedParameter(**factory_kwargs)\n\n    def _get_num_spatial_dims(self) -> int:\n        return 2\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LazyConvTranspose3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py",
      "start_line": 1801,
      "end_line": 1866,
      "code": "class LazyConvTranspose3d(_LazyConvXdMixin, ConvTranspose3d):  # type: ignore[misc]\n\n    # super class define this variable as None. \"type: ignore[..] is required\n    # since we are redefining the variable.\n    cls_to_become = ConvTranspose3d  # type: ignore[assignment]\n\n    def __init__(\n        self,\n        out_channels: int,\n        kernel_size: _size_3_t,\n        stride: _size_3_t = 1,\n        padding: _size_3_t = 0,\n        output_padding: _size_3_t = 0,\n        groups: int = 1,\n        bias: bool = True,\n        dilation: _size_3_t = 1,\n        padding_mode: str = \"zeros\",\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__(\n            0,\n            0,\n            kernel_size,\n            stride,\n            padding,\n            output_padding,\n            groups,\n            # bias is hardcoded to False to avoid creating tensor\n            # that will soon be overwritten.\n            False,\n            dilation,\n            padding_mode,\n            **factory_kwargs,\n        )\n        self.weight = UninitializedParameter(**factory_kwargs)\n        self.out_channels = out_channels\n        if bias:\n            self.bias = UninitializedParameter(**factory_kwargs)\n\n    def _get_num_spatial_dims(self) -> int:\n        return 3\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Unfold": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\fold.py",
      "start_line": 164,
      "end_line": 315,
      "code": "class Unfold(Module):\n \"\"\"\n    * :attr:`dilation` controls the spacing between the kernel points; also known as the \\u00e0 trous algorithm.\n      It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.\n\"\"\" r\"\"\"\n    Args:\n        kernel_size (int or tuple): the size of the sliding blocks\n        dilation (int or tuple, optional): a parameter that controls the\n                                           stride of elements within the\n                                           neighborhood. Default: 1\n        padding (int or tuple, optional): implicit zero padding to be added on\n                                          both sides of input. Default: 0\n        stride (int or tuple, optional): the stride of the sliding blocks in the input\n                                         spatial dimensions. Default: 1\n\n    * If :attr:`kernel_size`, :attr:`dilation`, :attr:`padding` or\n      :attr:`stride` is an int or a tuple of length 1, their values will be\n      replicated across all spatial dimensions.\n\n    * For the case of two input spatial dimensions this operation is sometimes\n      called ``im2col``.\n\n    .. note::\n        :class:`~torch.nn.Fold` calculates each combined value in the resulting\n        large tensor by summing all values from all containing blocks.\n        :class:`~torch.nn.Unfold` extracts the values in the local blocks by\n        copying from the large tensor. So, if the blocks overlap, they are not\n        inverses of each other.\n\n        In general, folding and unfolding operations are related as\n        follows. Consider :class:`~torch.nn.Fold` and\n        :class:`~torch.nn.Unfold` instances created with the same\n        parameters:\n\n        >>> fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...)\n        >>> fold = nn.Fold(output_size=..., **fold_params)\n        >>> unfold = nn.Unfold(**fold_params)\n\n        Then for any (supported) ``input`` tensor the following\n        equality holds:\n\n        ::\n\n            fold(unfold(input)) == divisor * input\n\n        where ``divisor`` is a tensor that depends only on the shape\n        and dtype of the ``input``:\n\n        >>> # xdoctest: +SKIP\n        >>> input_ones = torch.ones(input.shape, dtype=input.dtype)\n        >>> divisor = fold(unfold(input_ones))\n\n        When the ``divisor`` tensor contains no zero elements, then\n        ``fold`` and ``unfold`` operations are inverses of each\n        other (up to constant divisor).\n\n    .. warning::\n        Currently, only 4-D input tensors (batched image-like tensors) are\n        supported.\n\n    Shape:\n        - Input: :math:`(N, C, *)`\n        - Output: :math:`(N, C \\times \\prod(\\text{kernel\\_size}), L)` as described above\n\n    Examples::\n\n        >>> unfold = nn.Unfold(kernel_size=(2, 3))\n        >>> input = torch.randn(2, 5, 3, 4)\n        >>> output = unfold(input)\n        >>> # each patch contains 30 values (2x3=6 vectors, each of 5 channels)\n        >>> # 4 blocks (2x3 kernels) in total in the 3x4 input\n        >>> output.size()\n        torch.Size([2, 30, 4])\n\n        >>> # xdoctest: +IGNORE_WANT\n        >>> # Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n        >>> inp = torch.randn(1, 3, 10, 12)\n        >>> w = torch.randn(2, 3, 4, 5)\n        >>> inp_unf = torch.nn.functional.unfold(inp, (4, 5))\n        >>> out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n        >>> out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))\n        >>> # or equivalently (and avoiding a copy),\n        >>> # out = out_unf.view(1, 2, 7, 8)\n        >>> (torch.nn.functional.conv2d(inp, w) - out).abs().max()\n        tensor(1.9073e-06)\n\n    .. _link:\n        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n\n    \"\"\"\n\n    __constants__ = [\"kernel_size\", \"dilation\", \"padding\", \"stride\"]\n    kernel_size: _size_any_t\n    dilation: _size_any_t\n    padding: _size_any_t\n    stride: _size_any_t\n\n    def __init__(\n        self,\n        kernel_size: _size_any_t,\n        dilation: _size_any_t = 1,\n        padding: _size_any_t = 0,\n        stride: _size_any_t = 1,\n    ) -> None:\n        super().__init__()\n        self.kernel_size = kernel_size\n        self.dilation = dilation\n        self.padding = padding\n        self.stride = stride\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.unfold(\n            input, self.kernel_size, self.dilation, self.padding, self.stride\n        )\n\n    def extra_repr(self) -> str:\n        return (\n            \"kernel_size={kernel_size}, dilation={dilation}, padding={padding},\"\n            \" stride={stride}\".format(**self.__dict__)\n        )\n"
    },
    "cpp": {
      "function": "unfold",
      "file": "aten/src/ATen/native/TensorShape.cpp",
      "start_line": 3771,
      "end_line": 3790,
      "code": "Tensor unfold(const Tensor& self, int64_t d, int64_t size, int64_t step) {\n  // some special handling to deal with allow d == 0 when self.dim() == 0\n  auto ndim = self.dim();\n  d = at::maybe_wrap_dim(d, ndim, /*wrap_scalar=*/true);\n\n  auto sizes = self.sizes().vec();\n  auto strides = self.strides().vec();\n  int64_t max_size = self.dim() == 0 ? 1 : sizes[d];\n  TORCH_CHECK(size <= max_size, \"maximum size for tensor at dimension \", d,\n                                \" is \", max_size, \" but size is \", size);\n  TORCH_CHECK(step > 0, \"step is \", step, \" but must be > 0\");\n  sizes.push_back(size);\n  strides.push_back(self.dim() == 0 ? 1 : strides[d]);\n  // The if handles the self.dim() == 0 case\n  if (d < ndim) {\n    sizes[d] = (sizes[d] - size) / step + 1;\n    strides[d] *= step;\n  }\n  return self.as_strided(sizes, strides);\n}\n"
    }
  },
  "torch.nn.Fold": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\fold.py",
      "start_line": 11,
      "end_line": 161,
      "code": "class Fold(Module):\n \"\"\"\n    * :attr:`dilation` controls the spacing between the kernel points; also known as the \\u00e0 trous algorithm.\n      It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.\n\"\"\" r\"\"\"\n    Args:\n        output_size (int or tuple): the shape of the spatial dimensions of the\n                                    output (i.e., ``output.sizes()[2:]``)\n        kernel_size (int or tuple): the size of the sliding blocks\n        dilation (int or tuple, optional): a parameter that controls the\n                                           stride of elements within the\n                                           neighborhood. Default: 1\n        padding (int or tuple, optional): implicit zero padding to be added on\n                                          both sides of input. Default: 0\n        stride (int or tuple): the stride of the sliding blocks in the input\n                               spatial dimensions. Default: 1\n\n    * If :attr:`output_size`, :attr:`kernel_size`, :attr:`dilation`,\n      :attr:`padding` or :attr:`stride` is an int or a tuple of length 1 then\n      their values will be replicated across all spatial dimensions.\n\n    * For the case of two output spatial dimensions this operation is sometimes\n      called ``col2im``.\n\n    .. note::\n        :class:`~torch.nn.Fold` calculates each combined value in the resulting\n        large tensor by summing all values from all containing blocks.\n        :class:`~torch.nn.Unfold` extracts the values in the local blocks by\n        copying from the large tensor. So, if the blocks overlap, they are not\n        inverses of each other.\n\n        In general, folding and unfolding operations are related as\n        follows. Consider :class:`~torch.nn.Fold` and\n        :class:`~torch.nn.Unfold` instances created with the same\n        parameters:\n\n        >>> fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...)\n        >>> fold = nn.Fold(output_size=..., **fold_params)\n        >>> unfold = nn.Unfold(**fold_params)\n\n        Then for any (supported) ``input`` tensor the following\n        equality holds:\n\n        ::\n\n            fold(unfold(input)) == divisor * input\n\n        where ``divisor`` is a tensor that depends only on the shape\n        and dtype of the ``input``:\n\n        >>> # xdoctest: +SKIP\n        >>> input_ones = torch.ones(input.shape, dtype=input.dtype)\n        >>> divisor = fold(unfold(input_ones))\n\n        When the ``divisor`` tensor contains no zero elements, then\n        ``fold`` and ``unfold`` operations are inverses of each\n        other (up to constant divisor).\n\n    .. warning::\n        Currently, only unbatched (3D) or batched (4D) image-like output tensors are supported.\n\n    Shape:\n        - Input: :math:`(N, C \\times \\prod(\\text{kernel\\_size}), L)` or :math:`(C \\times \\prod(\\text{kernel\\_size}), L)`\n        - Output: :math:`(N, C, \\text{output\\_size}[0], \\text{output\\_size}[1], \\dots)`\n          or :math:`(C, \\text{output\\_size}[0], \\text{output\\_size}[1], \\dots)` as described above\n\n    Examples::\n\n        >>> fold = nn.Fold(output_size=(4, 5), kernel_size=(2, 2))\n        >>> input = torch.randn(1, 3 * 2 * 2, 12)\n        >>> output = fold(input)\n        >>> output.size()\n        torch.Size([1, 3, 4, 5])\n\n    .. _link:\n        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n\n    \"\"\"\n\n    __constants__ = [\"output_size\", \"kernel_size\", \"dilation\", \"padding\", \"stride\"]\n    output_size: _size_any_t\n    kernel_size: _size_any_t\n    dilation: _size_any_t\n    padding: _size_any_t\n    stride: _size_any_t\n\n    def __init__(\n        self,\n        output_size: _size_any_t,\n        kernel_size: _size_any_t,\n        dilation: _size_any_t = 1,\n        padding: _size_any_t = 0,\n        stride: _size_any_t = 1,\n    ) -> None:\n        super().__init__()\n        self.output_size = output_size\n        self.kernel_size = kernel_size\n        self.dilation = dilation\n        self.padding = padding\n        self.stride = stride\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.fold(\n            input,\n            self.output_size,\n            self.kernel_size,\n            self.dilation,\n            self.padding,\n            self.stride,\n        )\n\n    def extra_repr(self) -> str:\n        return (\n            \"output_size={output_size}, kernel_size={kernel_size}, \"\n            \"dilation={dilation}, padding={padding}, stride={stride}\".format(\n                **self.__dict__\n            )\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MaxPool1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 81,
      "end_line": 142,
      "code": "class MaxPool1d(_MaxPoolNd):\n\n    kernel_size: _size_1_t\n    stride: _size_1_t\n    padding: _size_1_t\n    dilation: _size_1_t\n\n    def forward(self, input: Tensor):\n        return F.max_pool1d(\n            input,\n            self.kernel_size,\n            self.stride,\n            self.padding,\n            self.dilation,\n            ceil_mode=self.ceil_mode,\n            return_indices=self.return_indices,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MaxPool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 145,
      "end_line": 221,
      "code": "class MaxPool2d(_MaxPoolNd):\n\n    kernel_size: _size_2_t\n    stride: _size_2_t\n    padding: _size_2_t\n    dilation: _size_2_t\n\n    def forward(self, input: Tensor):\n        return F.max_pool2d(\n            input,\n            self.kernel_size,\n            self.stride,\n            self.padding,\n            self.dilation,\n            ceil_mode=self.ceil_mode,\n            return_indices=self.return_indices,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MaxPool3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 224,
      "end_line": 304,
      "code": "class MaxPool3d(_MaxPoolNd):\n  # noqa: E501\n\n    kernel_size: _size_3_t\n    stride: _size_3_t\n    padding: _size_3_t\n    dilation: _size_3_t\n\n    def forward(self, input: Tensor):\n        return F.max_pool3d(\n            input,\n            self.kernel_size,\n            self.stride,\n            self.padding,\n            self.dilation,\n            ceil_mode=self.ceil_mode,\n            return_indices=self.return_indices,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MaxUnpool1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 312,
      "end_line": 391,
      "code": "class MaxUnpool1d(_MaxUnpoolNd):\n\n    kernel_size: _size_1_t\n    stride: _size_1_t\n    padding: _size_1_t\n\n    def __init__(\n        self,\n        kernel_size: _size_1_t,\n        stride: Optional[_size_1_t] = None,\n        padding: _size_1_t = 0,\n    ) -> None:\n        super().__init__()\n        self.kernel_size = _single(kernel_size)\n        self.stride = _single(stride if (stride is not None) else kernel_size)\n        self.padding = _single(padding)\n\n    def forward(\n        self, input: Tensor, indices: Tensor, output_size: Optional[List[int]] = None\n    ) -> Tensor:\n        return F.max_unpool1d(\n            input, indices, self.kernel_size, self.stride, self.padding, output_size\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MaxUnpool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 394,
      "end_line": 486,
      "code": "class MaxUnpool2d(_MaxUnpoolNd):\n\n    kernel_size: _size_2_t\n    stride: _size_2_t\n    padding: _size_2_t\n\n    def __init__(\n        self,\n        kernel_size: _size_2_t,\n        stride: Optional[_size_2_t] = None,\n        padding: _size_2_t = 0,\n    ) -> None:\n        super().__init__()\n        self.kernel_size = _pair(kernel_size)\n        self.stride = _pair(stride if (stride is not None) else kernel_size)\n        self.padding = _pair(padding)\n\n    def forward(\n        self, input: Tensor, indices: Tensor, output_size: Optional[List[int]] = None\n    ) -> Tensor:\n        return F.max_unpool2d(\n            input, indices, self.kernel_size, self.stride, self.padding, output_size\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MaxUnpool3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 489,
      "end_line": 564,
      "code": "class MaxUnpool3d(_MaxUnpoolNd):\n\n    kernel_size: _size_3_t\n    stride: _size_3_t\n    padding: _size_3_t\n\n    def __init__(\n        self,\n        kernel_size: _size_3_t,\n        stride: Optional[_size_3_t] = None,\n        padding: _size_3_t = 0,\n    ) -> None:\n        super().__init__()\n        self.kernel_size = _triple(kernel_size)\n        self.stride = _triple(stride if (stride is not None) else kernel_size)\n        self.padding = _triple(padding)\n\n    def forward(\n        self, input: Tensor, indices: Tensor, output_size: Optional[List[int]] = None\n    ) -> Tensor:\n        return F.max_unpool3d(\n            input, indices, self.kernel_size, self.stride, self.padding, output_size\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.AvgPool1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 580,
      "end_line": 658,
      "code": "class AvgPool1d(_AvgPoolNd):\n\n    kernel_size: _size_1_t\n    stride: _size_1_t\n    padding: _size_1_t\n    ceil_mode: bool\n    count_include_pad: bool\n\n    def __init__(\n        self,\n        kernel_size: _size_1_t,\n        stride: _size_1_t = None,\n        padding: _size_1_t = 0,\n        ceil_mode: bool = False,\n        count_include_pad: bool = True,\n    ) -> None:\n        super().__init__()\n        self.kernel_size = _single(kernel_size)\n        self.stride = _single(stride if stride is not None else kernel_size)\n        self.padding = _single(padding)\n        self.ceil_mode = ceil_mode\n        self.count_include_pad = count_include_pad\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.avg_pool1d(\n            input,\n            self.kernel_size,\n            self.stride,\n            self.padding,\n            self.ceil_mode,\n            self.count_include_pad,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.AvgPool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 661,
      "end_line": 764,
      "code": "class AvgPool2d(_AvgPoolNd):\n\n    __constants__ = [\n        \"kernel_size\",\n        \"stride\",\n        \"padding\",\n        \"ceil_mode\",\n        \"count_include_pad\",\n        \"divisor_override\",\n    ]\n\n    kernel_size: _size_2_t\n    stride: _size_2_t\n    padding: _size_2_t\n    ceil_mode: bool\n    count_include_pad: bool\n\n    def __init__(\n        self,\n        kernel_size: _size_2_t,\n        stride: Optional[_size_2_t] = None,\n        padding: _size_2_t = 0,\n        ceil_mode: bool = False,\n        count_include_pad: bool = True,\n        divisor_override: Optional[int] = None,\n    ) -> None:\n        super().__init__()\n        self.kernel_size = kernel_size\n        self.stride = stride if (stride is not None) else kernel_size\n        self.padding = padding\n        self.ceil_mode = ceil_mode\n        self.count_include_pad = count_include_pad\n        self.divisor_override = divisor_override\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.avg_pool2d(\n            input,\n            self.kernel_size,\n            self.stride,\n            self.padding,\n            self.ceil_mode,\n            self.count_include_pad,\n            self.divisor_override,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.AvgPool3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 767,
      "end_line": 883,
      "code": "class AvgPool3d(_AvgPoolNd):\n\n    __constants__ = [\n        \"kernel_size\",\n        \"stride\",\n        \"padding\",\n        \"ceil_mode\",\n        \"count_include_pad\",\n        \"divisor_override\",\n    ]\n\n    kernel_size: _size_3_t\n    stride: _size_3_t\n    padding: _size_3_t\n    ceil_mode: bool\n    count_include_pad: bool\n\n    def __init__(\n        self,\n        kernel_size: _size_3_t,\n        stride: Optional[_size_3_t] = None,\n        padding: _size_3_t = 0,\n        ceil_mode: bool = False,\n        count_include_pad: bool = True,\n        divisor_override: Optional[int] = None,\n    ) -> None:\n        super().__init__()\n        self.kernel_size = kernel_size\n        self.stride = stride if (stride is not None) else kernel_size\n        self.padding = padding\n        self.ceil_mode = ceil_mode\n        self.count_include_pad = count_include_pad\n        self.divisor_override = divisor_override\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.avg_pool3d(\n            input,\n            self.kernel_size,\n            self.stride,\n            self.padding,\n            self.ceil_mode,\n            self.count_include_pad,\n            self.divisor_override,\n        )\n\n    def __setstate__(self, d):\n        super().__setstate__(d)\n        self.__dict__.setdefault(\"padding\", 0)\n        self.__dict__.setdefault(\"ceil_mode\", False)\n        self.__dict__.setdefault(\"count_include_pad\", True)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.FractionalMaxPool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 886,
      "end_line": 972,
      "code": "class FractionalMaxPool2d(Module):\n\n    __constants__ = [\"kernel_size\", \"return_indices\", \"output_size\", \"output_ratio\"]\n\n    kernel_size: _size_2_t\n    return_indices: bool\n    output_size: _size_2_t\n    output_ratio: _ratio_2_t\n\n    def __init__(\n        self,\n        kernel_size: _size_2_t,\n        output_size: Optional[_size_2_t] = None,\n        output_ratio: Optional[_ratio_2_t] = None,\n        return_indices: bool = False,\n        _random_samples=None,\n    ) -> None:\n        super().__init__()\n        self.kernel_size = _pair(kernel_size)\n        self.return_indices = return_indices\n        self.register_buffer(\"_random_samples\", _random_samples)\n        self.output_size = _pair(output_size) if output_size is not None else None\n        self.output_ratio = _pair(output_ratio) if output_ratio is not None else None\n        if output_size is None and output_ratio is None:\n            raise ValueError(\n                \"FractionalMaxPool2d requires specifying either \"\n                \"an output size, or a pooling ratio\"\n            )\n        if output_size is not None and output_ratio is not None:\n            raise ValueError(\n                \"only one of output_size and output_ratio may be specified\"\n            )\n        if self.output_ratio is not None:\n            if not (0 < self.output_ratio[0] < 1 and 0 < self.output_ratio[1] < 1):\n                raise ValueError(\n                    f\"output_ratio must be between 0 and 1 (got {output_ratio})\"\n                )\n\n    def forward(self, input: Tensor):\n        return F.fractional_max_pool2d(\n            input,\n            self.kernel_size,\n            self.output_size,\n            self.output_ratio,\n            self.return_indices,\n            _random_samples=self._random_samples,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LPPool1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 1090,
      "end_line": 1129,
      "code": "class LPPool1d(_LPPoolNd):\n\n    kernel_size: _size_1_t\n    stride: _size_1_t\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.lp_pool1d(\n            input, float(self.norm_type), self.kernel_size, self.stride, self.ceil_mode\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LPPool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 1132,
      "end_line": 1184,
      "code": "class LPPool2d(_LPPoolNd):\n\n    kernel_size: _size_2_t\n    stride: _size_2_t\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.lp_pool2d(\n            input, float(self.norm_type), self.kernel_size, self.stride, self.ceil_mode\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.AdaptiveMaxPool1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 1265,
      "end_line": 1292,
      "code": "class AdaptiveMaxPool1d(_AdaptiveMaxPoolNd):\n\n    output_size: _size_1_t\n\n    def forward(self, input: Tensor):\n        return F.adaptive_max_pool1d(input, self.output_size, self.return_indices)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.AdaptiveMaxPool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 1295,
      "end_line": 1334,
      "code": "class AdaptiveMaxPool2d(_AdaptiveMaxPoolNd):\n\n    output_size: _size_2_opt_t\n\n    def forward(self, input: Tensor):\n        return F.adaptive_max_pool2d(input, self.output_size, self.return_indices)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.AdaptiveMaxPool3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 1337,
      "end_line": 1377,
      "code": "class AdaptiveMaxPool3d(_AdaptiveMaxPoolNd):\n\n    output_size: _size_3_opt_t\n\n    def forward(self, input: Tensor):\n        return F.adaptive_max_pool3d(input, self.output_size, self.return_indices)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.AdaptiveAvgPool1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 1391,
      "end_line": 1416,
      "code": "class AdaptiveAvgPool1d(_AdaptiveAvgPoolNd):\n\n    output_size: _size_1_t\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.adaptive_avg_pool1d(input, self.output_size)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.AdaptiveAvgPool2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 1419,
      "end_line": 1455,
      "code": "class AdaptiveAvgPool2d(_AdaptiveAvgPoolNd):\n\n    output_size: _size_2_opt_t\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.adaptive_avg_pool2d(input, self.output_size)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.AdaptiveAvgPool3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py",
      "start_line": 1458,
      "end_line": 1494,
      "code": "class AdaptiveAvgPool3d(_AdaptiveAvgPoolNd):\n\n    output_size: _size_3_opt_t\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.adaptive_avg_pool3d(input, self.output_size)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ReflectionPad1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\padding.py",
      "start_line": 374,
      "end_line": 412,
      "code": "class ReflectionPad1d(_ReflectionPadNd):\n\n    padding: Tuple[int, int]\n\n    def __init__(self, padding: _size_2_t) -> None:\n        super().__init__()\n        self.padding = _pair(padding)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ReflectionPad2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\padding.py",
      "start_line": 415,
      "end_line": 465,
      "code": "class ReflectionPad2d(_ReflectionPadNd):\n\n    padding: Tuple[int, int, int, int]\n\n    def __init__(self, padding: _size_4_t) -> None:\n        super().__init__()\n        self.padding = _quadruple(padding)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ReplicationPad1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\padding.py",
      "start_line": 533,
      "end_line": 571,
      "code": "class ReplicationPad1d(_ReplicationPadNd):\n\n    padding: Tuple[int, int]\n\n    def __init__(self, padding: _size_2_t) -> None:\n        super().__init__()\n        self.padding = _pair(padding)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ReplicationPad2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\padding.py",
      "start_line": 574,
      "end_line": 623,
      "code": "class ReplicationPad2d(_ReplicationPadNd):\n\n    padding: Tuple[int, int, int, int]\n\n    def __init__(self, padding: _size_4_t) -> None:\n        super().__init__()\n        self.padding = _quadruple(padding)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ReplicationPad3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\padding.py",
      "start_line": 626,
      "end_line": 664,
      "code": "class ReplicationPad3d(_ReplicationPadNd):\n\n    padding: Tuple[int, int, int, int, int, int]\n\n    def __init__(self, padding: _size_6_t) -> None:\n        super().__init__()\n        self.padding = _ntuple(6)(padding)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ZeroPad2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\padding.py",
      "start_line": 720,
      "end_line": 771,
      "code": "class ZeroPad2d(ConstantPad2d):\n\n    padding: Tuple[int, int, int, int]\n\n    def __init__(self, padding: _size_4_t) -> None:\n        super().__init__(padding, 0.0)\n\n    def extra_repr(self) -> str:\n        return f\"{self.padding}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ConstantPad1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\padding.py",
      "start_line": 221,
      "end_line": 269,
      "code": "class ConstantPad1d(_ConstantPadNd):\n\n    padding: Tuple[int, int]\n\n    def __init__(self, padding: _size_2_t, value: float):\n        super().__init__(value)\n        self.padding = _pair(padding)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ConstantPad2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\padding.py",
      "start_line": 272,
      "end_line": 320,
      "code": "class ConstantPad2d(_ConstantPadNd):\n\n    __constants__ = [\"padding\", \"value\"]\n    padding: Tuple[int, int, int, int]\n\n    def __init__(self, padding: _size_4_t, value: float) -> None:\n        super().__init__(value)\n        self.padding = _quadruple(padding)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ConstantPad3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\padding.py",
      "start_line": 323,
      "end_line": 360,
      "code": "class ConstantPad3d(_ConstantPadNd):\n\n    padding: Tuple[int, int, int, int, int, int]\n\n    def __init__(self, padding: _size_6_t, value: float) -> None:\n        super().__init__(value)\n        self.padding = _ntuple(6)(padding)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ELU": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 520,
      "end_line": 565,
      "code": "class ELU(Module):\n\n    __constants__ = [\"alpha\", \"inplace\"]\n    alpha: float\n    inplace: bool\n\n    def __init__(self, alpha: float = 1.0, inplace: bool = False) -> None:\n        super().__init__()\n        self.alpha = alpha\n        self.inplace = inplace\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.elu(input, self.alpha, self.inplace)\n\n    def extra_repr(self) -> str:\n        inplace_str = \", inplace=True\" if self.inplace else \"\"\n        return f\"alpha={self.alpha}{inplace_str}\"\n"
    },
    "cpp": {
      "function": "elu_out",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 270,
      "end_line": 274,
      "code": "TORCH_IMPL_FUNC(elu_out) (\n  const Tensor& self, const Scalar& alpha, const Scalar& scale, const Scalar& input_scale, const Tensor& result\n) {\n  elu_stub(device_type(), *this, alpha, scale, input_scale);\n}\n"
    }
  },
  "torch.nn.Hardshrink": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 740,
      "end_line": 780,
      "code": "class Hardshrink(Module):\n\n    __constants__ = [\"lambd\"]\n    lambd: float\n\n    def __init__(self, lambd: float = 0.5) -> None:\n        super().__init__()\n        self.lambd = lambd\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.hardshrink(input, self.lambd)\n\n    def extra_repr(self) -> str:\n        return f\"{self.lambd}\"\n"
    },
    "cpp": {
      "function": "hardshrink_out",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 350,
      "end_line": 354,
      "code": "TORCH_IMPL_FUNC(hardshrink_out) (\n  const Tensor & self, const Scalar& lambd, const Tensor& result\n) {\n  hardshrink_stub(device_type(), *this, lambd);\n}\n"
    }
  },
  "torch.nn.Hardsigmoid": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 330,
      "end_line": 367,
      "code": "class Hardsigmoid(Module):\n\n    __constants__ = [\"inplace\"]\n\n    inplace: bool\n\n    def __init__(self, inplace: bool = False) -> None:\n        super().__init__()\n        self.inplace = inplace\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.hardsigmoid(input, self.inplace)\n"
    },
    "cpp": {
      "function": "hardsigmoid_quantized_cpu",
      "file": "aten/src/ATen/native/quantized/cpu/qhardsigmoid.cpp",
      "start_line": 90,
      "end_line": 100,
      "code": "Tensor hardsigmoid_quantized_cpu(const Tensor& qx) {\n#ifdef USE_PYTORCH_QNNPACK\n  if (at::globalContext().qEngine() == at::QEngine::QNNPACK &&\n      qx.scalar_type() == kQUInt8) {\n    return qnnpack_hardsigmoid(qx);\n  }\n#endif  // USE_PYTORCH_QNNPACK\n  Tensor qy;\n  qhardsigmoid_stub(qx.device().type(), qx, qy);\n  return qy;\n}\n"
    }
  },
  "torch.nn.Hardtanh": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 200,
      "end_line": 273,
      "code": "class Hardtanh(Module):\n\n    __constants__ = [\"min_val\", \"max_val\", \"inplace\"]\n\n    min_val: float\n    max_val: float\n    inplace: bool\n\n    def __init__(\n        self,\n        min_val: float = -1.0,\n        max_val: float = 1.0,\n        inplace: bool = False,\n        min_value: Optional[float] = None,\n        max_value: Optional[float] = None,\n    ) -> None:\n        super().__init__()\n        if min_value is not None:\n            warnings.warn(\n                \"keyword argument `min_value` is deprecated and rename to `min_val`\",\n                FutureWarning,\n                stacklevel=2,\n            )\n            min_val = min_value\n        if max_value is not None:\n            warnings.warn(\n                \"keyword argument `max_value` is deprecated and rename to `max_val`\",\n                FutureWarning,\n                stacklevel=2,\n            )\n            max_val = max_value\n\n        self.min_val = min_val\n        self.max_val = max_val\n        self.inplace = inplace\n        assert self.max_val > self.min_val\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n\n    def extra_repr(self) -> str:\n        inplace_str = \", inplace=True\" if self.inplace else \"\"\n        return f\"min_val={self.min_val}, max_val={self.max_val}{inplace_str}\"\n"
    },
    "cpp": {
      "function": "hardtanh",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 433,
      "end_line": 436,
      "code": "Tensor hardtanh(const Tensor& self, const Scalar& min, const Scalar& max) {\n  Tensor result = at::empty_like(self);\n  return at::hardtanh_out(result, self, min, max);\n}\n"
    }
  },
  "torch.nn.Hardswish": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 478,
      "end_line": 517,
      "code": "class Hardswish(Module):\n\n    __constants__ = [\"inplace\"]\n\n    inplace: bool\n\n    def __init__(self, inplace: bool = False) -> None:\n        super().__init__()\n        self.inplace = inplace\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.hardswish(input, self.inplace)\n"
    },
    "cpp": {
      "function": "hardswish",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 474,
      "end_line": 484,
      "code": "Tensor hardswish(const Tensor& self) {\n  #if defined(C10_MOBILE) && defined(USE_XNNPACK)\n  if (xnnpack::use_hardswish(self)) {\n    return xnnpack::hardswish(self);\n  }\n  #endif\n  Tensor result;\n  auto iter = TensorIterator::unary_op(result, self);\n  hardswish_stub(iter.device_type(), iter);\n  return iter.output();\n}\n"
    }
  },
  "torch.nn.LeakyReLU": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 783,
      "end_line": 832,
      "code": "class LeakyReLU(Module):\n\n    __constants__ = [\"inplace\", \"negative_slope\"]\n    inplace: bool\n    negative_slope: float\n\n    def __init__(self, negative_slope: float = 1e-2, inplace: bool = False) -> None:\n        super().__init__()\n        self.negative_slope = negative_slope\n        self.inplace = inplace\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.leaky_relu(input, self.negative_slope, self.inplace)\n\n    def extra_repr(self) -> str:\n        inplace_str = \", inplace=True\" if self.inplace else \"\"\n        return f\"negative_slope={self.negative_slope}{inplace_str}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MultiheadAttention": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 973,
      "end_line": 1442,
      "code": "class MultiheadAttention(Module):\n\n    __constants__ = [\"batch_first\"]\n    bias_k: Optional[torch.Tensor]\n    bias_v: Optional[torch.Tensor]\n\n    def __init__(\n        self,\n        embed_dim,\n        num_heads,\n        dropout=0.0,\n        bias=True,\n        add_bias_kv=False,\n        add_zero_attn=False,\n        kdim=None,\n        vdim=None,\n        batch_first=False,\n        device=None,\n        dtype=None,\n    ) -> None:\n        if embed_dim <= 0 or num_heads <= 0:\n            raise ValueError(\n                f\"embed_dim and num_heads must be greater than 0,\"\n                f\" got embed_dim={embed_dim} and num_heads={num_heads} instead\"\n            )\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.kdim = kdim if kdim is not None else embed_dim\n        self.vdim = vdim if vdim is not None else embed_dim\n        self._qkv_same_embed_dim = self.kdim == embed_dim and self.vdim == embed_dim\n\n        self.num_heads = num_heads\n        self.dropout = dropout\n        self.batch_first = batch_first\n        self.head_dim = embed_dim // num_heads\n        assert (\n            self.head_dim * num_heads == self.embed_dim\n        ), \"embed_dim must be divisible by num_heads\"\n\n        if not self._qkv_same_embed_dim:\n            self.q_proj_weight = Parameter(\n                torch.empty((embed_dim, embed_dim), **factory_kwargs)\n            )\n            self.k_proj_weight = Parameter(\n                torch.empty((embed_dim, self.kdim), **factory_kwargs)\n            )\n            self.v_proj_weight = Parameter(\n                torch.empty((embed_dim, self.vdim), **factory_kwargs)\n            )\n            self.register_parameter(\"in_proj_weight\", None)\n        else:\n            self.in_proj_weight = Parameter(\n                torch.empty((3 * embed_dim, embed_dim), **factory_kwargs)\n            )\n            self.register_parameter(\"q_proj_weight\", None)\n            self.register_parameter(\"k_proj_weight\", None)\n            self.register_parameter(\"v_proj_weight\", None)\n\n        if bias:\n            self.in_proj_bias = Parameter(torch.empty(3 * embed_dim, **factory_kwargs))\n        else:\n            self.register_parameter(\"in_proj_bias\", None)\n        self.out_proj = NonDynamicallyQuantizableLinear(\n            embed_dim, embed_dim, bias=bias, **factory_kwargs\n        )\n\n        if add_bias_kv:\n            self.bias_k = Parameter(torch.empty((1, 1, embed_dim), **factory_kwargs))\n            self.bias_v = Parameter(torch.empty((1, 1, embed_dim), **factory_kwargs))\n        else:\n            self.bias_k = self.bias_v = None\n\n        self.add_zero_attn = add_zero_attn\n\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        if self._qkv_same_embed_dim:\n            xavier_uniform_(self.in_proj_weight)\n        else:\n            xavier_uniform_(self.q_proj_weight)\n            xavier_uniform_(self.k_proj_weight)\n            xavier_uniform_(self.v_proj_weight)\n\n        if self.in_proj_bias is not None:\n            constant_(self.in_proj_bias, 0.0)\n            constant_(self.out_proj.bias, 0.0)\n        if self.bias_k is not None:\n            xavier_normal_(self.bias_k)\n        if self.bias_v is not None:\n            xavier_normal_(self.bias_v)\n\n    def __setstate__(self, state):\n        # Support loading old MultiheadAttention checkpoints generated by v1.1.0\n        if \"_qkv_same_embed_dim\" not in state:\n            state[\"_qkv_same_embed_dim\"] = True\n\n        super().__setstate__(state)\n\n    def forward(\n        self,\n        query: Tensor,\n        key: Tensor,\n        value: Tensor,\n        key_padding_mask: Optional[Tensor] = None,\n        need_weights: bool = True,\n        attn_mask: Optional[Tensor] = None,\n        average_attn_weights: bool = True,\n        is_causal: bool = False,\n    ) -> Tuple[Tensor, Optional[Tensor]]:\n        r\"\"\"Compute attention outputs using query, key, and value embeddings.\n\n            Supports optional parameters for padding, masks and attention weights.\n\n        Args:\n            query: Query embeddings of shape :math:`(L, E_q)` for unbatched input, :math:`(L, N, E_q)` when ``batch_first=False``\n                or :math:`(N, L, E_q)` when ``batch_first=True``, where :math:`L` is the target sequence length,\n                :math:`N` is the batch size, and :math:`E_q` is the query embedding dimension ``embed_dim``.\n                Queries are compared against key-value pairs to produce the output.\n                See \"Attention Is All You Need\" for more details.\n            key: Key embeddings of shape :math:`(S, E_k)` for unbatched input, :math:`(S, N, E_k)` when ``batch_first=False``\n                or :math:`(N, S, E_k)` when ``batch_first=True``, where :math:`S` is the source sequence length,\n                :math:`N` is the batch size, and :math:`E_k` is the key embedding dimension ``kdim``.\n                See \"Attention Is All You Need\" for more details.\n            value: Value embeddings of shape :math:`(S, E_v)` for unbatched input, :math:`(S, N, E_v)` when\n                ``batch_first=False`` or :math:`(N, S, E_v)` when ``batch_first=True``, where :math:`S` is the source\n                sequence length, :math:`N` is the batch size, and :math:`E_v` is the value embedding dimension ``vdim``.\n                See \"Attention Is All You Need\" for more details.\n            key_padding_mask: If specified, a mask of shape :math:`(N, S)` indicating which elements within ``key``\n                to ignore for the purpose of attention (i.e. treat as \"padding\"). For unbatched `query`, shape should be :math:`(S)`.\n                Binary and float masks are supported.\n                For a binary mask, a ``True`` value indicates that the corresponding ``key`` value will be ignored for\n                the purpose of attention. For a float mask, it will be directly added to the corresponding ``key`` value.\n            need_weights: If specified, returns ``attn_output_weights`` in addition to ``attn_outputs``.\n                Set ``need_weights=False`` to use the optimized ``scaled_dot_product_attention``\n                and achieve the best performance for MHA.\n                Default: ``True``.\n            attn_mask: If specified, a 2D or 3D mask preventing attention to certain positions. Must be of shape\n                :math:`(L, S)` or :math:`(N\\cdot\\text{num\\_heads}, L, S)`, where :math:`N` is the batch size,\n                :math:`L` is the target sequence length, and :math:`S` is the source sequence length. A 2D mask will be\n                broadcasted across the batch while a 3D mask allows for a different mask for each entry in the batch.\n                Binary and float masks are supported. For a binary mask, a ``True`` value indicates that the\n                corresponding position is not allowed to attend. For a float mask, the mask values will be added to\n                the attention weight.\n                If both attn_mask and key_padding_mask are supplied, their types should match.\n            average_attn_weights: If true, indicates that the returned ``attn_weights`` should be averaged across\n                heads. Otherwise, ``attn_weights`` are provided separately per head. Note that this flag only has an\n                effect when ``need_weights=True``. Default: ``True`` (i.e. average weights across heads)\n            is_causal: If specified, applies a causal mask as attention mask.\n                Default: ``False``.\n                Warning:\n                ``is_causal`` provides a hint that ``attn_mask`` is the\n                causal mask. Providing incorrect hints can result in\n                incorrect execution, including forward and backward\n                compatibility.\n\n        Outputs:\n            - **attn_output** - Attention outputs of shape :math:`(L, E)` when input is unbatched,\n              :math:`(L, N, E)` when ``batch_first=False`` or :math:`(N, L, E)` when ``batch_first=True``,\n              where :math:`L` is the target sequence length, :math:`N` is the batch size, and :math:`E` is the\n              embedding dimension ``embed_dim``.\n            - **attn_output_weights** - Only returned when ``need_weights=True``. If ``average_attn_weights=True``,\n              returns attention weights averaged across heads of shape :math:`(L, S)` when input is unbatched or\n              :math:`(N, L, S)`, where :math:`N` is the batch size, :math:`L` is the target sequence length, and\n              :math:`S` is the source sequence length. If ``average_attn_weights=False``, returns attention weights per\n              head of shape :math:`(\\text{num\\_heads}, L, S)` when input is unbatched or :math:`(N, \\text{num\\_heads}, L, S)`.\n\n            .. note::\n                `batch_first` argument is ignored for unbatched inputs.\n        \"\"\"  # noqa: B950\n        why_not_fast_path = \"\"\n        if (\n            (attn_mask is not None and torch.is_floating_point(attn_mask))\n            or (key_padding_mask is not None)\n            and torch.is_floating_point(key_padding_mask)\n        ):\n            why_not_fast_path = \"floating-point masks are not supported for fast path.\"\n\n        is_batched = query.dim() == 3\n\n        key_padding_mask = F._canonical_mask(\n            mask=key_padding_mask,\n            mask_name=\"key_padding_mask\",\n            other_type=F._none_or_dtype(attn_mask),\n            other_name=\"attn_mask\",\n            target_type=query.dtype,\n        )\n\n        attn_mask = F._canonical_mask(\n            mask=attn_mask,\n            mask_name=\"attn_mask\",\n            other_type=None,\n            other_name=\"\",\n            target_type=query.dtype,\n            check_other=False,\n        )\n\n        is_fastpath_enabled = torch.backends.mha.get_fastpath_enabled()\n\n        if not is_fastpath_enabled:\n            why_not_fast_path = \"torch.backends.mha.get_fastpath_enabled() was not True\"\n        elif not is_batched:\n            why_not_fast_path = (\n                f\"input not batched; expected query.dim() of 3 but got {query.dim()}\"\n            )\n        elif query is not key or key is not value:\n            # When lifting this restriction, don't forget to either\n            # enforce that the dtypes all match or test cases where\n            # they don't!\n            why_not_fast_path = \"non-self attention was used (query, key, and value are not the same Tensor)\"\n        elif self.in_proj_bias is not None and query.dtype != self.in_proj_bias.dtype:\n            why_not_fast_path = f\"dtypes of query ({query.dtype}) and self.in_proj_bias ({self.in_proj_bias.dtype}) don't match\"\n        elif self.in_proj_weight is None:\n            why_not_fast_path = \"in_proj_weight was None\"\n        elif query.dtype != self.in_proj_weight.dtype:\n            # this case will fail anyway, but at least they'll get a useful error message.\n            why_not_fast_path = f\"dtypes of query ({query.dtype}) and self.in_proj_weight ({self.in_proj_weight.dtype}) don't match\"\n        elif self.training:\n            why_not_fast_path = \"training is enabled\"\n        elif (self.num_heads % 2) != 0:\n            why_not_fast_path = \"self.num_heads is not even\"\n        elif not self.batch_first:\n            why_not_fast_path = \"batch_first was not True\"\n        elif self.bias_k is not None:\n            why_not_fast_path = \"self.bias_k was not None\"\n        elif self.bias_v is not None:\n            why_not_fast_path = \"self.bias_v was not None\"\n        elif self.add_zero_attn:\n            why_not_fast_path = \"add_zero_attn was enabled\"\n        elif not self._qkv_same_embed_dim:\n            why_not_fast_path = \"_qkv_same_embed_dim was not True\"\n        elif query.is_nested and (\n            key_padding_mask is not None or attn_mask is not None\n        ):\n            why_not_fast_path = \"supplying both src_key_padding_mask and src_mask at the same time \\\n                                 is not supported with NestedTensor input\"\n        elif torch.is_autocast_enabled():\n            why_not_fast_path = \"autocast is enabled\"\n\n        if not why_not_fast_path:\n            tensor_args = (\n                query,\n                key,\n                value,\n                self.in_proj_weight,\n                self.in_proj_bias,\n                self.out_proj.weight,\n                self.out_proj.bias,\n            )\n            # We have to use list comprehensions below because TorchScript does not support\n            # generator expressions.\n            if torch.overrides.has_torch_function(tensor_args):\n                why_not_fast_path = \"some Tensor argument has_torch_function\"\n            elif _is_make_fx_tracing():\n                why_not_fast_path = \"we are running make_fx tracing\"\n            elif not all(_check_arg_device(x) for x in tensor_args):\n                why_not_fast_path = (\n                    \"some Tensor argument's device is neither one of \"\n                    f\"cpu, cuda or {torch.utils.backend_registration._privateuse1_backend_name}\"\n                )\n            elif torch.is_grad_enabled() and any(\n                _arg_requires_grad(x) for x in tensor_args\n            ):\n                why_not_fast_path = (\n                    \"grad is enabled and at least one of query or the \"\n                    \"input/output projection weights or biases requires_grad\"\n                )\n            if not why_not_fast_path:\n                merged_mask, mask_type = self.merge_masks(\n                    attn_mask, key_padding_mask, query\n                )\n\n                if self.in_proj_bias is not None and self.in_proj_weight is not None:\n                    return torch._native_multi_head_attention(\n                        query,\n                        key,\n                        value,\n                        self.embed_dim,\n                        self.num_heads,\n                        self.in_proj_weight,\n                        self.in_proj_bias,\n                        self.out_proj.weight,\n                        self.out_proj.bias,\n                        merged_mask,\n                        need_weights,\n                        average_attn_weights,\n                        mask_type,\n                    )\n\n        any_nested = query.is_nested or key.is_nested or value.is_nested\n        assert not any_nested, (\n            \"MultiheadAttention does not support NestedTensor outside of its fast path. \"\n            + f\"The fast path was not hit because {why_not_fast_path}\"\n        )\n\n        if self.batch_first and is_batched:\n            # make sure that the transpose op does not affect the \"is\" property\n            if key is value:\n                if query is key:\n                    query = key = value = query.transpose(1, 0)\n                else:\n                    query, key = (x.transpose(1, 0) for x in (query, key))\n                    value = key\n            else:\n                query, key, value = (x.transpose(1, 0) for x in (query, key, value))\n\n        if not self._qkv_same_embed_dim:\n            attn_output, attn_output_weights = F.multi_head_attention_forward(\n                query,\n                key,\n                value,\n                self.embed_dim,\n                self.num_heads,\n                self.in_proj_weight,\n                self.in_proj_bias,\n                self.bias_k,\n                self.bias_v,\n                self.add_zero_attn,\n                self.dropout,\n                self.out_proj.weight,\n                self.out_proj.bias,\n                training=self.training,\n                key_padding_mask=key_padding_mask,\n                need_weights=need_weights,\n                attn_mask=attn_mask,\n                use_separate_proj_weight=True,\n                q_proj_weight=self.q_proj_weight,\n                k_proj_weight=self.k_proj_weight,\n                v_proj_weight=self.v_proj_weight,\n                average_attn_weights=average_attn_weights,\n                is_causal=is_causal,\n            )\n        else:\n            attn_output, attn_output_weights = F.multi_head_attention_forward(\n                query,\n                key,\n                value,\n                self.embed_dim,\n                self.num_heads,\n                self.in_proj_weight,\n                self.in_proj_bias,\n                self.bias_k,\n                self.bias_v,\n                self.add_zero_attn,\n                self.dropout,\n                self.out_proj.weight,\n                self.out_proj.bias,\n                training=self.training,\n                key_padding_mask=key_padding_mask,\n                need_weights=need_weights,\n                attn_mask=attn_mask,\n                average_attn_weights=average_attn_weights,\n                is_causal=is_causal,\n            )\n        if self.batch_first and is_batched:\n            return attn_output.transpose(1, 0), attn_output_weights\n        else:\n            return attn_output, attn_output_weights\n\n    def merge_masks(\n        self,\n        attn_mask: Optional[Tensor],\n        key_padding_mask: Optional[Tensor],\n        query: Tensor,\n    ) -> Tuple[Optional[Tensor], Optional[int]]:\n        r\"\"\"Determine mask type and combine masks if necessary.\n\n        If only one mask is provided, that mask\n        and the corresponding mask type will be returned. If both masks are provided, they will be both\n        expanded to shape ``(batch_size, num_heads, seq_len, seq_len)``, combined with logical ``or``\n        and mask type 2 will be returned\n        Args:\n            attn_mask: attention mask of shape ``(seq_len, seq_len)``, mask type 0\n            key_padding_mask: padding mask of shape ``(batch_size, seq_len)``, mask type 1\n            query: query embeddings of shape ``(batch_size, seq_len, embed_dim)``\n        Returns:\n            merged_mask: merged mask\n            mask_type: merged mask type (0, 1, or 2)\n        \"\"\"\n        mask_type: Optional[int] = None\n        merged_mask: Optional[Tensor] = None\n\n        if key_padding_mask is not None:\n            mask_type = 1\n            merged_mask = key_padding_mask\n\n        if attn_mask is not None:\n            # In this branch query can't be a nested tensor, so it has a shape\n            batch_size, seq_len, _ = query.shape\n            mask_type = 2\n\n            # Always expands attn_mask to 4D\n            if attn_mask.dim() == 3:\n                attn_mask_expanded = attn_mask.view(batch_size, -1, seq_len, seq_len)\n            else:  # attn_mask.dim() == 2:\n                attn_mask_expanded = attn_mask.view(1, 1, seq_len, seq_len).expand(\n                    batch_size, self.num_heads, -1, -1\n                )\n            merged_mask = attn_mask_expanded\n\n            if key_padding_mask is not None:\n                key_padding_mask_expanded = key_padding_mask.view(\n                    batch_size, 1, 1, seq_len\n                ).expand(-1, self.num_heads, -1, -1)\n                merged_mask = attn_mask_expanded + key_padding_mask_expanded\n\n        # no attn_mask and no key_padding_mask, returns None, None\n        return merged_mask, mask_type\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.PReLU": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 1445,
      "end_line": 1515,
      "code": "class PReLU(Module):\n\n    __constants__ = [\"num_parameters\"]\n    num_parameters: int\n\n    def __init__(\n        self, num_parameters: int = 1, init: float = 0.25, device=None, dtype=None\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        self.num_parameters = num_parameters\n        super().__init__()\n        self.init = init\n        self.weight = Parameter(torch.empty(num_parameters, **factory_kwargs))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        torch.nn.init.constant_(self.weight, self.init)\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.prelu(input, self.weight)\n\n    def extra_repr(self) -> str:\n        return f\"num_parameters={self.num_parameters}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ReLU": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 97,
      "end_line": 137,
      "code": "class ReLU(Module):\n\n    __constants__ = [\"inplace\"]\n    inplace: bool\n\n    def __init__(self, inplace: bool = False):\n        super().__init__()\n        self.inplace = inplace\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.relu(input, inplace=self.inplace)\n\n    def extra_repr(self) -> str:\n        inplace_str = \"inplace=True\" if self.inplace else \"\"\n        return inplace_str\n"
    },
    "cpp": {
      "function": "relu",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 511,
      "end_line": 514,
      "code": "Tensor relu(const Tensor & self) {\n  TORCH_CHECK(self.scalar_type() != at::kBool, \"Boolean inputs not supported for relu\");\n  return at::clamp_min(self, 0);\n}\n"
    }
  },
  "torch.nn.ReLU6": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 276,
      "end_line": 303,
      "code": "class ReLU6(Hardtanh):\n\n    def __init__(self, inplace: bool = False):\n        super().__init__(0.0, 6.0, inplace)\n\n    def extra_repr(self) -> str:\n        inplace_str = \"inplace=True\" if self.inplace else \"\"\n        return inplace_str\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.RReLU": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 140,
      "end_line": 197,
      "code": "class RReLU(Module):\n\n    __constants__ = [\"lower\", \"upper\", \"inplace\"]\n\n    lower: float\n    upper: float\n    inplace: bool\n\n    def __init__(\n        self, lower: float = 1.0 / 8, upper: float = 1.0 / 3, inplace: bool = False\n    ):\n        super().__init__()\n        self.lower = lower\n        self.upper = upper\n        self.inplace = inplace\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.rrelu(input, self.lower, self.upper, self.training, self.inplace)\n\n    def extra_repr(self):\n        inplace_str = \", inplace=True\" if self.inplace else \"\"\n        return f\"lower={self.lower}, upper={self.upper}{inplace_str}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.SELU": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 613,
      "end_line": 660,
      "code": "class SELU(Module):\n\n    __constants__ = [\"inplace\"]\n    inplace: bool\n\n    def __init__(self, inplace: bool = False) -> None:\n        super().__init__()\n        self.inplace = inplace\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.selu(input, self.inplace)\n\n    def extra_repr(self) -> str:\n        inplace_str = \"inplace=True\" if self.inplace else \"\"\n        return inplace_str\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.CELU": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 568,
      "end_line": 610,
      "code": "class CELU(Module):\n\n    __constants__ = [\"alpha\", \"inplace\"]\n    alpha: float\n    inplace: bool\n\n    def __init__(self, alpha: float = 1.0, inplace: bool = False) -> None:\n        super().__init__()\n        self.alpha = alpha\n        self.inplace = inplace\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.celu(input, self.alpha, self.inplace)\n\n    def extra_repr(self) -> str:\n        inplace_str = \", inplace=True\" if self.inplace else \"\"\n        return f\"alpha={self.alpha}{inplace_str}\"\n"
    },
    "cpp": {
      "function": "celu",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 537,
      "end_line": 542,
      "code": "Tensor celu(const Tensor & self, const Scalar& alpha) {\n  TORCH_CHECK(alpha.to<double>() != 0,\n      \"ZeroDivisionError: alpha cannot be 0 for CELU\");\n  double inv_alpha = 1. / alpha.to<double>();\n  return at::elu(self, alpha, Scalar(1.0), Scalar(inv_alpha));\n}\n"
    }
  },
  "torch.nn.SiLU": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 395,
      "end_line": 436,
      "code": "class SiLU(Module):\n\n    __constants__ = [\"inplace\"]\n    inplace: bool\n\n    def __init__(self, inplace: bool = False):\n        super().__init__()\n        self.inplace = inplace\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.silu(input, inplace=self.inplace)\n\n    def extra_repr(self) -> str:\n        inplace_str = \"inplace=True\" if self.inplace else \"\"\n        return inplace_str\n"
    },
    "cpp": {
      "function": "NestedTensor_silu",
      "file": "aten/src/ATen/native/nested/NestedTensorUnaryOps.cpp",
      "start_line": 150,
      "end_line": 152,
      "code": "Tensor NestedTensor_silu(const Tensor& self){\n  return map_nt(self, at::silu);\n}\n"
    }
  },
  "torch.nn.Softplus": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 858,
      "end_line": 900,
      "code": "class Softplus(Module):\n\n    __constants__ = [\"beta\", \"threshold\"]\n    beta: float\n    threshold: float\n\n    def __init__(self, beta: float = 1.0, threshold: float = 20.0) -> None:\n        super().__init__()\n        self.beta = beta\n        self.threshold = threshold\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.softplus(input, self.beta, self.threshold)\n\n    def extra_repr(self) -> str:\n        return f\"beta={self.beta}, threshold={self.threshold}\"\n"
    },
    "cpp": {
      "function": "softplus_out",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 306,
      "end_line": 310,
      "code": "TORCH_IMPL_FUNC(softplus_out) (\n  const Tensor& self, const Scalar& beta, const Scalar& threshold, const Tensor& result\n) {\n  softplus_stub(device_type(), *this, beta, threshold);\n}\n"
    }
  },
  "torch.nn.Softshrink": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 903,
      "end_line": 941,
      "code": "class Softshrink(Module):\n\n    __constants__ = [\"lambd\"]\n    lambd: float\n\n    def __init__(self, lambd: float = 0.5) -> None:\n        super().__init__()\n        self.lambd = lambd\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.softshrink(input, self.lambd)\n\n    def extra_repr(self) -> str:\n        return str(self.lambd)\n"
    },
    "cpp": {
      "function": "softshrink_out",
      "file": "aten/src/ATen/native/Activation.cpp",
      "start_line": 362,
      "end_line": 366,
      "code": "TORCH_IMPL_FUNC(softshrink_out) (\n  const Tensor & self, const Scalar& lambd, const Tensor& result\n) {\n  softshrink_stub(device_type(), *this, lambd);\n}\n"
    }
  },
  "torch.nn.Threshold": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 48,
      "end_line": 94,
      "code": "class Threshold(Module):\n\n    __constants__ = [\"threshold\", \"value\", \"inplace\"]\n\n    threshold: float\n    value: float\n    inplace: bool\n\n    def __init__(self, threshold: float, value: float, inplace: bool = False) -> None:\n        super().__init__()\n        self.threshold = threshold\n        self.value = value\n        self.inplace = inplace\n        # TODO: check in THNN (if inplace == True, then assert value <= threshold)\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.threshold(input, self.threshold, self.value, self.inplace)\n\n    def extra_repr(self):\n        inplace_str = \", inplace=True\" if self.inplace else \"\"\n        return f\"threshold={self.threshold}, value={self.value}{inplace_str}\"\n"
    },
    "cpp": {
      "function": "threshold_quantized_cpu",
      "file": "aten/src/ATen/native/quantized/cpu/qthreshold.cpp",
      "start_line": 33,
      "end_line": 42,
      "code": "Tensor threshold_quantized_cpu(\n    const Tensor& qx,\n    const Scalar& threshold,\n    const Scalar& value) {\n  Tensor qy;\n  AT_DISPATCH_QINT_TYPES(qx.scalar_type(), \"threshold\", [&]() {\n    qy = quantized_threshold_impl(qx, threshold, value);\n  });\n  return qy;\n}\n"
    }
  },
  "torch.nn.Softmin": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 1564,
      "end_line": 1611,
      "code": "class Softmin(Module):\n\n    __constants__ = [\"dim\"]\n    dim: Optional[int]\n\n    def __init__(self, dim: Optional[int] = None) -> None:\n        super().__init__()\n        self.dim = dim\n\n    def __setstate__(self, state):\n        super().__setstate__(state)\n        if not hasattr(self, \"dim\"):\n            self.dim = None\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.softmin(input, self.dim, _stacklevel=5)\n\n    def extra_repr(self):\n        return f\"dim={self.dim}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Softmax": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 1614,
      "end_line": 1670,
      "code": "class Softmax(Module):\n\n    __constants__ = [\"dim\"]\n    dim: Optional[int]\n\n    def __init__(self, dim: Optional[int] = None) -> None:\n        super().__init__()\n        self.dim = dim\n\n    def __setstate__(self, state):\n        super().__setstate__(state)\n        if not hasattr(self, \"dim\"):\n            self.dim = None\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.softmax(input, self.dim, _stacklevel=5)\n\n    def extra_repr(self) -> str:\n        return f\"dim={self.dim}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LogSoftmax": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\activation.py",
      "start_line": 1703,
      "end_line": 1746,
      "code": "class LogSoftmax(Module):\n\n    __constants__ = [\"dim\"]\n    dim: Optional[int]\n\n    def __init__(self, dim: Optional[int] = None) -> None:\n        super().__init__()\n        self.dim = dim\n\n    def __setstate__(self, state):\n        super().__setstate__(state)\n        if not hasattr(self, \"dim\"):\n            self.dim = None\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.log_softmax(input, self.dim, _stacklevel=5)\n\n    def extra_repr(self):\n        return f\"dim={self.dim}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.AdaptiveLogSoftmaxWithLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\adaptive.py",
      "start_line": 20,
      "end_line": 330,
      "code": "class AdaptiveLogSoftmaxWithLoss(Module):\n r\"\"\"\n    Adaptive softmax is an approximate strategy for training models with large\n    output spaces. It is most effective when the label distribution is highly\n    imbalanced, for example in natural language modelling, where the word\n    frequency distribution approximately follows the `Zipf's law`_.\n\n    Adaptive softmax partitions the labels into several clusters, according to\n    their frequency. These clusters may contain different number of targets\n    each.\n    Additionally, clusters containing less frequent labels assign lower\n    dimensional embeddings to those labels, which speeds up the computation.\n    For each minibatch, only clusters for which at least one target is\n    present are evaluated.\n\n    The idea is that the clusters which are accessed frequently\n    (like the first one, containing most frequent labels), should also be cheap\n    to compute -- that is, contain a small number of assigned labels.\n\n    We highly recommend taking a look at the original paper for more details.\n\n    * :attr:`cutoffs` should be an ordered Sequence of integers sorted\n      in the increasing order.\n      It controls number of clusters and the partitioning of targets into\n      clusters. For example setting ``cutoffs = [10, 100, 1000]``\n      means that first `10` targets will be assigned\n      to the 'head' of the adaptive softmax, targets `11, 12, ..., 100` will be\n      assigned to the first cluster, and targets `101, 102, ..., 1000` will be\n      assigned to the second cluster, while targets\n      `1001, 1002, ..., n_classes - 1` will be assigned\n      to the last, third cluster.\n\n    * :attr:`div_value` is used to compute the size of each additional cluster,\n      which is given as\n      :math:`\\left\\lfloor\\frac{\\texttt{in\\_features}}{\\texttt{div\\_value}^{idx}}\\right\\rfloor`,\n      where :math:`idx` is the cluster index (with clusters\n      for less frequent words having larger indices,\n      and indices starting from :math:`1`).\n\n    * :attr:`head_bias` if set to True, adds a bias term to the 'head' of the\n      adaptive softmax. See paper for details. Set to False in the official\n      implementation.\n\n    .. warning::\n        Labels passed as inputs to this module should be sorted according to\n        their frequency. This means that the most frequent label should be\n        represented by the index `0`, and the least frequent\n        label should be represented by the index `n_classes - 1`.\n\n    .. note::\n        This module returns a ``NamedTuple`` with ``output``\n        and ``loss`` fields. See further documentation for details.\n\n    .. note::\n        To compute log-probabilities for all classes, the ``log_prob``\n        method can be used.\n\n    Args:\n        in_features (int): Number of features in the input tensor\n        n_classes (int): Number of classes in the dataset\n        cutoffs (Sequence): Cutoffs used to assign targets to their buckets\n        div_value (float, optional): value used as an exponent to compute sizes\n            of the clusters. Default: 4.0\n        head_bias (bool, optional): If ``True``, adds a bias term to the 'head' of the\n            adaptive softmax. Default: ``False``\n\n    Returns:\n        ``NamedTuple`` with ``output`` and ``loss`` fields:\n            * **output** is a Tensor of size ``N`` containing computed target\n              log probabilities for each example\n            * **loss** is a Scalar representing the computed negative\n              log likelihood loss\n\n    Shape:\n        - input: :math:`(N, \\texttt{in\\_features})` or :math:`(\\texttt{in\\_features})`\n        - target: :math:`(N)` or :math:`()` where each value satisfies :math:`0 <= \\texttt{target[i]} <= \\texttt{n\\_classes}`\n        - output1: :math:`(N)` or :math:`()`\n        - output2: ``Scalar``\n\n    .. _Zipf's law: https://en.wikipedia.org/wiki/Zipf%27s_law\n    \"\"\"\n\n    in_features: int\n    n_classes: int\n    cutoffs: List[int]\n    div_value: float\n    head_bias: bool\n    head: Linear\n    tail: ModuleList\n\n    def __init__(\n        self,\n        in_features: int,\n        n_classes: int,\n        cutoffs: Sequence[int],\n        div_value: float = 4.0,\n        head_bias: bool = False,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n\n        cutoffs = list(cutoffs)\n\n        if len(cutoffs) == 0:\n            raise ValueError(\"cutoffs should be a sequence of length larger than 0\")\n\n        if (\n            (cutoffs != sorted(cutoffs))\n            or (min(cutoffs) <= 0)\n            or (max(cutoffs) > (n_classes - 1))\n            or (len(set(cutoffs)) != len(cutoffs))\n            or any(int(c) != c for c in cutoffs)\n        ):\n            raise ValueError(\n                \"cutoffs should be a sequence of unique, positive \"\n                \"integers sorted in an increasing order, where \"\n                \"each value is between 1 and n_classes-1\"\n            )\n\n        self.in_features = in_features\n        self.n_classes = n_classes\n        self.cutoffs = cutoffs + [n_classes]\n        self.div_value = div_value\n        self.head_bias = head_bias\n\n        self.shortlist_size = self.cutoffs[0]\n        self.n_clusters = len(self.cutoffs) - 1\n        self.head_size = self.shortlist_size + self.n_clusters\n\n        self.head = Linear(\n            self.in_features, self.head_size, bias=self.head_bias, **factory_kwargs\n        )\n        self.tail = ModuleList()\n\n        for i in range(self.n_clusters):\n            hsz = int(self.in_features // (self.div_value ** (i + 1)))\n            osz = self.cutoffs[i + 1] - self.cutoffs[i]\n\n            projection = Sequential(\n                Linear(self.in_features, hsz, bias=False, **factory_kwargs),\n                Linear(hsz, osz, bias=False, **factory_kwargs),\n            )\n\n            self.tail.append(projection)\n\n    def reset_parameters(self) -> None:\n        self.head.reset_parameters()\n        for i2h, h2o in self.tail:\n            i2h.reset_parameters()\n            h2o.reset_parameters()\n\n    def forward(self, input_: Tensor, target_: Tensor) -> _ASMoutput:\n        targ_dim = target_.dim()\n\n        if targ_dim == 1:\n            if input_.size(0) != target_.size(0):\n                raise RuntimeError(\n                    \"Input and target should have the same size \"\n                    \"in the batch dimension.\"\n                )\n            if input_.dim() != 2:\n                raise RuntimeError(\n                    \"1D target tensor expects 2D input tensors, \"\n                    \"but found inputs with size\",\n                    input_.size(),\n                )\n        elif targ_dim == 0:\n            if input_.dim() != 1:\n                raise RuntimeError(\n                    \"0D target tensor expects 1D input tensors, \"\n                    \"but found inputs with size\",\n                    input_.size(),\n                )\n        else:\n            raise RuntimeError(\n                \"0D or 1D target tensor expected, \" \"multi-target not supported\"\n            )\n\n        is_batched = targ_dim > 0\n        input = input_ if is_batched else input_.unsqueeze(0)\n        target = target_ if is_batched else target_.unsqueeze(0)\n\n        used_rows = 0\n        batch_size = target.size(0)\n\n        output = input.new_zeros(batch_size)\n        gather_inds = target.new_empty(batch_size)\n\n        cutoff_values = [0] + self.cutoffs\n        for i in range(len(cutoff_values) - 1):\n            low_idx = cutoff_values[i]\n            high_idx = cutoff_values[i + 1]\n\n            target_mask = (target >= low_idx) & (target < high_idx)\n            row_indices = target_mask.nonzero().squeeze()\n\n            if row_indices.numel() == 0:\n                continue\n\n            if i == 0:\n                gather_inds.index_copy_(0, row_indices, target[target_mask])\n\n            else:\n                relative_target = target[target_mask] - low_idx\n                input_subset = input.index_select(0, row_indices)\n\n                cluster_output = self.tail[i - 1](input_subset)\n                cluster_index = self.shortlist_size + i - 1\n\n                gather_inds.index_fill_(0, row_indices, cluster_index)\n                cluster_logprob = F.log_softmax(cluster_output, dim=1)\n                local_logprob = cluster_logprob.gather(1, relative_target.unsqueeze(1))\n                output.index_copy_(0, row_indices, local_logprob.squeeze(1))\n\n            used_rows += row_indices.numel()\n\n        if used_rows != batch_size:\n            raise RuntimeError(\n                f\"Target values should be in [0, {self.n_classes - 1}], \"\n                f\"but values in range [{target.min().item()}, {target.max().item()}] \"\n                \"were found. \"\n            )\n\n        head_output = self.head(input)\n        head_logprob = F.log_softmax(head_output, dim=1)\n        output += head_logprob.gather(1, gather_inds.unsqueeze(1)).squeeze()\n        loss = (-output).mean()\n\n        if not is_batched:\n            output = output.squeeze(0)\n\n        return _ASMoutput(output, loss)\n\n    def _get_full_log_prob(self, input, head_output):\n        \"\"\"Given input tensor, and output of ``self.head``, compute the log of the full distribution.\"\"\"\n        out = input.new_empty((head_output.size(0), self.n_classes))\n        head_logprob = F.log_softmax(head_output, dim=1)\n\n        out[:, : self.shortlist_size] = head_logprob[:, : self.shortlist_size]\n\n        for i, (start_idx, stop_idx) in enumerate(zip(self.cutoffs, self.cutoffs[1:])):\n            cluster_output = self.tail[i](input)\n            cluster_logprob = F.log_softmax(cluster_output, dim=1)\n            output_logprob = cluster_logprob + head_logprob[\n                :, self.shortlist_size + i\n            ].unsqueeze(1)\n\n            out[:, start_idx:stop_idx] = output_logprob\n\n        return out\n\n    def log_prob(self, input: Tensor) -> Tensor:\n        r\"\"\"Compute log probabilities for all :math:`\\texttt{n\\_classes}`.\n\n        Args:\n            input (Tensor): a minibatch of examples\n\n        Returns:\n            log-probabilities of for each class :math:`c`\n            in range :math:`0 <= c <= \\texttt{n\\_classes}`, where :math:`\\texttt{n\\_classes}` is a\n            parameter passed to ``AdaptiveLogSoftmaxWithLoss`` constructor.\n\n        Shape:\n            - Input: :math:`(N, \\texttt{in\\_features})`\n            - Output: :math:`(N, \\texttt{n\\_classes})`\n\n        \"\"\"\n        head_output = self.head(input)\n        return self._get_full_log_prob(input, head_output)\n\n    def predict(self, input: Tensor) -> Tensor:\n        r\"\"\"Return the class with the highest probability for each example in the input minibatch.\n\n        This is equivalent to ``self.log_prob(input).argmax(dim=1)``, but is more efficient in some cases.\n\n        Args:\n            input (Tensor): a minibatch of examples\n\n        Returns:\n            output (Tensor): a class with the highest probability for each example\n\n        Shape:\n            - Input: :math:`(N, \\texttt{in\\_features})`\n            - Output: :math:`(N)`\n        \"\"\"\n        head_output = self.head(input)\n        output = torch.argmax(head_output, dim=1)\n        not_in_shortlist = output >= self.shortlist_size\n        all_in_shortlist = not (not_in_shortlist.any())\n\n        if all_in_shortlist:\n            return output\n\n        elif not_in_shortlist.all():\n            log_prob = self._get_full_log_prob(input, head_output)\n            return torch.argmax(log_prob, dim=1)\n\n        else:\n            log_prob = self._get_full_log_prob(\n                input[not_in_shortlist], head_output[not_in_shortlist]\n            )\n            output[not_in_shortlist] = torch.argmax(log_prob, dim=1)\n            return output\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.BatchNorm1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py",
      "start_line": 268,
      "end_line": 341,
      "code": "class BatchNorm1d(_BatchNorm):\n\n    def _check_input_dim(self, input):\n        if input.dim() != 2 and input.dim() != 3:\n            raise ValueError(f\"expected 2D or 3D input (got {input.dim()}D input)\")\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.BatchNorm2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py",
      "start_line": 378,
      "end_line": 452,
      "code": "class BatchNorm2d(_BatchNorm):\n\n    def _check_input_dim(self, input):\n        if input.dim() != 4:\n            raise ValueError(f\"expected 4D input (got {input.dim()}D input)\")\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.BatchNorm3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py",
      "start_line": 489,
      "end_line": 563,
      "code": "class BatchNorm3d(_BatchNorm):\n\n    def _check_input_dim(self, input):\n        if input.dim() != 5:\n            raise ValueError(f\"expected 5D input (got {input.dim()}D input)\")\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.GroupNorm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py",
      "start_line": 228,
      "end_line": 318,
      "code": "class GroupNorm(Module):\n\n    __constants__ = [\"num_groups\", \"num_channels\", \"eps\", \"affine\"]\n    num_groups: int\n    num_channels: int\n    eps: float\n    affine: bool\n\n    def __init__(\n        self,\n        num_groups: int,\n        num_channels: int,\n        eps: float = 1e-5,\n        affine: bool = True,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        if num_channels % num_groups != 0:\n            raise ValueError(\"num_channels must be divisible by num_groups\")\n\n        self.num_groups = num_groups\n        self.num_channels = num_channels\n        self.eps = eps\n        self.affine = affine\n        if self.affine:\n            self.weight = Parameter(torch.empty(num_channels, **factory_kwargs))\n            self.bias = Parameter(torch.empty(num_channels, **factory_kwargs))\n        else:\n            self.register_parameter(\"weight\", None)\n            self.register_parameter(\"bias\", None)\n\n        self.reset_parameters()\n\n    def reset_parameters(self) -> None:\n        if self.affine:\n            init.ones_(self.weight)\n            init.zeros_(self.bias)\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n\n    def extra_repr(self) -> str:\n        return \"{num_groups}, {num_channels}, eps={eps}, \" \"affine={affine}\".format(\n            **self.__dict__\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.SyncBatchNorm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py",
      "start_line": 600,
      "end_line": 883,
      "code": "class SyncBatchNorm(_BatchNorm):\n\n    def __init__(\n        self,\n        num_features: int,\n        eps: float = 1e-5,\n        momentum: Optional[float] = 0.1,\n        affine: bool = True,\n        track_running_stats: bool = True,\n        process_group: Optional[Any] = None,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__(\n            num_features, eps, momentum, affine, track_running_stats, **factory_kwargs\n        )\n        self.process_group = process_group\n\n    def _check_input_dim(self, input):\n        if input.dim() < 2:\n            raise ValueError(f\"expected at least 2D input (got {input.dim()}D input)\")\n\n    def _check_non_zero_input_channels(self, input):\n        if input.size(1) == 0:\n            raise ValueError(\n                \"SyncBatchNorm number of input channels should be non-zero\"\n            )\n\n    def forward(self, input: Tensor) -> Tensor:\n        self._check_input_dim(input)\n        self._check_non_zero_input_channels(input)\n\n        # exponential_average_factor is set to self.momentum\n        # (when it is available) only so that it gets updated\n        # in ONNX graph when this node is exported to ONNX.\n        if self.momentum is None:\n            exponential_average_factor = 0.0\n        else:\n            exponential_average_factor = self.momentum\n\n        if self.training and self.track_running_stats:\n            assert self.num_batches_tracked is not None\n            self.num_batches_tracked.add_(1)\n            if self.momentum is None:  # use cumulative moving average\n                exponential_average_factor = 1.0 / self.num_batches_tracked.item()\n            else:  # use exponential moving average\n                exponential_average_factor = self.momentum\n\n        r\"\"\"\n        Decide whether the mini-batch stats should be used for normalization rather than the buffers.\n        Mini-batch stats are used in training mode, and in eval mode when buffers are None.\n        \"\"\"\n        if self.training:\n            bn_training = True\n        else:\n            bn_training = (self.running_mean is None) and (self.running_var is None)\n\n        r\"\"\"\n        Buffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\n        passed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\n        used for normalization (i.e. in eval mode when buffers are not None).\n        \"\"\"\n        # If buffers are not to be tracked, ensure that they won't be updated\n        running_mean = (\n            self.running_mean if not self.training or self.track_running_stats else None\n        )\n        running_var = (\n            self.running_var if not self.training or self.track_running_stats else None\n        )\n\n        # Don't sync batchnorm stats in inference mode (model.eval()).\n        need_sync = (\n            bn_training\n            and self.training\n            and torch.distributed.is_available()\n            and torch.distributed.is_initialized()\n        )\n        if need_sync:\n            # currently only GPU/PrivateUse1 input is supported\n            if input.device.type not in [\n                \"cuda\",\n                torch._C._get_privateuse1_backend_name(),\n            ]:\n                raise ValueError(\n                    \"SyncBatchNorm expected input tensor to be on GPU or \"\n                    f\"{torch._C._get_privateuse1_backend_name()}\"\n                )\n\n            process_group = torch.distributed.group.WORLD\n            if self.process_group:\n                process_group = self.process_group\n            world_size = torch.distributed.get_world_size(process_group)\n            need_sync = world_size > 1\n\n        # fallback to framework BN when synchronization is not necessary\n        if not need_sync:\n            return F.batch_norm(\n                input,\n                running_mean,\n                running_var,\n                self.weight,\n                self.bias,\n                bn_training,\n                exponential_average_factor,\n                self.eps,\n            )\n        else:\n            assert bn_training\n            return sync_batch_norm.apply(\n                input,\n                self.weight,\n                self.bias,\n                running_mean,\n                running_var,\n                self.eps,\n                exponential_average_factor,\n                process_group,  # type: ignore[possibly-undefined]\n                world_size,  # type: ignore[possibly-undefined]\n            )\n\n    @classmethod\n    def convert_sync_batchnorm(cls, module, process_group=None):\n        r\"\"\"Converts all :attr:`BatchNorm*D` layers in the model to :class:`torch.nn.SyncBatchNorm` layers.\n\n        Args:\n            module (nn.Module): module containing one or more :attr:`BatchNorm*D` layers\n            process_group (optional): process group to scope synchronization,\n                default is the whole world\n\n        Returns:\n            The original :attr:`module` with the converted :class:`torch.nn.SyncBatchNorm`\n            layers. If the original :attr:`module` is a :attr:`BatchNorm*D` layer,\n            a new :class:`torch.nn.SyncBatchNorm` layer object will be returned\n            instead.\n\n        Example::\n\n            >>> # Network with nn.BatchNorm layer\n            >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA)\n            >>> module = torch.nn.Sequential(\n            >>>            torch.nn.Linear(20, 100),\n            >>>            torch.nn.BatchNorm1d(100),\n            >>>          ).cuda()\n            >>> # creating process group (optional)\n            >>> # ranks is a list of int identifying rank ids.\n            >>> ranks = list(range(8))\n            >>> r1, r2 = ranks[:4], ranks[4:]\n            >>> # Note: every rank calls into new_group for every\n            >>> # process group created, even if that rank is not\n            >>> # part of the group.\n            >>> # xdoctest: +SKIP(\"distributed\")\n            >>> process_groups = [torch.distributed.new_group(pids) for pids in [r1, r2]]\n            >>> process_group = process_groups[0 if dist.get_rank() <= 3 else 1]\n            >>> sync_bn_module = torch.nn.SyncBatchNorm.convert_sync_batchnorm(module, process_group)\n\n        \"\"\"\n        module_output = module\n        if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n            module_output = torch.nn.SyncBatchNorm(\n                module.num_features,\n                module.eps,\n                module.momentum,\n                module.affine,\n                module.track_running_stats,\n                process_group,\n            )\n            if module.affine:\n                with torch.no_grad():\n                    module_output.weight = module.weight\n                    module_output.bias = module.bias\n            module_output.running_mean = module.running_mean\n            module_output.running_var = module.running_var\n            module_output.num_batches_tracked = module.num_batches_tracked\n            module_output.training = module.training\n            if hasattr(module, \"qconfig\"):\n                module_output.qconfig = module.qconfig\n        for name, child in module.named_children():\n            module_output.add_module(\n                name, cls.convert_sync_batchnorm(child, process_group)\n            )\n        del module\n        return module_output\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.InstanceNorm1d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\instancenorm.py",
      "start_line": 127,
      "end_line": 201,
      "code": "class InstanceNorm1d(_InstanceNorm):\n\n    def _get_no_batch_dim(self):\n        return 2\n\n    def _check_input_dim(self, input):\n        if input.dim() not in (2, 3):\n            raise ValueError(f\"expected 2D or 3D input (got {input.dim()}D input)\")\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.InstanceNorm2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\instancenorm.py",
      "start_line": 241,
      "end_line": 317,
      "code": "class InstanceNorm2d(_InstanceNorm):\n\n    def _get_no_batch_dim(self):\n        return 3\n\n    def _check_input_dim(self, input):\n        if input.dim() not in (3, 4):\n            raise ValueError(f\"expected 3D or 4D input (got {input.dim()}D input)\")\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.InstanceNorm3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\instancenorm.py",
      "start_line": 358,
      "end_line": 433,
      "code": "class InstanceNorm3d(_InstanceNorm):\n\n    def _get_no_batch_dim(self):\n        return 4\n\n    def _check_input_dim(self, input):\n        if input.dim() not in (4, 5):\n            raise ValueError(f\"expected 4D or 5D input (got {input.dim()}D input)\")\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LayerNorm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py",
      "start_line": 94,
      "end_line": 225,
      "code": "class LayerNorm(Module):\n\n    __constants__ = [\"normalized_shape\", \"eps\", \"elementwise_affine\"]\n    normalized_shape: Tuple[int, ...]\n    eps: float\n    elementwise_affine: bool\n\n    def __init__(\n        self,\n        normalized_shape: _shape_t,\n        eps: float = 1e-5,\n        elementwise_affine: bool = True,\n        bias: bool = True,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        if isinstance(normalized_shape, numbers.Integral):\n            # mypy error: incompatible types in assignment\n            normalized_shape = (normalized_shape,)  # type: ignore[assignment]\n        self.normalized_shape = tuple(normalized_shape)  # type: ignore[arg-type]\n        self.eps = eps\n        self.elementwise_affine = elementwise_affine\n        if self.elementwise_affine:\n            self.weight = Parameter(\n                torch.empty(self.normalized_shape, **factory_kwargs)\n            )\n            if bias:\n                self.bias = Parameter(\n                    torch.empty(self.normalized_shape, **factory_kwargs)\n                )\n            else:\n                self.register_parameter(\"bias\", None)\n        else:\n            self.register_parameter(\"weight\", None)\n            self.register_parameter(\"bias\", None)\n\n        self.reset_parameters()\n\n    def reset_parameters(self) -> None:\n        if self.elementwise_affine:\n            init.ones_(self.weight)\n            if self.bias is not None:\n                init.zeros_(self.bias)\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.layer_norm(\n            input, self.normalized_shape, self.weight, self.bias, self.eps\n        )\n\n    def extra_repr(self) -> str:\n        return (\n            \"{normalized_shape}, eps={eps}, \"\n            \"elementwise_affine={elementwise_affine}\".format(**self.__dict__)\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LocalResponseNorm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py",
      "start_line": 17,
      "end_line": 66,
      "code": "class LocalResponseNorm(Module):\n\n    __constants__ = [\"size\", \"alpha\", \"beta\", \"k\"]\n    size: int\n    alpha: float\n    beta: float\n    k: float\n\n    def __init__(\n        self, size: int, alpha: float = 1e-4, beta: float = 0.75, k: float = 1.0\n    ) -> None:\n        super().__init__()\n        self.size = size\n        self.alpha = alpha\n        self.beta = beta\n        self.k = k\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.local_response_norm(input, self.size, self.alpha, self.beta, self.k)\n\n    def extra_repr(self):\n        return \"{size}, alpha={alpha}, beta={beta}, k={k}\".format(**self.__dict__)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.RNNBase": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py",
      "start_line": 48,
      "end_line": 464,
      "code": "class RNNBase(Module):\n\n    __constants__ = [\n        \"mode\",\n        \"input_size\",\n        \"hidden_size\",\n        \"num_layers\",\n        \"bias\",\n        \"batch_first\",\n        \"dropout\",\n        \"bidirectional\",\n        \"proj_size\",\n    ]\n    __jit_unused_properties__ = [\"all_weights\"]\n\n    mode: str\n    input_size: int\n    hidden_size: int\n    num_layers: int\n    bias: bool\n    batch_first: bool\n    dropout: float\n    bidirectional: bool\n    proj_size: int\n\n    def __init__(\n        self,\n        mode: str,\n        input_size: int,\n        hidden_size: int,\n        num_layers: int = 1,\n        bias: bool = True,\n        batch_first: bool = False,\n        dropout: float = 0.0,\n        bidirectional: bool = False,\n        proj_size: int = 0,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        self.mode = mode\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.bias = bias\n        self.batch_first = batch_first\n        self.dropout = float(dropout)\n        self.bidirectional = bidirectional\n        self.proj_size = proj_size\n        self._flat_weight_refs: List[Optional[weakref.ReferenceType[Parameter]]] = []\n        num_directions = 2 if bidirectional else 1\n\n        if (\n            not isinstance(dropout, numbers.Number)\n            or not 0 <= dropout <= 1\n            or isinstance(dropout, bool)\n        ):\n            raise ValueError(\n                \"dropout should be a number in range [0, 1] \"\n                \"representing the probability of an element being \"\n                \"zeroed\"\n            )\n        if dropout > 0 and num_layers == 1:\n            warnings.warn(\n                \"dropout option adds dropout after all but last \"\n                \"recurrent layer, so non-zero dropout expects \"\n                f\"num_layers greater than 1, but got dropout={dropout} and \"\n                f\"num_layers={num_layers}\"\n            )\n\n        if not isinstance(hidden_size, int):\n            raise TypeError(\n                f\"hidden_size should be of type int, got: {type(hidden_size).__name__}\"\n            )\n        if hidden_size <= 0:\n            raise ValueError(\"hidden_size must be greater than zero\")\n        if num_layers <= 0:\n            raise ValueError(\"num_layers must be greater than zero\")\n        if proj_size < 0:\n            raise ValueError(\n                \"proj_size should be a positive integer or zero to disable projections\"\n            )\n        if proj_size >= hidden_size:\n            raise ValueError(\"proj_size has to be smaller than hidden_size\")\n\n        if mode == \"LSTM\":\n            gate_size = 4 * hidden_size\n        elif mode == \"GRU\":\n            gate_size = 3 * hidden_size\n        elif mode == \"RNN_TANH\":\n            gate_size = hidden_size\n        elif mode == \"RNN_RELU\":\n            gate_size = hidden_size\n        else:\n            raise ValueError(\"Unrecognized RNN mode: \" + mode)\n\n        self._flat_weights_names = []\n        self._all_weights = []\n        for layer in range(num_layers):\n            for direction in range(num_directions):\n                real_hidden_size = proj_size if proj_size > 0 else hidden_size\n                layer_input_size = (\n                    input_size if layer == 0 else real_hidden_size * num_directions\n                )\n\n                w_ih = Parameter(\n                    torch.empty((gate_size, layer_input_size), **factory_kwargs)\n                )\n                w_hh = Parameter(\n                    torch.empty((gate_size, real_hidden_size), **factory_kwargs)\n                )\n                b_ih = Parameter(torch.empty(gate_size, **factory_kwargs))\n                # Second bias vector included for CuDNN compatibility. Only one\n                # bias vector is needed in standard definition.\n                b_hh = Parameter(torch.empty(gate_size, **factory_kwargs))\n                layer_params: Tuple[Tensor, ...] = ()\n                if self.proj_size == 0:\n                    if bias:\n                        layer_params = (w_ih, w_hh, b_ih, b_hh)\n                    else:\n                        layer_params = (w_ih, w_hh)\n                else:\n                    w_hr = Parameter(\n                        torch.empty((proj_size, hidden_size), **factory_kwargs)\n                    )\n                    if bias:\n                        layer_params = (w_ih, w_hh, b_ih, b_hh, w_hr)\n                    else:\n                        layer_params = (w_ih, w_hh, w_hr)\n\n                suffix = \"_reverse\" if direction == 1 else \"\"\n                param_names = [\"weight_ih_l{}{}\", \"weight_hh_l{}{}\"]\n                if bias:\n                    param_names += [\"bias_ih_l{}{}\", \"bias_hh_l{}{}\"]\n                if self.proj_size > 0:\n                    param_names += [\"weight_hr_l{}{}\"]\n                param_names = [x.format(layer, suffix) for x in param_names]\n\n                for name, param in zip(param_names, layer_params):\n                    setattr(self, name, param)\n                self._flat_weights_names.extend(param_names)\n                self._all_weights.append(param_names)\n\n        self._init_flat_weights()\n\n        self.reset_parameters()\n\n    def _init_flat_weights(self):\n        self._flat_weights = [\n            getattr(self, wn) if hasattr(self, wn) else None\n            for wn in self._flat_weights_names\n        ]\n        self._flat_weight_refs = [\n            weakref.ref(w) if w is not None else None for w in self._flat_weights\n        ]\n        self.flatten_parameters()\n\n    def __setattr__(self, attr, value):\n        if hasattr(self, \"_flat_weights_names\") and attr in self._flat_weights_names:\n            # keep self._flat_weights up to date if you do self.weight = ...\n            idx = self._flat_weights_names.index(attr)\n            self._flat_weights[idx] = value\n        super().__setattr__(attr, value)\n\n    def flatten_parameters(self) -> None:\n        \"\"\"Reset parameter data pointer so that they can use faster code paths.\n\n        Right now, this works only if the module is on the GPU and cuDNN is enabled.\n        Otherwise, it's a no-op.\n        \"\"\"\n        # Short-circuits if _flat_weights is only partially instantiated\n        if len(self._flat_weights) != len(self._flat_weights_names):\n            return\n\n        for w in self._flat_weights:\n            if not isinstance(w, Tensor):\n                return\n        # Short-circuits if any tensor in self._flat_weights is not acceptable to cuDNN\n        # or the tensors in _flat_weights are of different dtypes\n\n        first_fw = self._flat_weights[0]\n        dtype = first_fw.dtype\n        for fw in self._flat_weights:\n            if (\n                not isinstance(fw, Tensor)\n                or not (fw.dtype == dtype)\n                or not fw.is_cuda\n                or not torch.backends.cudnn.is_acceptable(fw)\n            ):\n                return\n\n        # If any parameters alias, we fall back to the slower, copying code path. This is\n        # a sufficient check, because overlapping parameter buffers that don't completely\n        # alias would break the assumptions of the uniqueness check in\n        # Module.named_parameters().\n        unique_data_ptrs = {p.data_ptr() for p in self._flat_weights}\n        if len(unique_data_ptrs) != len(self._flat_weights):\n            return\n\n        with torch.cuda.device_of(first_fw):\n            import torch.backends.cudnn.rnn as rnn\n\n            # Note: no_grad() is necessary since _cudnn_rnn_flatten_weight is\n            # an inplace operation on self._flat_weights\n            with torch.no_grad():\n                if torch._use_cudnn_rnn_flatten_weight():\n                    num_weights = 4 if self.bias else 2\n                    if self.proj_size > 0:\n                        num_weights += 1\n                    torch._cudnn_rnn_flatten_weight(\n                        self._flat_weights,\n                        num_weights,\n                        self.input_size,\n                        rnn.get_cudnn_mode(self.mode),\n                        self.hidden_size,\n                        self.proj_size,\n                        self.num_layers,\n                        self.batch_first,\n                        bool(self.bidirectional),\n                    )\n\n    def _apply(self, fn, recurse=True):\n        self._flat_weight_refs = []\n        ret = super()._apply(fn, recurse)\n\n        # Resets _flat_weights\n        # Note: be v. careful before removing this, as 3rd party device types\n        # likely rely on this behavior to properly .to() modules like LSTM.\n        self._init_flat_weights()\n\n        return ret\n\n    def reset_parameters(self) -> None:\n        stdv = 1.0 / math.sqrt(self.hidden_size) if self.hidden_size > 0 else 0\n        for weight in self.parameters():\n            init.uniform_(weight, -stdv, stdv)\n\n    def check_input(self, input: Tensor, batch_sizes: Optional[Tensor]) -> None:\n        if not torch.jit.is_scripting():\n            if (\n                input.dtype != self._flat_weights[0].dtype\n                and not torch._C._is_any_autocast_enabled()\n            ):\n                raise ValueError(\n                    f\"input must have the type {self._flat_weights[0].dtype}, got type {input.dtype}\"\n                )\n        expected_input_dim = 2 if batch_sizes is not None else 3\n        if input.dim() != expected_input_dim:\n            raise RuntimeError(\n                f\"input must have {expected_input_dim} dimensions, got {input.dim()}\"\n            )\n        if self.input_size != input.size(-1):\n            raise RuntimeError(\n                f\"input.size(-1) must be equal to input_size. Expected {self.input_size}, got {input.size(-1)}\"\n            )\n\n    def get_expected_hidden_size(\n        self, input: Tensor, batch_sizes: Optional[Tensor]\n    ) -> Tuple[int, int, int]:\n        if batch_sizes is not None:\n            mini_batch = int(batch_sizes[0])\n        else:\n            mini_batch = input.size(0) if self.batch_first else input.size(1)\n        num_directions = 2 if self.bidirectional else 1\n        if self.proj_size > 0:\n            expected_hidden_size = (\n                self.num_layers * num_directions,\n                mini_batch,\n                self.proj_size,\n            )\n        else:\n            expected_hidden_size = (\n                self.num_layers * num_directions,\n                mini_batch,\n                self.hidden_size,\n            )\n        return expected_hidden_size\n\n    def check_hidden_size(\n        self,\n        hx: Tensor,\n        expected_hidden_size: Tuple[int, int, int],\n        msg: str = \"Expected hidden size {}, got {}\",\n    ) -> None:\n        if hx.size() != expected_hidden_size:\n            raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n\n    def _weights_have_changed(self):\n        # Returns True if the weight tensors have changed since the last forward pass.\n        # This is the case when used with torch.func.functional_call(), for example.\n        weights_changed = False\n        for ref, name in zip(self._flat_weight_refs, self._flat_weights_names):\n            weight = getattr(self, name) if hasattr(self, name) else None\n            if weight is not None and ref is not None and ref() is not weight:\n                weights_changed = True\n                break\n        return weights_changed\n\n    def check_forward_args(\n        self, input: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]\n    ):\n        self.check_input(input, batch_sizes)\n        expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)\n\n        self.check_hidden_size(hidden, expected_hidden_size)\n\n    def permute_hidden(self, hx: Tensor, permutation: Optional[Tensor]):\n        if permutation is None:\n            return hx\n        return _apply_permutation(hx, permutation)\n\n    def extra_repr(self) -> str:\n        s = \"{input_size}, {hidden_size}\"\n        if self.proj_size != 0:\n            s += \", proj_size={proj_size}\"\n        if self.num_layers != 1:\n            s += \", num_layers={num_layers}\"\n        if self.bias is not True:\n            s += \", bias={bias}\"\n        if self.batch_first is not False:\n            s += \", batch_first={batch_first}\"\n        if self.dropout != 0:\n            s += \", dropout={dropout}\"\n        if self.bidirectional is not False:\n            s += \", bidirectional={bidirectional}\"\n        return s.format(**self.__dict__)\n\n    def _update_flat_weights(self):\n        if not torch.jit.is_scripting():\n            if self._weights_have_changed():\n                self._init_flat_weights()\n\n    def __getstate__(self):\n        # If weights have been changed, update the _flat_weights in __getstate__ here.\n        self._update_flat_weights()\n        # Don't serialize the weight references.\n        state = self.__dict__.copy()\n        del state[\"_flat_weight_refs\"]\n        return state\n\n    def __setstate__(self, d):\n        super().__setstate__(d)\n        if \"all_weights\" in d:\n            self._all_weights = d[\"all_weights\"]\n        # In PyTorch 1.8 we added a proj_size member variable to LSTM.\n        # LSTMs that were serialized via torch.save(module) before PyTorch 1.8\n        # don't have it, so to preserve compatibility we set proj_size here.\n        if \"proj_size\" not in d:\n            self.proj_size = 0\n\n        if not isinstance(self._all_weights[0][0], str):\n            num_layers = self.num_layers\n            num_directions = 2 if self.bidirectional else 1\n            self._flat_weights_names = []\n            self._all_weights = []\n            for layer in range(num_layers):\n                for direction in range(num_directions):\n                    suffix = \"_reverse\" if direction == 1 else \"\"\n                    weights = [\n                        \"weight_ih_l{}{}\",\n                        \"weight_hh_l{}{}\",\n                        \"bias_ih_l{}{}\",\n                        \"bias_hh_l{}{}\",\n                        \"weight_hr_l{}{}\",\n                    ]\n                    weights = [x.format(layer, suffix) for x in weights]\n                    if self.bias:\n                        if self.proj_size > 0:\n                            self._all_weights += [weights]\n                            self._flat_weights_names.extend(weights)\n                        else:\n                            self._all_weights += [weights[:4]]\n                            self._flat_weights_names.extend(weights[:4])\n                    else:\n                        if self.proj_size > 0:\n                            self._all_weights += [weights[:2]] + [weights[-1:]]\n                            self._flat_weights_names.extend(\n                                weights[:2] + [weights[-1:]]\n                            )\n                        else:\n                            self._all_weights += [weights[:2]]\n                            self._flat_weights_names.extend(weights[:2])\n            self._flat_weights = [\n                getattr(self, wn) if hasattr(self, wn) else None\n                for wn in self._flat_weights_names\n            ]\n\n        self._flat_weight_refs = [\n            weakref.ref(w) if w is not None else None for w in self._flat_weights\n        ]\n\n    @property\n    def all_weights(self) -> List[List[Parameter]]:\n        return [\n            [getattr(self, weight) for weight in weights]\n            for weights in self._all_weights\n        ]\n\n    def _replicate_for_data_parallel(self):\n        replica = super()._replicate_for_data_parallel()\n        # Need to copy these caches, otherwise the replica will share the same\n        # flat weights list.\n        replica._flat_weights = replica._flat_weights[:]\n        replica._flat_weights_names = replica._flat_weights_names[:]\n        return replica\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.RNN": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py",
      "start_line": 467,
      "end_line": 776,
      "code": "class RNN(RNNBase):\n\n    @overload\n    def __init__(\n        self,\n        input_size: int,\n        hidden_size: int,\n        num_layers: int = 1,\n        nonlinearity: str = \"tanh\",\n        bias: bool = True,\n        batch_first: bool = False,\n        dropout: float = 0.0,\n        bidirectional: bool = False,\n        device=None,\n        dtype=None,\n    ) -> None:\n        ...\n\n    @overload\n    def __init__(self, *args, **kwargs):\n        ...\n\n    def __init__(self, *args, **kwargs):\n        if \"proj_size\" in kwargs:\n            raise ValueError(\n                \"proj_size argument is only supported for LSTM, not RNN or GRU\"\n            )\n        if len(args) > 3:\n            self.nonlinearity = args[3]\n            args = args[:3] + args[4:]\n        else:\n            self.nonlinearity = kwargs.pop(\"nonlinearity\", \"tanh\")\n        if self.nonlinearity == \"tanh\":\n            mode = \"RNN_TANH\"\n        elif self.nonlinearity == \"relu\":\n            mode = \"RNN_RELU\"\n        else:\n            raise ValueError(\n                f\"Unknown nonlinearity '{self.nonlinearity}'. Select from 'tanh' or 'relu'.\"\n            )\n        super().__init__(mode, *args, **kwargs)\n\n    @overload\n    @torch._jit_internal._overload_method  # noqa: F811\n    def forward(\n        self, input: Tensor, hx: Optional[Tensor] = None\n    ) -> Tuple[Tensor, Tensor]:\n        pass\n\n    @overload\n    @torch._jit_internal._overload_method  # noqa: F811\n    def forward(\n        self, input: PackedSequence, hx: Optional[Tensor] = None\n    ) -> Tuple[PackedSequence, Tensor]:\n        pass\n\n    def forward(self, input, hx=None):  # noqa: F811\n        self._update_flat_weights()\n\n        num_directions = 2 if self.bidirectional else 1\n        orig_input = input\n\n        if isinstance(orig_input, PackedSequence):\n            input, batch_sizes, sorted_indices, unsorted_indices = input\n            max_batch_size = batch_sizes[0]\n            # script() is unhappy when max_batch_size is different type in cond branches, so we duplicate\n            if hx is None:\n                hx = torch.zeros(\n                    self.num_layers * num_directions,\n                    max_batch_size,\n                    self.hidden_size,\n                    dtype=input.dtype,\n                    device=input.device,\n                )\n            else:\n                # Each batch of the hidden state should match the input sequence that\n                # the user believes he/she is passing in.\n                hx = self.permute_hidden(hx, sorted_indices)\n        else:\n            batch_sizes = None\n            if input.dim() not in (2, 3):\n                raise ValueError(\n                    f\"RNN: Expected input to be 2D or 3D, got {input.dim()}D tensor instead\"\n                )\n            is_batched = input.dim() == 3\n            batch_dim = 0 if self.batch_first else 1\n            if not is_batched:\n                input = input.unsqueeze(batch_dim)\n                if hx is not None:\n                    if hx.dim() != 2:\n                        raise RuntimeError(\n                            f\"For unbatched 2-D input, hx should also be 2-D but got {hx.dim()}-D tensor\"\n                        )\n                    hx = hx.unsqueeze(1)\n            else:\n                if hx is not None and hx.dim() != 3:\n                    raise RuntimeError(\n                        f\"For batched 3-D input, hx should also be 3-D but got {hx.dim()}-D tensor\"\n                    )\n            max_batch_size = input.size(0) if self.batch_first else input.size(1)\n            sorted_indices = None\n            unsorted_indices = None\n            if hx is None:\n                hx = torch.zeros(\n                    self.num_layers * num_directions,\n                    max_batch_size,\n                    self.hidden_size,\n                    dtype=input.dtype,\n                    device=input.device,\n                )\n            else:\n                # Each batch of the hidden state should match the input sequence that\n                # the user believes he/she is passing in.\n                hx = self.permute_hidden(hx, sorted_indices)\n\n        assert hx is not None\n        self.check_forward_args(input, hx, batch_sizes)\n        assert self.mode == \"RNN_TANH\" or self.mode == \"RNN_RELU\"\n        if batch_sizes is None:\n            if self.mode == \"RNN_TANH\":\n                result = _VF.rnn_tanh(\n                    input,\n                    hx,\n                    self._flat_weights,\n                    self.bias,\n                    self.num_layers,\n                    self.dropout,\n                    self.training,\n                    self.bidirectional,\n                    self.batch_first,\n                )\n            else:\n                result = _VF.rnn_relu(\n                    input,\n                    hx,\n                    self._flat_weights,\n                    self.bias,\n                    self.num_layers,\n                    self.dropout,\n                    self.training,\n                    self.bidirectional,\n                    self.batch_first,\n                )\n        else:\n            if self.mode == \"RNN_TANH\":\n                result = _VF.rnn_tanh(\n                    input,\n                    batch_sizes,\n                    hx,\n                    self._flat_weights,\n                    self.bias,\n                    self.num_layers,\n                    self.dropout,\n                    self.training,\n                    self.bidirectional,\n                )\n            else:\n                result = _VF.rnn_relu(\n                    input,\n                    batch_sizes,\n                    hx,\n                    self._flat_weights,\n                    self.bias,\n                    self.num_layers,\n                    self.dropout,\n                    self.training,\n                    self.bidirectional,\n                )\n\n        output = result[0]\n        hidden = result[1]\n\n        if isinstance(orig_input, PackedSequence):\n            output_packed = PackedSequence(\n                output, batch_sizes, sorted_indices, unsorted_indices\n            )\n            return output_packed, self.permute_hidden(hidden, unsorted_indices)\n\n        if not is_batched:  # type: ignore[possibly-undefined]\n            output = output.squeeze(batch_dim)  # type: ignore[possibly-undefined]\n            hidden = hidden.squeeze(1)\n\n        return output, self.permute_hidden(hidden, unsorted_indices)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LSTM": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py",
      "start_line": 793,
      "end_line": 1158,
      "code": "class LSTM(RNNBase):\n\n    @overload\n    def __init__(\n        self,\n        input_size: int,\n        hidden_size: int,\n        num_layers: int = 1,\n        bias: bool = True,\n        batch_first: bool = False,\n        dropout: float = 0.0,\n        bidirectional: bool = False,\n        proj_size: int = 0,\n        device=None,\n        dtype=None,\n    ) -> None:\n        ...\n\n    @overload\n    def __init__(self, *args, **kwargs):\n        ...\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(\"LSTM\", *args, **kwargs)\n\n    def get_expected_cell_size(\n        self, input: Tensor, batch_sizes: Optional[Tensor]\n    ) -> Tuple[int, int, int]:\n        if batch_sizes is not None:\n            mini_batch = int(batch_sizes[0])\n        else:\n            mini_batch = input.size(0) if self.batch_first else input.size(1)\n        num_directions = 2 if self.bidirectional else 1\n        expected_hidden_size = (\n            self.num_layers * num_directions,\n            mini_batch,\n            self.hidden_size,\n        )\n        return expected_hidden_size\n\n    # In the future, we should prevent mypy from applying contravariance rules here.\n    # See torch/nn/modules/module.py::_forward_unimplemented\n    def check_forward_args(\n        self,\n        input: Tensor,\n        hidden: Tuple[Tensor, Tensor],  # type: ignore[override]\n        batch_sizes: Optional[Tensor],\n    ):\n        self.check_input(input, batch_sizes)\n        self.check_hidden_size(\n            hidden[0],\n            self.get_expected_hidden_size(input, batch_sizes),\n            \"Expected hidden[0] size {}, got {}\",\n        )\n        self.check_hidden_size(\n            hidden[1],\n            self.get_expected_cell_size(input, batch_sizes),\n            \"Expected hidden[1] size {}, got {}\",\n        )\n\n    # Same as above, see torch/nn/modules/module.py::_forward_unimplemented\n    def permute_hidden(  # type: ignore[override]\n        self,\n        hx: Tuple[Tensor, Tensor],\n        permutation: Optional[Tensor],\n    ) -> Tuple[Tensor, Tensor]:\n        if permutation is None:\n            return hx\n        return _apply_permutation(hx[0], permutation), _apply_permutation(\n            hx[1], permutation\n        )\n\n    # Same as above, see torch/nn/modules/module.py::_forward_unimplemented\n    @overload  # type: ignore[override]\n    @torch._jit_internal._overload_method  # noqa: F811\n    def forward(\n        self, input: Tensor, hx: Optional[Tuple[Tensor, Tensor]] = None\n    ) -> Tuple[Tensor, Tuple[Tensor, Tensor]]:  # noqa: F811\n        pass\n\n    # Same as above, see torch/nn/modules/module.py::_forward_unimplemented\n    @overload\n    @torch._jit_internal._overload_method  # noqa: F811\n    def forward(\n        self, input: PackedSequence, hx: Optional[Tuple[Tensor, Tensor]] = None\n    ) -> Tuple[PackedSequence, Tuple[Tensor, Tensor]]:  # noqa: F811\n        pass\n\n    def forward(self, input, hx=None):  # noqa: F811\n        self._update_flat_weights()\n\n        orig_input = input\n        # xxx: isinstance check needs to be in conditional for TorchScript to compile\n        batch_sizes = None\n        do_permute = False\n        num_directions = 2 if self.bidirectional else 1\n        real_hidden_size = self.proj_size if self.proj_size > 0 else self.hidden_size\n        if isinstance(orig_input, PackedSequence):\n            input, batch_sizes, sorted_indices, unsorted_indices = input\n            max_batch_size = batch_sizes[0]\n            if hx is None:\n                h_zeros = torch.zeros(\n                    self.num_layers * num_directions,\n                    max_batch_size,\n                    real_hidden_size,\n                    dtype=input.dtype,\n                    device=input.device,\n                )\n                c_zeros = torch.zeros(\n                    self.num_layers * num_directions,\n                    max_batch_size,\n                    self.hidden_size,\n                    dtype=input.dtype,\n                    device=input.device,\n                )\n                hx = (h_zeros, c_zeros)\n            else:\n                # Each batch of the hidden state should match the input sequence that\n                # the user believes he/she is passing in.\n                hx = self.permute_hidden(hx, sorted_indices)\n        else:\n            if input.dim() not in (2, 3):\n                raise ValueError(\n                    f\"LSTM: Expected input to be 2D or 3D, got {input.dim()}D instead\"\n                )\n            is_batched = input.dim() == 3\n            batch_dim = 0 if self.batch_first else 1\n            if not is_batched:\n                input = input.unsqueeze(batch_dim)\n            max_batch_size = input.size(0) if self.batch_first else input.size(1)\n            sorted_indices = None\n            unsorted_indices = None\n            if hx is None:\n                h_zeros = torch.zeros(\n                    self.num_layers * num_directions,\n                    max_batch_size,\n                    real_hidden_size,\n                    dtype=input.dtype,\n                    device=input.device,\n                )\n                c_zeros = torch.zeros(\n                    self.num_layers * num_directions,\n                    max_batch_size,\n                    self.hidden_size,\n                    dtype=input.dtype,\n                    device=input.device,\n                )\n                hx = (h_zeros, c_zeros)\n                self.check_forward_args(input, hx, batch_sizes)\n            else:\n                if is_batched:\n                    if hx[0].dim() != 3 or hx[1].dim() != 3:\n                        msg = (\n                            \"For batched 3-D input, hx and cx should \"\n                            f\"also be 3-D but got ({hx[0].dim()}-D, {hx[1].dim()}-D) tensors\"\n                        )\n                        raise RuntimeError(msg)\n                else:\n                    if hx[0].dim() != 2 or hx[1].dim() != 2:\n                        msg = (\n                            \"For unbatched 2-D input, hx and cx should \"\n                            f\"also be 2-D but got ({hx[0].dim()}-D, {hx[1].dim()}-D) tensors\"\n                        )\n                        raise RuntimeError(msg)\n                    hx = (hx[0].unsqueeze(1), hx[1].unsqueeze(1))\n                # Each batch of the hidden state should match the input sequence that\n                # the user believes he/she is passing in.\n                self.check_forward_args(input, hx, batch_sizes)\n                hx = self.permute_hidden(hx, sorted_indices)\n\n        if batch_sizes is None:\n            result = _VF.lstm(\n                input,\n                hx,\n                self._flat_weights,\n                self.bias,\n                self.num_layers,\n                self.dropout,\n                self.training,\n                self.bidirectional,\n                self.batch_first,\n            )\n        else:\n            result = _VF.lstm(\n                input,\n                batch_sizes,\n                hx,\n                self._flat_weights,\n                self.bias,\n                self.num_layers,\n                self.dropout,\n                self.training,\n                self.bidirectional,\n            )\n        output = result[0]\n        hidden = result[1:]\n        # xxx: isinstance check needs to be in conditional for TorchScript to compile\n        if isinstance(orig_input, PackedSequence):\n            output_packed = PackedSequence(\n                output, batch_sizes, sorted_indices, unsorted_indices\n            )\n            return output_packed, self.permute_hidden(hidden, unsorted_indices)\n        else:\n            if not is_batched:  # type: ignore[possibly-undefined]\n                output = output.squeeze(batch_dim)  # type: ignore[possibly-undefined]\n                hidden = (hidden[0].squeeze(1), hidden[1].squeeze(1))\n            return output, self.permute_hidden(hidden, unsorted_indices)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.GRU": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py",
      "start_line": 1161,
      "end_line": 1429,
      "code": "class GRU(RNNBase):\n\n    @overload\n    def __init__(\n        self,\n        input_size: int,\n        hidden_size: int,\n        num_layers: int = 1,\n        bias: bool = True,\n        batch_first: bool = False,\n        dropout: float = 0.0,\n        bidirectional: bool = False,\n        device=None,\n        dtype=None,\n    ) -> None:\n        ...\n\n    @overload\n    def __init__(self, *args, **kwargs):\n        ...\n\n    def __init__(self, *args, **kwargs):\n        if \"proj_size\" in kwargs:\n            raise ValueError(\n                \"proj_size argument is only supported for LSTM, not RNN or GRU\"\n            )\n        super().__init__(\"GRU\", *args, **kwargs)\n\n    @overload  # type: ignore[override]\n    @torch._jit_internal._overload_method  # noqa: F811\n    def forward(\n        self, input: Tensor, hx: Optional[Tensor] = None\n    ) -> Tuple[Tensor, Tensor]:  # noqa: F811\n        pass\n\n    @overload\n    @torch._jit_internal._overload_method  # noqa: F811\n    def forward(\n        self, input: PackedSequence, hx: Optional[Tensor] = None\n    ) -> Tuple[PackedSequence, Tensor]:  # noqa: F811\n        pass\n\n    def forward(self, input, hx=None):  # noqa: F811\n        self._update_flat_weights()\n\n        orig_input = input\n        # xxx: isinstance check needs to be in conditional for TorchScript to compile\n        if isinstance(orig_input, PackedSequence):\n            input, batch_sizes, sorted_indices, unsorted_indices = input\n            max_batch_size = batch_sizes[0]\n            if hx is None:\n                num_directions = 2 if self.bidirectional else 1\n                hx = torch.zeros(\n                    self.num_layers * num_directions,\n                    max_batch_size,\n                    self.hidden_size,\n                    dtype=input.dtype,\n                    device=input.device,\n                )\n            else:\n                # Each batch of the hidden state should match the input sequence that\n                # the user believes he/she is passing in.\n                hx = self.permute_hidden(hx, sorted_indices)\n        else:\n            batch_sizes = None\n            if input.dim() not in (2, 3):\n                raise ValueError(\n                    f\"GRU: Expected input to be 2D or 3D, got {input.dim()}D instead\"\n                )\n            is_batched = input.dim() == 3\n            batch_dim = 0 if self.batch_first else 1\n            if not is_batched:\n                input = input.unsqueeze(batch_dim)\n                if hx is not None:\n                    if hx.dim() != 2:\n                        raise RuntimeError(\n                            f\"For unbatched 2-D input, hx should also be 2-D but got {hx.dim()}-D tensor\"\n                        )\n                    hx = hx.unsqueeze(1)\n            else:\n                if hx is not None and hx.dim() != 3:\n                    raise RuntimeError(\n                        f\"For batched 3-D input, hx should also be 3-D but got {hx.dim()}-D tensor\"\n                    )\n            max_batch_size = input.size(0) if self.batch_first else input.size(1)\n            sorted_indices = None\n            unsorted_indices = None\n            if hx is None:\n                num_directions = 2 if self.bidirectional else 1\n                hx = torch.zeros(\n                    self.num_layers * num_directions,\n                    max_batch_size,\n                    self.hidden_size,\n                    dtype=input.dtype,\n                    device=input.device,\n                )\n            else:\n                # Each batch of the hidden state should match the input sequence that\n                # the user believes he/she is passing in.\n                hx = self.permute_hidden(hx, sorted_indices)\n\n        self.check_forward_args(input, hx, batch_sizes)\n        if batch_sizes is None:\n            result = _VF.gru(\n                input,\n                hx,\n                self._flat_weights,\n                self.bias,\n                self.num_layers,\n                self.dropout,\n                self.training,\n                self.bidirectional,\n                self.batch_first,\n            )\n        else:\n            result = _VF.gru(\n                input,\n                batch_sizes,\n                hx,\n                self._flat_weights,\n                self.bias,\n                self.num_layers,\n                self.dropout,\n                self.training,\n                self.bidirectional,\n            )\n        output = result[0]\n        hidden = result[1]\n\n        # xxx: isinstance check needs to be in conditional for TorchScript to compile\n        if isinstance(orig_input, PackedSequence):\n            output_packed = PackedSequence(\n                output, batch_sizes, sorted_indices, unsorted_indices\n            )\n            return output_packed, self.permute_hidden(hidden, unsorted_indices)\n        else:\n            if not is_batched:  # type: ignore[possibly-undefined]\n                output = output.squeeze(batch_dim)  # type: ignore[possibly-undefined]\n                hidden = hidden.squeeze(1)\n\n            return output, self.permute_hidden(hidden, unsorted_indices)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.RNNCell": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py",
      "start_line": 1490,
      "end_line": 1606,
      "code": "class RNNCell(RNNCellBase):\n\n    __constants__ = [\"input_size\", \"hidden_size\", \"bias\", \"nonlinearity\"]\n    nonlinearity: str\n\n    def __init__(\n        self,\n        input_size: int,\n        hidden_size: int,\n        bias: bool = True,\n        nonlinearity: str = \"tanh\",\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__(input_size, hidden_size, bias, num_chunks=1, **factory_kwargs)\n        self.nonlinearity = nonlinearity\n\n    def forward(self, input: Tensor, hx: Optional[Tensor] = None) -> Tensor:\n        if input.dim() not in (1, 2):\n            raise ValueError(\n                f\"RNNCell: Expected input to be 1D or 2D, got {input.dim()}D instead\"\n            )\n        if hx is not None and hx.dim() not in (1, 2):\n            raise ValueError(\n                f\"RNNCell: Expected hidden to be 1D or 2D, got {hx.dim()}D instead\"\n            )\n        is_batched = input.dim() == 2\n        if not is_batched:\n            input = input.unsqueeze(0)\n\n        if hx is None:\n            hx = torch.zeros(\n                input.size(0), self.hidden_size, dtype=input.dtype, device=input.device\n            )\n        else:\n            hx = hx.unsqueeze(0) if not is_batched else hx\n\n        if self.nonlinearity == \"tanh\":\n            ret = _VF.rnn_tanh_cell(\n                input,\n                hx,\n                self.weight_ih,\n                self.weight_hh,\n                self.bias_ih,\n                self.bias_hh,\n            )\n        elif self.nonlinearity == \"relu\":\n            ret = _VF.rnn_relu_cell(\n                input,\n                hx,\n                self.weight_ih,\n                self.weight_hh,\n                self.bias_ih,\n                self.bias_hh,\n            )\n        else:\n            ret = input  # TODO: remove when jit supports exception flow\n            raise RuntimeError(f\"Unknown nonlinearity: {self.nonlinearity}\")\n\n        if not is_batched:\n            ret = ret.squeeze(0)\n\n        return ret\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LSTMCell": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py",
      "start_line": 1609,
      "end_line": 1716,
      "code": "class LSTMCell(RNNCellBase):\n\n    def __init__(\n        self,\n        input_size: int,\n        hidden_size: int,\n        bias: bool = True,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__(input_size, hidden_size, bias, num_chunks=4, **factory_kwargs)\n\n    def forward(\n        self, input: Tensor, hx: Optional[Tuple[Tensor, Tensor]] = None\n    ) -> Tuple[Tensor, Tensor]:\n        if input.dim() not in (1, 2):\n            raise ValueError(\n                f\"LSTMCell: Expected input to be 1D or 2D, got {input.dim()}D instead\"\n            )\n        if hx is not None:\n            for idx, value in enumerate(hx):\n                if value.dim() not in (1, 2):\n                    raise ValueError(\n                        f\"LSTMCell: Expected hx[{idx}] to be 1D or 2D, got {value.dim()}D instead\"\n                    )\n        is_batched = input.dim() == 2\n        if not is_batched:\n            input = input.unsqueeze(0)\n\n        if hx is None:\n            zeros = torch.zeros(\n                input.size(0), self.hidden_size, dtype=input.dtype, device=input.device\n            )\n            hx = (zeros, zeros)\n        else:\n            hx = (hx[0].unsqueeze(0), hx[1].unsqueeze(0)) if not is_batched else hx\n\n        ret = _VF.lstm_cell(\n            input,\n            hx,\n            self.weight_ih,\n            self.weight_hh,\n            self.bias_ih,\n            self.bias_hh,\n        )\n\n        if not is_batched:\n            ret = (ret[0].squeeze(0), ret[1].squeeze(0))\n        return ret\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.GRUCell": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py",
      "start_line": 1719,
      "end_line": 1824,
      "code": "class GRUCell(RNNCellBase):\n\n    def __init__(\n        self,\n        input_size: int,\n        hidden_size: int,\n        bias: bool = True,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__(input_size, hidden_size, bias, num_chunks=3, **factory_kwargs)\n\n    def forward(self, input: Tensor, hx: Optional[Tensor] = None) -> Tensor:\n        if input.dim() not in (1, 2):\n            raise ValueError(\n                f\"GRUCell: Expected input to be 1D or 2D, got {input.dim()}D instead\"\n            )\n        if hx is not None and hx.dim() not in (1, 2):\n            raise ValueError(\n                f\"GRUCell: Expected hidden to be 1D or 2D, got {hx.dim()}D instead\"\n            )\n        is_batched = input.dim() == 2\n        if not is_batched:\n            input = input.unsqueeze(0)\n\n        if hx is None:\n            hx = torch.zeros(\n                input.size(0), self.hidden_size, dtype=input.dtype, device=input.device\n            )\n        else:\n            hx = hx.unsqueeze(0) if not is_batched else hx\n\n        ret = _VF.gru_cell(\n            input,\n            hx,\n            self.weight_ih,\n            self.weight_hh,\n            self.bias_ih,\n            self.bias_hh,\n        )\n\n        if not is_batched:\n            ret = ret.squeeze(0)\n\n        return ret\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Transformer": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py",
      "start_line": 61,
      "end_line": 306,
      "code": "class Transformer(Module):\n\n    def __init__(\n        self,\n        d_model: int = 512,\n        nhead: int = 8,\n        num_encoder_layers: int = 6,\n        num_decoder_layers: int = 6,\n        dim_feedforward: int = 2048,\n        dropout: float = 0.1,\n        activation: Union[str, Callable[[Tensor], Tensor]] = F.relu,\n        custom_encoder: Optional[Any] = None,\n        custom_decoder: Optional[Any] = None,\n        layer_norm_eps: float = 1e-5,\n        batch_first: bool = False,\n        norm_first: bool = False,\n        bias: bool = True,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        torch._C._log_api_usage_once(f\"torch.nn.modules.{self.__class__.__name__}\")\n\n        if custom_encoder is not None:\n            self.encoder = custom_encoder\n        else:\n            encoder_layer = TransformerEncoderLayer(\n                d_model,\n                nhead,\n                dim_feedforward,\n                dropout,\n                activation,\n                layer_norm_eps,\n                batch_first,\n                norm_first,\n                bias,\n                **factory_kwargs,\n            )\n            encoder_norm = LayerNorm(\n                d_model, eps=layer_norm_eps, bias=bias, **factory_kwargs\n            )\n            self.encoder = TransformerEncoder(\n                encoder_layer, num_encoder_layers, encoder_norm\n            )\n\n        if custom_decoder is not None:\n            self.decoder = custom_decoder\n        else:\n            decoder_layer = TransformerDecoderLayer(\n                d_model,\n                nhead,\n                dim_feedforward,\n                dropout,\n                activation,\n                layer_norm_eps,\n                batch_first,\n                norm_first,\n                bias,\n                **factory_kwargs,\n            )\n            decoder_norm = LayerNorm(\n                d_model, eps=layer_norm_eps, bias=bias, **factory_kwargs\n            )\n            self.decoder = TransformerDecoder(\n                decoder_layer, num_decoder_layers, decoder_norm\n            )\n\n        self._reset_parameters()\n\n        self.d_model = d_model\n        self.nhead = nhead\n\n        self.batch_first = batch_first\n\n    def forward(\n        self,\n        src: Tensor,\n        tgt: Tensor,\n        src_mask: Optional[Tensor] = None,\n        tgt_mask: Optional[Tensor] = None,\n        memory_mask: Optional[Tensor] = None,\n        src_key_padding_mask: Optional[Tensor] = None,\n        tgt_key_padding_mask: Optional[Tensor] = None,\n        memory_key_padding_mask: Optional[Tensor] = None,\n        src_is_causal: Optional[bool] = None,\n        tgt_is_causal: Optional[bool] = None,\n        memory_is_causal: bool = False,\n    ) -> Tensor:\n        r\"\"\"Take in and process masked source/target sequences.\n\n        .. note::\n\n            If a boolean tensor is provided for any of the [src/tgt/memory]_mask arguments, positions with a ``True`` value are\n            not allowed to participate in the attention,\n            which is the opposite of the definition for :attr:`attn_mask`\n            in :func:`torch.nn.functional.scaled_dot_product_attention`.\n\n        Args:\n            src: the sequence to the encoder (required).\n            tgt: the sequence to the decoder (required).\n            src_mask: the additive mask for the src sequence (optional).\n            tgt_mask: the additive mask for the tgt sequence (optional).\n            memory_mask: the additive mask for the encoder output (optional).\n            src_key_padding_mask: the Tensor mask for src keys per batch (optional).\n            tgt_key_padding_mask: the Tensor mask for tgt keys per batch (optional).\n            memory_key_padding_mask: the Tensor mask for memory keys per batch (optional).\n            src_is_causal: If specified, applies a causal mask as ``src_mask``.\n                Default: ``None``; try to detect a causal mask.\n                Warning:\n                ``src_is_causal`` provides a hint that ``src_mask`` is\n                the causal mask. Providing incorrect hints can result in\n                incorrect execution, including forward and backward\n                compatibility.\n            tgt_is_causal: If specified, applies a causal mask as ``tgt_mask``.\n                Default: ``None``; try to detect a causal mask.\n                Warning:\n                ``tgt_is_causal`` provides a hint that ``tgt_mask`` is\n                the causal mask. Providing incorrect hints can result in\n                incorrect execution, including forward and backward\n                compatibility.\n            memory_is_causal: If specified, applies a causal mask as\n                ``memory_mask``.\n                Default: ``False``.\n                Warning:\n                ``memory_is_causal`` provides a hint that\n                ``memory_mask`` is the causal mask. Providing incorrect\n                hints can result in incorrect execution, including\n                forward and backward compatibility.\n\n        Shape:\n            - src: :math:`(S, E)` for unbatched input, :math:`(S, N, E)` if `batch_first=False` or\n              `(N, S, E)` if `batch_first=True`.\n            - tgt: :math:`(T, E)` for unbatched input, :math:`(T, N, E)` if `batch_first=False` or\n              `(N, T, E)` if `batch_first=True`.\n            - src_mask: :math:`(S, S)` or :math:`(N\\cdot\\text{num\\_heads}, S, S)`.\n            - tgt_mask: :math:`(T, T)` or :math:`(N\\cdot\\text{num\\_heads}, T, T)`.\n            - memory_mask: :math:`(T, S)`.\n            - src_key_padding_mask: :math:`(S)` for unbatched input otherwise :math:`(N, S)`.\n            - tgt_key_padding_mask: :math:`(T)` for unbatched input otherwise :math:`(N, T)`.\n            - memory_key_padding_mask: :math:`(S)` for unbatched input otherwise :math:`(N, S)`.\n\n            Note: [src/tgt/memory]_mask ensures that position :math:`i` is allowed to attend the unmasked\n            positions. If a BoolTensor is provided, positions with ``True``\n            are not allowed to attend while ``False`` values will be unchanged. If a FloatTensor\n            is provided, it will be added to the attention weight.\n            [src/tgt/memory]_key_padding_mask provides specified elements in the key to be ignored by\n            the attention. If a BoolTensor is provided, the positions with the\n            value of ``True`` will be ignored while the position with the value of ``False`` will be unchanged.\n\n            - output: :math:`(T, E)` for unbatched input, :math:`(T, N, E)` if `batch_first=False` or\n              `(N, T, E)` if `batch_first=True`.\n\n            Note: Due to the multi-head attention architecture in the transformer model,\n            the output sequence length of a transformer is same as the input sequence\n            (i.e. target) length of the decoder.\n\n            where :math:`S` is the source sequence length, :math:`T` is the target sequence length, :math:`N` is the\n            batch size, :math:`E` is the feature number\n\n        Examples:\n            >>> # xdoctest: +SKIP\n            >>> output = transformer_model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\n        \"\"\"\n        is_batched = src.dim() == 3\n        if not self.batch_first and src.size(1) != tgt.size(1) and is_batched:\n            raise RuntimeError(\"the batch number of src and tgt must be equal\")\n        elif self.batch_first and src.size(0) != tgt.size(0) and is_batched:\n            raise RuntimeError(\"the batch number of src and tgt must be equal\")\n\n        if src.size(-1) != self.d_model or tgt.size(-1) != self.d_model:\n            raise RuntimeError(\n                \"the feature number of src and tgt must be equal to d_model\"\n            )\n\n        memory = self.encoder(\n            src,\n            mask=src_mask,\n            src_key_padding_mask=src_key_padding_mask,\n            is_causal=src_is_causal,\n        )\n        output = self.decoder(\n            tgt,\n            memory,\n            tgt_mask=tgt_mask,\n            memory_mask=memory_mask,\n            tgt_key_padding_mask=tgt_key_padding_mask,\n            memory_key_padding_mask=memory_key_padding_mask,\n            tgt_is_causal=tgt_is_causal,\n            memory_is_causal=memory_is_causal,\n        )\n        return output\n\n    @staticmethod\n    def generate_square_subsequent_mask(\n        sz: int,\n        device: Optional[torch.device] = None,\n        dtype: Optional[torch.dtype] = None,\n    ) -> Tensor:\n        r\"\"\"Generate a square causal mask for the sequence.\n\n        The masked positions are filled with float('-inf'). Unmasked positions are filled with float(0.0).\n        \"\"\"\n        return _generate_square_subsequent_mask(sz, dtype=dtype, device=device)\n\n    def _reset_parameters(self):\n        r\"\"\"Initiate parameters in the transformer model.\"\"\"\n        for p in self.parameters():\n            if p.dim() > 1:\n                xavier_uniform_(p)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.TransformerEncoder": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py",
      "start_line": 309,
      "end_line": 524,
      "code": "class TransformerEncoder(Module):\n\n    __constants__ = [\"norm\"]\n\n    def __init__(\n        self,\n        encoder_layer: \"TransformerEncoderLayer\",\n        num_layers: int,\n        norm: Optional[Module] = None,\n        enable_nested_tensor: bool = True,\n        mask_check: bool = True,\n    ) -> None:\n        super().__init__()\n        torch._C._log_api_usage_once(f\"torch.nn.modules.{self.__class__.__name__}\")\n        self.layers = _get_clones(encoder_layer, num_layers)\n        self.num_layers = num_layers\n        self.norm = norm\n        # this attribute saves the value providedat object construction\n        self.enable_nested_tensor = enable_nested_tensor\n        # this attribute controls whether nested tensors are used\n        self.use_nested_tensor = enable_nested_tensor\n        self.mask_check = mask_check\n\n        enc_layer = \"encoder_layer\"\n        why_not_sparsity_fast_path = \"\"\n        if not isinstance(encoder_layer, torch.nn.TransformerEncoderLayer):\n            why_not_sparsity_fast_path = f\"{enc_layer} was not TransformerEncoderLayer\"\n        elif encoder_layer.norm_first:\n            why_not_sparsity_fast_path = f\"{enc_layer}.norm_first was True\"\n        elif not encoder_layer.self_attn.batch_first:\n            why_not_sparsity_fast_path = (\n                f\"{enc_layer}.self_attn.batch_first was not True\"\n                + \"(use batch_first for better inference performance)\"\n            )\n        elif not encoder_layer.self_attn._qkv_same_embed_dim:\n            why_not_sparsity_fast_path = (\n                f\"{enc_layer}.self_attn._qkv_same_embed_dim was not True\"\n            )\n        elif encoder_layer.self_attn.in_proj_bias is None:\n            why_not_sparsity_fast_path = f\"{enc_layer}.self_attn was passed bias=False\"\n        elif not encoder_layer.activation_relu_or_gelu:\n            why_not_sparsity_fast_path = (\n                f\"{enc_layer}.activation_relu_or_gelu was not True\"\n            )\n        elif not (encoder_layer.norm1.eps == encoder_layer.norm2.eps):\n            why_not_sparsity_fast_path = (\n                f\"{enc_layer}.norm1.eps was not equal to {enc_layer}.norm2.eps\"\n            )\n        elif encoder_layer.self_attn.num_heads % 2 == 1:\n            why_not_sparsity_fast_path = f\"{enc_layer}.self_attn.num_heads is odd\"\n\n        if enable_nested_tensor and why_not_sparsity_fast_path:\n            warnings.warn(\n                f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\"\n            )\n            self.use_nested_tensor = False\n\n    def forward(\n        self,\n        src: Tensor,\n        mask: Optional[Tensor] = None,\n        src_key_padding_mask: Optional[Tensor] = None,\n        is_causal: Optional[bool] = None,\n    ) -> Tensor:\n        r\"\"\"Pass the input through the encoder layers in turn.\n\n        Args:\n            src: the sequence to the encoder (required).\n            mask: the mask for the src sequence (optional).\n            src_key_padding_mask: the mask for the src keys per batch (optional).\n            is_causal: If specified, applies a causal mask as ``mask``.\n                Default: ``None``; try to detect a causal mask.\n                Warning:\n                ``is_causal`` provides a hint that ``mask`` is the\n                causal mask. Providing incorrect hints can result in\n                incorrect execution, including forward and backward\n                compatibility.\n\n        Shape:\n            see the docs in :class:`~torch.nn.Transformer`.\n        \"\"\"\n        src_key_padding_mask = F._canonical_mask(\n            mask=src_key_padding_mask,\n            mask_name=\"src_key_padding_mask\",\n            other_type=F._none_or_dtype(mask),\n            other_name=\"mask\",\n            target_type=src.dtype,\n        )\n\n        mask = F._canonical_mask(\n            mask=mask,\n            mask_name=\"mask\",\n            other_type=None,\n            other_name=\"\",\n            target_type=src.dtype,\n            check_other=False,\n        )\n\n        output = src\n        convert_to_nested = False\n        first_layer = self.layers[0]\n        src_key_padding_mask_for_layers = src_key_padding_mask\n        why_not_sparsity_fast_path = \"\"\n        str_first_layer = \"self.layers[0]\"\n        batch_first = first_layer.self_attn.batch_first\n        is_fastpath_enabled = torch.backends.mha.get_fastpath_enabled()\n\n        if not is_fastpath_enabled:\n            why_not_sparsity_fast_path = (\n                \"torch.backends.mha.get_fastpath_enabled() was not True\"\n            )\n        elif not hasattr(self, \"use_nested_tensor\"):\n            why_not_sparsity_fast_path = \"use_nested_tensor attribute not present\"\n        elif not self.use_nested_tensor:\n            why_not_sparsity_fast_path = (\n                \"self.use_nested_tensor (set in init) was not True\"\n            )\n        elif first_layer.training:\n            why_not_sparsity_fast_path = f\"{str_first_layer} was in training mode\"\n        elif not src.dim() == 3:\n            why_not_sparsity_fast_path = (\n                f\"input not batched; expected src.dim() of 3 but got {src.dim()}\"\n            )\n        elif src_key_padding_mask is None:\n            why_not_sparsity_fast_path = \"src_key_padding_mask was None\"\n        elif (\n            (not hasattr(self, \"mask_check\")) or self.mask_check\n        ) and not torch._nested_tensor_from_mask_left_aligned(\n            src, src_key_padding_mask.logical_not()\n        ):\n            why_not_sparsity_fast_path = \"mask_check enabled, and src and src_key_padding_mask was not left aligned\"\n        elif output.is_nested:\n            why_not_sparsity_fast_path = \"NestedTensor input is not supported\"\n        elif mask is not None:\n            why_not_sparsity_fast_path = (\n                \"src_key_padding_mask and mask were both supplied\"\n            )\n        elif torch.is_autocast_enabled():\n            why_not_sparsity_fast_path = \"autocast is enabled\"\n\n        if not why_not_sparsity_fast_path:\n            tensor_args = (\n                src,\n                first_layer.self_attn.in_proj_weight,\n                first_layer.self_attn.in_proj_bias,\n                first_layer.self_attn.out_proj.weight,\n                first_layer.self_attn.out_proj.bias,\n                first_layer.norm1.weight,\n                first_layer.norm1.bias,\n                first_layer.norm2.weight,\n                first_layer.norm2.bias,\n                first_layer.linear1.weight,\n                first_layer.linear1.bias,\n                first_layer.linear2.weight,\n                first_layer.linear2.bias,\n            )\n            _supported_device_type = [\n                \"cpu\",\n                \"cuda\",\n                torch.utils.backend_registration._privateuse1_backend_name,\n            ]\n            if torch.overrides.has_torch_function(tensor_args):\n                why_not_sparsity_fast_path = \"some Tensor argument has_torch_function\"\n            elif src.device.type not in _supported_device_type:\n                why_not_sparsity_fast_path = (\n                    f\"src device is neither one of {_supported_device_type}\"\n                )\n            elif torch.is_grad_enabled() and any(x.requires_grad for x in tensor_args):\n                why_not_sparsity_fast_path = (\n                    \"grad is enabled and at least one of query or the \"\n                    \"input/output projection weights or biases requires_grad\"\n                )\n\n            if (not why_not_sparsity_fast_path) and (src_key_padding_mask is not None):\n                convert_to_nested = True\n                output = torch._nested_tensor_from_mask(\n                    output, src_key_padding_mask.logical_not(), mask_check=False\n                )\n                src_key_padding_mask_for_layers = None\n\n        seq_len = _get_seq_len(src, batch_first)\n        is_causal = _detect_is_causal_mask(mask, is_causal, seq_len)\n\n        for mod in self.layers:\n            output = mod(\n                output,\n                src_mask=mask,\n                is_causal=is_causal,\n                src_key_padding_mask=src_key_padding_mask_for_layers,\n            )\n\n        if convert_to_nested:\n            output = output.to_padded_tensor(0.0, src.size())\n\n        if self.norm is not None:\n            output = self.norm(output)\n\n        return output\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.TransformerDecoder": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py",
      "start_line": 527,
      "end_line": 616,
      "code": "class TransformerDecoder(Module):\n\n    __constants__ = [\"norm\"]\n\n    def __init__(\n        self,\n        decoder_layer: \"TransformerDecoderLayer\",\n        num_layers: int,\n        norm: Optional[Module] = None,\n    ) -> None:\n        super().__init__()\n        torch._C._log_api_usage_once(f\"torch.nn.modules.{self.__class__.__name__}\")\n        self.layers = _get_clones(decoder_layer, num_layers)\n        self.num_layers = num_layers\n        self.norm = norm\n\n    def forward(\n        self,\n        tgt: Tensor,\n        memory: Tensor,\n        tgt_mask: Optional[Tensor] = None,\n        memory_mask: Optional[Tensor] = None,\n        tgt_key_padding_mask: Optional[Tensor] = None,\n        memory_key_padding_mask: Optional[Tensor] = None,\n        tgt_is_causal: Optional[bool] = None,\n        memory_is_causal: bool = False,\n    ) -> Tensor:\n        r\"\"\"Pass the inputs (and mask) through the decoder layer in turn.\n\n        Args:\n            tgt: the sequence to the decoder (required).\n            memory: the sequence from the last layer of the encoder (required).\n            tgt_mask: the mask for the tgt sequence (optional).\n            memory_mask: the mask for the memory sequence (optional).\n            tgt_key_padding_mask: the mask for the tgt keys per batch (optional).\n            memory_key_padding_mask: the mask for the memory keys per batch (optional).\n            tgt_is_causal: If specified, applies a causal mask as ``tgt mask``.\n                Default: ``None``; try to detect a causal mask.\n                Warning:\n                ``tgt_is_causal`` provides a hint that ``tgt_mask`` is\n                the causal mask. Providing incorrect hints can result in\n                incorrect execution, including forward and backward\n                compatibility.\n            memory_is_causal: If specified, applies a causal mask as\n                ``memory mask``.\n                Default: ``False``.\n                Warning:\n                ``memory_is_causal`` provides a hint that\n                ``memory_mask`` is the causal mask. Providing incorrect\n                hints can result in incorrect execution, including\n                forward and backward compatibility.\n\n        Shape:\n            see the docs in :class:`~torch.nn.Transformer`.\n        \"\"\"\n        output = tgt\n\n        seq_len = _get_seq_len(tgt, self.layers[0].self_attn.batch_first)\n        tgt_is_causal = _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\n        for mod in self.layers:\n            output = mod(\n                output,\n                memory,\n                tgt_mask=tgt_mask,\n                memory_mask=memory_mask,\n                tgt_key_padding_mask=tgt_key_padding_mask,\n                memory_key_padding_mask=memory_key_padding_mask,\n                tgt_is_causal=tgt_is_causal,\n                memory_is_causal=memory_is_causal,\n            )\n\n        if self.norm is not None:\n            output = self.norm(output)\n\n        return output\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.TransformerEncoderLayer": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py",
      "start_line": 619,
      "end_line": 932,
      "code": "class TransformerEncoderLayer(Module):\n\n    __constants__ = [\"norm_first\"]\n\n    def __init__(\n        self,\n        d_model: int,\n        nhead: int,\n        dim_feedforward: int = 2048,\n        dropout: float = 0.1,\n        activation: Union[str, Callable[[Tensor], Tensor]] = F.relu,\n        layer_norm_eps: float = 1e-5,\n        batch_first: bool = False,\n        norm_first: bool = False,\n        bias: bool = True,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        self.self_attn = MultiheadAttention(\n            d_model,\n            nhead,\n            dropout=dropout,\n            bias=bias,\n            batch_first=batch_first,\n            **factory_kwargs,\n        )\n        # Implementation of Feedforward model\n        self.linear1 = Linear(d_model, dim_feedforward, bias=bias, **factory_kwargs)\n        self.dropout = Dropout(dropout)\n        self.linear2 = Linear(dim_feedforward, d_model, bias=bias, **factory_kwargs)\n\n        self.norm_first = norm_first\n        self.norm1 = LayerNorm(d_model, eps=layer_norm_eps, bias=bias, **factory_kwargs)\n        self.norm2 = LayerNorm(d_model, eps=layer_norm_eps, bias=bias, **factory_kwargs)\n        self.dropout1 = Dropout(dropout)\n        self.dropout2 = Dropout(dropout)\n\n        # Legacy string support for activation function.\n        if isinstance(activation, str):\n            activation = _get_activation_fn(activation)\n\n        # We can't test self.activation in forward() in TorchScript,\n        # so stash some information about it instead.\n        if activation is F.relu or isinstance(activation, torch.nn.ReLU):\n            self.activation_relu_or_gelu = 1\n        elif activation is F.gelu or isinstance(activation, torch.nn.GELU):\n            self.activation_relu_or_gelu = 2\n        else:\n            self.activation_relu_or_gelu = 0\n        self.activation = activation\n\n    def __setstate__(self, state):\n        super().__setstate__(state)\n        if not hasattr(self, \"activation\"):\n            self.activation = F.relu\n\n    def forward(\n        self,\n        src: Tensor,\n        src_mask: Optional[Tensor] = None,\n        src_key_padding_mask: Optional[Tensor] = None,\n        is_causal: bool = False,\n    ) -> Tensor:\n        r\"\"\"Pass the input through the encoder layer.\n\n        Args:\n            src: the sequence to the encoder layer (required).\n            src_mask: the mask for the src sequence (optional).\n            src_key_padding_mask: the mask for the src keys per batch (optional).\n            is_causal: If specified, applies a causal mask as ``src mask``.\n                Default: ``False``.\n                Warning:\n                ``is_causal`` provides a hint that ``src_mask`` is the\n                causal mask. Providing incorrect hints can result in\n                incorrect execution, including forward and backward\n                compatibility.\n\n        Shape:\n            see the docs in :class:`~torch.nn.Transformer`.\n        \"\"\"\n        src_key_padding_mask = F._canonical_mask(\n            mask=src_key_padding_mask,\n            mask_name=\"src_key_padding_mask\",\n            other_type=F._none_or_dtype(src_mask),\n            other_name=\"src_mask\",\n            target_type=src.dtype,\n        )\n\n        src_mask = F._canonical_mask(\n            mask=src_mask,\n            mask_name=\"src_mask\",\n            other_type=None,\n            other_name=\"\",\n            target_type=src.dtype,\n            check_other=False,\n        )\n\n        is_fastpath_enabled = torch.backends.mha.get_fastpath_enabled()\n\n        why_not_sparsity_fast_path = \"\"\n        if not is_fastpath_enabled:\n            why_not_sparsity_fast_path = (\n                \"torch.backends.mha.get_fastpath_enabled() was not True\"\n            )\n        elif not src.dim() == 3:\n            why_not_sparsity_fast_path = (\n                f\"input not batched; expected src.dim() of 3 but got {src.dim()}\"\n            )\n        elif self.training:\n            why_not_sparsity_fast_path = \"training is enabled\"\n        elif not self.self_attn.batch_first:\n            why_not_sparsity_fast_path = \"self_attn.batch_first was not True\"\n        elif self.self_attn.in_proj_bias is None:\n            why_not_sparsity_fast_path = \"self_attn was passed bias=False\"\n        elif not self.self_attn._qkv_same_embed_dim:\n            why_not_sparsity_fast_path = \"self_attn._qkv_same_embed_dim was not True\"\n        elif not self.activation_relu_or_gelu:\n            why_not_sparsity_fast_path = \"activation_relu_or_gelu was not True\"\n        elif not (self.norm1.eps == self.norm2.eps):\n            why_not_sparsity_fast_path = \"norm1.eps is not equal to norm2.eps\"\n        elif src.is_nested and (\n            src_key_padding_mask is not None or src_mask is not None\n        ):\n            why_not_sparsity_fast_path = \"neither src_key_padding_mask nor src_mask are not supported with NestedTensor input\"\n        elif self.self_attn.num_heads % 2 == 1:\n            why_not_sparsity_fast_path = \"num_head is odd\"\n        elif torch.is_autocast_enabled():\n            why_not_sparsity_fast_path = \"autocast is enabled\"\n        elif any(\n            len(getattr(m, \"_forward_hooks\", {}))\n            + len(getattr(m, \"_forward_pre_hooks\", {}))\n            for m in self.modules()\n        ):\n            why_not_sparsity_fast_path = \"forward pre-/hooks are attached to the module\"\n        if not why_not_sparsity_fast_path:\n            tensor_args = (\n                src,\n                self.self_attn.in_proj_weight,\n                self.self_attn.in_proj_bias,\n                self.self_attn.out_proj.weight,\n                self.self_attn.out_proj.bias,\n                self.norm1.weight,\n                self.norm1.bias,\n                self.norm2.weight,\n                self.norm2.bias,\n                self.linear1.weight,\n                self.linear1.bias,\n                self.linear2.weight,\n                self.linear2.bias,\n            )\n\n            # We have to use list comprehensions below because TorchScript does not support\n            # generator expressions.\n            _supported_device_type = [\n                \"cpu\",\n                \"cuda\",\n                torch.utils.backend_registration._privateuse1_backend_name,\n            ]\n            if torch.overrides.has_torch_function(tensor_args):\n                why_not_sparsity_fast_path = \"some Tensor argument has_torch_function\"\n            elif not all(\n                (x.device.type in _supported_device_type) for x in tensor_args\n            ):\n                why_not_sparsity_fast_path = (\n                    \"some Tensor argument's device is neither one of \"\n                    f\"{_supported_device_type}\"\n                )\n            elif torch.is_grad_enabled() and any(x.requires_grad for x in tensor_args):\n                why_not_sparsity_fast_path = (\n                    \"grad is enabled and at least one of query or the \"\n                    \"input/output projection weights or biases requires_grad\"\n                )\n\n            if not why_not_sparsity_fast_path:\n                merged_mask, mask_type = self.self_attn.merge_masks(\n                    src_mask, src_key_padding_mask, src\n                )\n                return torch._transformer_encoder_layer_fwd(\n                    src,\n                    self.self_attn.embed_dim,\n                    self.self_attn.num_heads,\n                    self.self_attn.in_proj_weight,\n                    self.self_attn.in_proj_bias,\n                    self.self_attn.out_proj.weight,\n                    self.self_attn.out_proj.bias,\n                    self.activation_relu_or_gelu == 2,\n                    self.norm_first,\n                    self.norm1.eps,\n                    self.norm1.weight,\n                    self.norm1.bias,\n                    self.norm2.weight,\n                    self.norm2.bias,\n                    self.linear1.weight,\n                    self.linear1.bias,\n                    self.linear2.weight,\n                    self.linear2.bias,\n                    merged_mask,\n                    mask_type,\n                )\n\n        # see Fig. 1 of https://arxiv.org/pdf/2002.04745v1.pdf\n        x = src\n        if self.norm_first:\n            x = x + self._sa_block(\n                self.norm1(x), src_mask, src_key_padding_mask, is_causal=is_causal\n            )\n            x = x + self._ff_block(self.norm2(x))\n        else:\n            x = self.norm1(\n                x\n                + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal)\n            )\n            x = self.norm2(x + self._ff_block(x))\n\n        return x\n\n    # self-attention block\n    def _sa_block(\n        self,\n        x: Tensor,\n        attn_mask: Optional[Tensor],\n        key_padding_mask: Optional[Tensor],\n        is_causal: bool = False,\n    ) -> Tensor:\n        x = self.self_attn(\n            x,\n            x,\n            x,\n            attn_mask=attn_mask,\n            key_padding_mask=key_padding_mask,\n            need_weights=False,\n            is_causal=is_causal,\n        )[0]\n        return self.dropout1(x)\n\n    # feed forward block\n    def _ff_block(self, x: Tensor) -> Tensor:\n        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n        return self.dropout2(x)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.TransformerDecoderLayer": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py",
      "start_line": 935,
      "end_line": 1141,
      "code": "class TransformerDecoderLayer(Module):\n\n    __constants__ = [\"norm_first\"]\n\n    def __init__(\n        self,\n        d_model: int,\n        nhead: int,\n        dim_feedforward: int = 2048,\n        dropout: float = 0.1,\n        activation: Union[str, Callable[[Tensor], Tensor]] = F.relu,\n        layer_norm_eps: float = 1e-5,\n        batch_first: bool = False,\n        norm_first: bool = False,\n        bias: bool = True,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        self.self_attn = MultiheadAttention(\n            d_model,\n            nhead,\n            dropout=dropout,\n            batch_first=batch_first,\n            bias=bias,\n            **factory_kwargs,\n        )\n        self.multihead_attn = MultiheadAttention(\n            d_model,\n            nhead,\n            dropout=dropout,\n            batch_first=batch_first,\n            bias=bias,\n            **factory_kwargs,\n        )\n        # Implementation of Feedforward model\n        self.linear1 = Linear(d_model, dim_feedforward, bias=bias, **factory_kwargs)\n        self.dropout = Dropout(dropout)\n        self.linear2 = Linear(dim_feedforward, d_model, bias=bias, **factory_kwargs)\n\n        self.norm_first = norm_first\n        self.norm1 = LayerNorm(d_model, eps=layer_norm_eps, bias=bias, **factory_kwargs)\n        self.norm2 = LayerNorm(d_model, eps=layer_norm_eps, bias=bias, **factory_kwargs)\n        self.norm3 = LayerNorm(d_model, eps=layer_norm_eps, bias=bias, **factory_kwargs)\n        self.dropout1 = Dropout(dropout)\n        self.dropout2 = Dropout(dropout)\n        self.dropout3 = Dropout(dropout)\n\n        # Legacy string support for activation function.\n        if isinstance(activation, str):\n            self.activation = _get_activation_fn(activation)\n        else:\n            self.activation = activation\n\n    def __setstate__(self, state):\n        if \"activation\" not in state:\n            state[\"activation\"] = F.relu\n        super().__setstate__(state)\n\n    def forward(\n        self,\n        tgt: Tensor,\n        memory: Tensor,\n        tgt_mask: Optional[Tensor] = None,\n        memory_mask: Optional[Tensor] = None,\n        tgt_key_padding_mask: Optional[Tensor] = None,\n        memory_key_padding_mask: Optional[Tensor] = None,\n        tgt_is_causal: bool = False,\n        memory_is_causal: bool = False,\n    ) -> Tensor:\n        r\"\"\"Pass the inputs (and mask) through the decoder layer.\n\n        Args:\n            tgt: the sequence to the decoder layer (required).\n            memory: the sequence from the last layer of the encoder (required).\n            tgt_mask: the mask for the tgt sequence (optional).\n            memory_mask: the mask for the memory sequence (optional).\n            tgt_key_padding_mask: the mask for the tgt keys per batch (optional).\n            memory_key_padding_mask: the mask for the memory keys per batch (optional).\n            tgt_is_causal: If specified, applies a causal mask as ``tgt mask``.\n                Default: ``False``.\n                Warning:\n                ``tgt_is_causal`` provides a hint that ``tgt_mask`` is\n                the causal mask. Providing incorrect hints can result in\n                incorrect execution, including forward and backward\n                compatibility.\n            memory_is_causal: If specified, applies a causal mask as\n                ``memory mask``.\n                Default: ``False``.\n                Warning:\n                ``memory_is_causal`` provides a hint that\n                ``memory_mask`` is the causal mask. Providing incorrect\n                hints can result in incorrect execution, including\n                forward and backward compatibility.\n\n        Shape:\n            see the docs in :class:`~torch.nn.Transformer`.\n        \"\"\"\n        # see Fig. 1 of https://arxiv.org/pdf/2002.04745v1.pdf\n\n        x = tgt\n        if self.norm_first:\n            x = x + self._sa_block(\n                self.norm1(x), tgt_mask, tgt_key_padding_mask, tgt_is_causal\n            )\n            x = x + self._mha_block(\n                self.norm2(x),\n                memory,\n                memory_mask,\n                memory_key_padding_mask,\n                memory_is_causal,\n            )\n            x = x + self._ff_block(self.norm3(x))\n        else:\n            x = self.norm1(\n                x + self._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n            )\n            x = self.norm2(\n                x\n                + self._mha_block(\n                    x, memory, memory_mask, memory_key_padding_mask, memory_is_causal\n                )\n            )\n            x = self.norm3(x + self._ff_block(x))\n\n        return x\n\n    # self-attention block\n    def _sa_block(\n        self,\n        x: Tensor,\n        attn_mask: Optional[Tensor],\n        key_padding_mask: Optional[Tensor],\n        is_causal: bool = False,\n    ) -> Tensor:\n        x = self.self_attn(\n            x,\n            x,\n            x,\n            attn_mask=attn_mask,\n            key_padding_mask=key_padding_mask,\n            is_causal=is_causal,\n            need_weights=False,\n        )[0]\n        return self.dropout1(x)\n\n    # multihead attention block\n    def _mha_block(\n        self,\n        x: Tensor,\n        mem: Tensor,\n        attn_mask: Optional[Tensor],\n        key_padding_mask: Optional[Tensor],\n        is_causal: bool = False,\n    ) -> Tensor:\n        x = self.multihead_attn(\n            x,\n            mem,\n            mem,\n            attn_mask=attn_mask,\n            key_padding_mask=key_padding_mask,\n            is_causal=is_causal,\n            need_weights=False,\n        )[0]\n        return self.dropout2(x)\n\n    # feed forward block\n    def _ff_block(self, x: Tensor) -> Tensor:\n        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n        return self.dropout3(x)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Identity": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\linear.py",
      "start_line": 22,
      "end_line": 47,
      "code": "class Identity(Module):\n\n    def __init__(self, *args: Any, **kwargs: Any) -> None:\n        super().__init__()\n\n    def forward(self, input: Tensor) -> Tensor:\n        return input\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Linear": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\linear.py",
      "start_line": 50,
      "end_line": 128,
      "code": "class Linear(Module):\n\n    __constants__ = [\"in_features\", \"out_features\"]\n    in_features: int\n    out_features: int\n    weight: Tensor\n\n    def __init__(\n        self,\n        in_features: int,\n        out_features: int,\n        bias: bool = True,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = Parameter(\n            torch.empty((out_features, in_features), **factory_kwargs)\n        )\n        if bias:\n            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n        else:\n            self.register_parameter(\"bias\", None)\n        self.reset_parameters()\n\n    def reset_parameters(self) -> None:\n        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n        # https://github.com/pytorch/pytorch/issues/57109\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.linear(input, self.weight, self.bias)\n\n    def extra_repr(self) -> str:\n        return f\"in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}\"\n"
    },
    "cpp": {
      "function": "linear",
      "file": "aten/src/ATen/native/Linear.cpp",
      "start_line": 73,
      "end_line": 122,
      "code": "Tensor linear(const Tensor& input, const Tensor& weight, const std::optional<Tensor>& bias_opt) {\n  // _matmul_impl checks this again later, but _flatten_nd_linear does not work on scalars inputs,\n  // so let's try to catch this here already\n  const auto input_dim = input.dim();\n  const auto weight_dim = weight.dim();\n  TORCH_CHECK(input_dim != 0 && weight_dim != 0,\n              \"both arguments to linear need to be at least 1D, but they are \",\n              input_dim, \"D and \", weight_dim, \"D\");\n\n  // See [Note: hacky wrapper removal for optional tensor]\n  auto bias = bias_opt.has_value()\n    ? c10::MaybeOwned<Tensor>::borrowed(*bias_opt)\n    : c10::MaybeOwned<Tensor>::owned(std::in_place);\n  if (input.is_mkldnn()) {\n    return at::mkldnn_linear(input, weight, *bias);\n  }\n#if defined(C10_MOBILE)\n  if (xnnpack::use_linear(input, weight, *bias)) {\n    return xnnpack::linear(input, weight, *bias);\n  }\n#endif\n  if (input_dim == 2 && bias->defined()) {\n    // Fused op is marginally faster.\n    return at::addmm(*bias, input, weight.t());\n  }\n  if (bias->defined() && !input.is_xla()) {\n    // Also hit the fused path for contiguous 3D input, if not using xla\n    // backend. Reshaping/flattening has some performance implications on xla.\n    if (input.is_contiguous() && input_dim == 3) {\n      return _flatten_nd_linear(input, weight, *bias);\n    } else if (input.is_contiguous() && input.layout() == c10::kStrided && weight.layout() == c10::kStrided && bias->dim() == 1) {\n      return _flatten_nd_linear(input, weight, *bias);\n    } else if (parseLinearFlatten3d() && input_dim == 3) {\n      // If user forces flattening via env var\n      const Tensor input_cont = input.contiguous();\n      return _flatten_nd_linear(input_cont, weight, *bias);\n    }\n  }\n  auto output = at::matmul(input, weight.t());\n  if (bias->defined()) {\n    // for composite compliance use out-of-place version of `add`\n    if (isTensorSubclassLike(*bias) ||\n        bias->_fw_grad(/*level*/ 0).defined()) {\n      output = at::add(output, *bias);\n    } else {\n      output.add_(*bias);\n    }\n  }\n  return output;\n}\n"
    }
  },
  "torch.nn.Bilinear": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\linear.py",
      "start_line": 150,
      "end_line": 231,
      "code": "class Bilinear(Module):\n\n    __constants__ = [\"in1_features\", \"in2_features\", \"out_features\"]\n    in1_features: int\n    in2_features: int\n    out_features: int\n    weight: Tensor\n\n    def __init__(\n        self,\n        in1_features: int,\n        in2_features: int,\n        out_features: int,\n        bias: bool = True,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        self.in1_features = in1_features\n        self.in2_features = in2_features\n        self.out_features = out_features\n        self.weight = Parameter(\n            torch.empty((out_features, in1_features, in2_features), **factory_kwargs)\n        )\n\n        if bias:\n            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n        else:\n            self.register_parameter(\"bias\", None)\n        self.reset_parameters()\n\n    def reset_parameters(self) -> None:\n        bound = 1 / math.sqrt(self.weight.size(1))\n        init.uniform_(self.weight, -bound, bound)\n        if self.bias is not None:\n            init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, input1: Tensor, input2: Tensor) -> Tensor:\n        return F.bilinear(input1, input2, self.weight, self.bias)\n\n    def extra_repr(self) -> str:\n        return (\n            f\"in1_features={self.in1_features}, in2_features={self.in2_features}, \"\n            f\"out_features={self.out_features}, bias={self.bias is not None}\"\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.LazyLinear": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\linear.py",
      "start_line": 234,
      "end_line": 290,
      "code": "class LazyLinear(LazyModuleMixin, Linear):\n\n    cls_to_become = Linear  # type: ignore[assignment]\n    weight: UninitializedParameter\n    bias: UninitializedParameter  # type: ignore[assignment]\n\n    def __init__(\n        self, out_features: int, bias: bool = True, device=None, dtype=None\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        # bias is hardcoded to False to avoid creating tensor\n        # that will soon be overwritten.\n        super().__init__(0, 0, False)\n        self.weight = UninitializedParameter(**factory_kwargs)\n        self.out_features = out_features\n        if bias:\n            self.bias = UninitializedParameter(**factory_kwargs)\n\n    def reset_parameters(self) -> None:\n        if not self.has_uninitialized_params() and self.in_features != 0:\n            super().reset_parameters()\n\n    def initialize_parameters(self, input) -> None:  # type: ignore[override]\n        if self.has_uninitialized_params():\n            with torch.no_grad():\n                self.in_features = input.shape[-1]\n                self.weight.materialize((self.out_features, self.in_features))\n                if self.bias is not None:\n                    self.bias.materialize((self.out_features,))\n                self.reset_parameters()\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Dropout": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py",
      "start_line": 35,
      "end_line": 70,
      "code": "class Dropout(_DropoutNd):\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.dropout(input, self.p, self.training, self.inplace)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Dropout2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py",
      "start_line": 118,
      "end_line": 167,
      "code": "class Dropout2d(_DropoutNd):\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.dropout2d(input, self.p, self.training, self.inplace)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Dropout3d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py",
      "start_line": 170,
      "end_line": 212,
      "code": "class Dropout3d(_DropoutNd):\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.dropout3d(input, self.p, self.training, self.inplace)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.AlphaDropout": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py",
      "start_line": 215,
      "end_line": 254,
      "code": "class AlphaDropout(_DropoutNd):\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.alpha_dropout(input, self.p, self.training)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Embedding": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py",
      "start_line": 15,
      "end_line": 266,
      "code": "class Embedding(Module):\n\n    __constants__ = [\n        \"num_embeddings\",\n        \"embedding_dim\",\n        \"padding_idx\",\n        \"max_norm\",\n        \"norm_type\",\n        \"scale_grad_by_freq\",\n        \"sparse\",\n    ]\n\n    num_embeddings: int\n    embedding_dim: int\n    padding_idx: Optional[int]\n    max_norm: Optional[float]\n    norm_type: float\n    scale_grad_by_freq: bool\n    weight: Tensor\n    freeze: bool\n    sparse: bool\n\n    def __init__(\n        self,\n        num_embeddings: int,\n        embedding_dim: int,\n        padding_idx: Optional[int] = None,\n        max_norm: Optional[float] = None,\n        norm_type: float = 2.0,\n        scale_grad_by_freq: bool = False,\n        sparse: bool = False,\n        _weight: Optional[Tensor] = None,\n        _freeze: bool = False,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        self.num_embeddings = num_embeddings\n        self.embedding_dim = embedding_dim\n        if padding_idx is not None:\n            if padding_idx > 0:\n                assert (\n                    padding_idx < self.num_embeddings\n                ), \"Padding_idx must be within num_embeddings\"\n            elif padding_idx < 0:\n                assert (\n                    padding_idx >= -self.num_embeddings\n                ), \"Padding_idx must be within num_embeddings\"\n                padding_idx = self.num_embeddings + padding_idx\n        self.padding_idx = padding_idx\n        self.max_norm = max_norm\n        self.norm_type = norm_type\n        self.scale_grad_by_freq = scale_grad_by_freq\n        if _weight is None:\n            self.weight = Parameter(\n                torch.empty((num_embeddings, embedding_dim), **factory_kwargs),\n                requires_grad=not _freeze,\n            )\n            self.reset_parameters()\n        else:\n            assert list(_weight.shape) == [\n                num_embeddings,\n                embedding_dim,\n            ], \"Shape of weight does not match num_embeddings and embedding_dim\"\n            self.weight = Parameter(_weight, requires_grad=not _freeze)\n\n        self.sparse = sparse\n\n    def reset_parameters(self) -> None:\n        init.normal_(self.weight)\n        self._fill_padding_idx_with_zero()\n\n    def _fill_padding_idx_with_zero(self) -> None:\n        if self.padding_idx is not None:\n            with torch.no_grad():\n                self.weight[self.padding_idx].fill_(0)\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.embedding(\n            input,\n            self.weight,\n            self.padding_idx,\n            self.max_norm,\n            self.norm_type,\n            self.scale_grad_by_freq,\n            self.sparse,\n        )\n\n    def extra_repr(self) -> str:\n        s = \"{num_embeddings}, {embedding_dim}\"\n        if self.padding_idx is not None:\n            s += \", padding_idx={padding_idx}\"\n        if self.max_norm is not None:\n            s += \", max_norm={max_norm}\"\n        if self.norm_type != 2:\n            s += \", norm_type={norm_type}\"\n        if self.scale_grad_by_freq is not False:\n            s += \", scale_grad_by_freq={scale_grad_by_freq}\"\n        if self.sparse is not False:\n            s += \", sparse=True\"\n        return s.format(**self.__dict__)\n\n    @classmethod\n    def from_pretrained(\n        cls,\n        embeddings,\n        freeze=True,\n        padding_idx=None,\n        max_norm=None,\n        norm_type=2.0,\n        scale_grad_by_freq=False,\n        sparse=False,\n    ):\n        r\"\"\"Create Embedding instance from given 2-dimensional FloatTensor.\n\n        Args:\n            embeddings (Tensor): FloatTensor containing weights for the Embedding.\n                First dimension is being passed to Embedding as ``num_embeddings``, second as ``embedding_dim``.\n            freeze (bool, optional): If ``True``, the tensor does not get updated in the learning process.\n                Equivalent to ``embedding.weight.requires_grad = False``. Default: ``True``\n            padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n                                         therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n                                         i.e. it remains as a fixed \"pad\".\n            max_norm (float, optional): See module initialization documentation.\n            norm_type (float, optional): See module initialization documentation. Default ``2``.\n            scale_grad_by_freq (bool, optional): See module initialization documentation. Default ``False``.\n            sparse (bool, optional): See module initialization documentation.\n\n        Examples::\n\n            >>> # FloatTensor containing pretrained weights\n            >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n            >>> embedding = nn.Embedding.from_pretrained(weight)\n            >>> # Get embeddings for index 1\n            >>> input = torch.LongTensor([1])\n            >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n            >>> embedding(input)\n            tensor([[ 4.0000,  5.1000,  6.3000]])\n        \"\"\"\n        assert (\n            embeddings.dim() == 2\n        ), \"Embeddings parameter is expected to be 2-dimensional\"\n        rows, cols = embeddings.shape\n        embedding = cls(\n            num_embeddings=rows,\n            embedding_dim=cols,\n            _weight=embeddings,\n            _freeze=freeze,\n            padding_idx=padding_idx,\n            max_norm=max_norm,\n            norm_type=norm_type,\n            scale_grad_by_freq=scale_grad_by_freq,\n            sparse=sparse,\n        )\n        return embedding\n"
    },
    "cpp": {
      "function": "embedding_symint",
      "file": "aten/src/ATen/native/Embedding.cpp",
      "start_line": 37,
      "end_line": 54,
      "code": "Tensor embedding_symint(const Tensor & weight, const Tensor & indices,\n                        c10::SymInt padding_idx, bool scale_grad_by_freq, bool sparse) {\n  TORCH_CHECK(weight.dim() == 2,  \"'weight' must be 2-D\");\n  auto indices_arg = TensorArg(indices, \"indices\", 1);\n  checkScalarTypes(\"embedding\", indices_arg, {kLong, kInt});\n\n  // TODO: use tensor.index() after improving perf\n  if (indices.dim() == 1) {\n    return weight.index_select(0, indices);\n  }\n\n  auto size = indices.sym_sizes().vec();\n  for (const auto& d : weight.sym_sizes().slice(1)) {\n    size.push_back(d);\n  }\n\n  return weight.index_select(0, indices.reshape(-1)).view_symint(size);\n}\n"
    }
  },
  "torch.nn.EmbeddingBag": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py",
      "start_line": 269,
      "end_line": 546,
      "code": "class EmbeddingBag(Module):\n\n    __constants__ = [\n        \"num_embeddings\",\n        \"embedding_dim\",\n        \"max_norm\",\n        \"norm_type\",\n        \"scale_grad_by_freq\",\n        \"mode\",\n        \"sparse\",\n        \"include_last_offset\",\n        \"padding_idx\",\n    ]\n\n    num_embeddings: int\n    embedding_dim: int\n    max_norm: Optional[float]\n    norm_type: float\n    scale_grad_by_freq: bool\n    weight: Tensor\n    mode: str\n    sparse: bool\n    include_last_offset: bool\n    padding_idx: Optional[int]\n\n    def __init__(\n        self,\n        num_embeddings: int,\n        embedding_dim: int,\n        max_norm: Optional[float] = None,\n        norm_type: float = 2.0,\n        scale_grad_by_freq: bool = False,\n        mode: str = \"mean\",\n        sparse: bool = False,\n        _weight: Optional[Tensor] = None,\n        include_last_offset: bool = False,\n        padding_idx: Optional[int] = None,\n        device=None,\n        dtype=None,\n    ) -> None:\n        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        self.num_embeddings = num_embeddings\n        self.embedding_dim = embedding_dim\n        self.max_norm = max_norm\n        self.norm_type = norm_type\n        self.scale_grad_by_freq = scale_grad_by_freq\n        if padding_idx is not None:\n            if padding_idx > 0:\n                assert (\n                    padding_idx < self.num_embeddings\n                ), \"padding_idx must be within num_embeddings\"\n            elif padding_idx < 0:\n                assert (\n                    padding_idx >= -self.num_embeddings\n                ), \"padding_idx must be within num_embeddings\"\n                padding_idx = self.num_embeddings + padding_idx\n        self.padding_idx = padding_idx\n        if _weight is None:\n            self.weight = Parameter(\n                torch.empty((num_embeddings, embedding_dim), **factory_kwargs)\n            )\n            self.reset_parameters()\n        else:\n            assert list(_weight.shape) == [\n                num_embeddings,\n                embedding_dim,\n            ], \"Shape of weight does not match num_embeddings and embedding_dim\"\n            self.weight = Parameter(_weight)\n        self.mode = mode\n        self.sparse = sparse\n        self.include_last_offset = include_last_offset\n\n    def reset_parameters(self) -> None:\n        init.normal_(self.weight)\n        self._fill_padding_idx_with_zero()\n\n    def _fill_padding_idx_with_zero(self) -> None:\n        if self.padding_idx is not None:\n            with torch.no_grad():\n                self.weight[self.padding_idx].fill_(0)\n\n    def forward(\n        self,\n        input: Tensor,\n        offsets: Optional[Tensor] = None,\n        per_sample_weights: Optional[Tensor] = None,\n    ) -> Tensor:\n        \"\"\"Forward pass of EmbeddingBag.\n\n        Args:\n            input (Tensor): Tensor containing bags of indices into the embedding matrix.\n            offsets (Tensor, optional): Only used when :attr:`input` is 1D. :attr:`offsets` determines\n                the starting index position of each bag (sequence) in :attr:`input`.\n            per_sample_weights (Tensor, optional): a tensor of float / double weights, or None\n                to indicate all weights should be taken to be ``1``. If specified, :attr:`per_sample_weights`\n                must have exactly the same shape as input and is treated as having the same\n                :attr:`offsets`, if those are not ``None``. Only supported for ``mode='sum'``.\n\n        Returns:\n            Tensor output shape of `(B, embedding_dim)`.\n\n        .. note::\n\n            A few notes about ``input`` and ``offsets``:\n\n            - :attr:`input` and :attr:`offsets` have to be of the same type, either int or long\n\n            - If :attr:`input` is 2D of shape `(B, N)`, it will be treated as ``B`` bags (sequences)\n              each of fixed length ``N``, and this will return ``B`` values aggregated in a way\n              depending on the :attr:`mode`. :attr:`offsets` is ignored and required to be ``None`` in this case.\n\n            - If :attr:`input` is 1D of shape `(N)`, it will be treated as a concatenation of\n              multiple bags (sequences).  :attr:`offsets` is required to be a 1D tensor containing the\n              starting index positions of each bag in :attr:`input`. Therefore, for :attr:`offsets` of shape `(B)`,\n              :attr:`input` will be viewed as having ``B`` bags. Empty bags (i.e., having 0-length) will have\n              returned vectors filled by zeros.\n        \"\"\"\n        return F.embedding_bag(\n            input,\n            self.weight,\n            offsets,\n            self.max_norm,\n            self.norm_type,\n            self.scale_grad_by_freq,\n            self.mode,\n            self.sparse,\n            per_sample_weights,\n            self.include_last_offset,\n            self.padding_idx,\n        )\n\n    def extra_repr(self) -> str:\n        s = \"{num_embeddings}, {embedding_dim}\"\n        if self.max_norm is not None:\n            s += \", max_norm={max_norm}\"\n        if self.norm_type != 2:\n            s += \", norm_type={norm_type}\"\n        if self.scale_grad_by_freq is not False:\n            s += \", scale_grad_by_freq={scale_grad_by_freq}\"\n        s += \", mode={mode}\"\n        if self.padding_idx is not None:\n            s += \", padding_idx={padding_idx}\"\n        return s.format(**{k: repr(v) for k, v in self.__dict__.items()})\n\n    @classmethod\n    def from_pretrained(\n        cls,\n        embeddings: Tensor,\n        freeze: bool = True,\n        max_norm: Optional[float] = None,\n        norm_type: float = 2.0,\n        scale_grad_by_freq: bool = False,\n        mode: str = \"mean\",\n        sparse: bool = False,\n        include_last_offset: bool = False,\n        padding_idx: Optional[int] = None,\n    ) -> \"EmbeddingBag\":\n        r\"\"\"Create EmbeddingBag instance from given 2-dimensional FloatTensor.\n\n        Args:\n            embeddings (Tensor): FloatTensor containing weights for the EmbeddingBag.\n                First dimension is being passed to EmbeddingBag as 'num_embeddings', second as 'embedding_dim'.\n            freeze (bool, optional): If ``True``, the tensor does not get updated in the learning process.\n                Equivalent to ``embeddingbag.weight.requires_grad = False``. Default: ``True``\n            max_norm (float, optional): See module initialization documentation. Default: ``None``\n            norm_type (float, optional): See module initialization documentation. Default ``2``.\n            scale_grad_by_freq (bool, optional): See module initialization documentation. Default ``False``.\n            mode (str, optional): See module initialization documentation. Default: ``\"mean\"``\n            sparse (bool, optional): See module initialization documentation. Default: ``False``.\n            include_last_offset (bool, optional): See module initialization documentation. Default: ``False``.\n            padding_idx (int, optional): See module initialization documentation. Default: ``None``.\n\n        Examples::\n\n            >>> # FloatTensor containing pretrained weights\n            >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n            >>> embeddingbag = nn.EmbeddingBag.from_pretrained(weight)\n            >>> # Get embeddings for index 1\n            >>> input = torch.LongTensor([[1, 0]])\n            >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n            >>> embeddingbag(input)\n            tensor([[ 2.5000,  3.7000,  4.6500]])\n        \"\"\"\n        assert (\n            embeddings.dim() == 2\n        ), \"Embeddings parameter is expected to be 2-dimensional\"\n        rows, cols = embeddings.shape\n        embeddingbag = cls(\n            num_embeddings=rows,\n            embedding_dim=cols,\n            _weight=embeddings,\n            max_norm=max_norm,\n            norm_type=norm_type,\n            scale_grad_by_freq=scale_grad_by_freq,\n            mode=mode,\n            sparse=sparse,\n            include_last_offset=include_last_offset,\n            padding_idx=padding_idx,\n        )\n        embeddingbag.weight.requires_grad = not freeze\n        return embeddingbag\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.CosineSimilarity": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\distance.py",
      "start_line": 61,
      "end_line": 93,
      "code": "class CosineSimilarity(Module):\n\n    __constants__ = [\"dim\", \"eps\"]\n    dim: int\n    eps: float\n\n    def __init__(self, dim: int = 1, eps: float = 1e-8) -> None:\n        super().__init__()\n        self.dim = dim\n        self.eps = eps\n\n    def forward(self, x1: Tensor, x2: Tensor) -> Tensor:\n        return F.cosine_similarity(x1, x2, self.dim, self.eps)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.PairwiseDistance": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\distance.py",
      "start_line": 10,
      "end_line": 58,
      "code": "class PairwiseDistance(Module):\n\n    __constants__ = [\"norm\", \"eps\", \"keepdim\"]\n    norm: float\n    eps: float\n    keepdim: bool\n\n    def __init__(\n        self, p: float = 2.0, eps: float = 1e-6, keepdim: bool = False\n    ) -> None:\n        super().__init__()\n        self.norm = p\n        self.eps = eps\n        self.keepdim = keepdim\n\n    def forward(self, x1: Tensor, x2: Tensor) -> Tensor:\n        return F.pairwise_distance(x1, x2, self.norm, self.eps, self.keepdim)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.L1Loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 62,
      "end_line": 128,
      "code": "class L1Loss(_Loss):\n    __constants__ = [\"reduction\"]\n\n    def __init__(self, size_average=None, reduce=None, reduction: str = \"mean\") -> None:\n        super().__init__(size_average, reduce, reduction)\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.l1_loss(input, target, reduction=self.reduction)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MSELoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 546,
      "end_line": 608,
      "code": "class MSELoss(_Loss):\n    __constants__ = [\"reduction\"]\n\n    def __init__(self, size_average=None, reduce=None, reduction: str = \"mean\") -> None:\n        super().__init__(size_average, reduce, reduction)\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.mse_loss(input, target, reduction=self.reduction)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.CrossEntropyLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 1144,
      "end_line": 1300,
      "code": "class CrossEntropyLoss(_WeightedLoss):\n    __constants__ = [\"ignore_index\", \"reduction\", \"label_smoothing\"]\n    ignore_index: int\n    label_smoothing: float\n\n    def __init__(\n        self,\n        weight: Optional[Tensor] = None,\n        size_average=None,\n        ignore_index: int = -100,\n        reduce=None,\n        reduction: str = \"mean\",\n        label_smoothing: float = 0.0,\n    ) -> None:\n        super().__init__(weight, size_average, reduce, reduction)\n        self.ignore_index = ignore_index\n        self.label_smoothing = label_smoothing\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.cross_entropy(\n            input,\n            target,\n            weight=self.weight,\n            ignore_index=self.ignore_index,\n            reduction=self.reduction,\n            label_smoothing=self.label_smoothing,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.NLLLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 131,
      "end_line": 257,
      "code": "class NLLLoss(_WeightedLoss):\n    __constants__ = [\"ignore_index\", \"reduction\"]\n    ignore_index: int\n\n    def __init__(\n        self,\n        weight: Optional[Tensor] = None,\n        size_average=None,\n        ignore_index: int = -100,\n        reduce=None,\n        reduction: str = \"mean\",\n    ) -> None:\n        super().__init__(weight, size_average, reduce, reduction)\n        self.ignore_index = ignore_index\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.nll_loss(\n            input,\n            target,\n            weight=self.weight,\n            ignore_index=self.ignore_index,\n            reduction=self.reduction,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.CTCLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 1828,
      "end_line": 1988,
      "code": "class CTCLoss(_Loss):\n    __constants__ = [\"blank\", \"reduction\"]\n    blank: int\n    zero_infinity: bool\n\n    def __init__(\n        self, blank: int = 0, reduction: str = \"mean\", zero_infinity: bool = False\n    ):\n        super().__init__(reduction=reduction)\n        self.blank = blank\n        self.zero_infinity = zero_infinity\n\n    def forward(\n        self,\n        log_probs: Tensor,\n        targets: Tensor,\n        input_lengths: Tensor,\n        target_lengths: Tensor,\n    ) -> Tensor:\n        return F.ctc_loss(\n            log_probs,\n            targets,\n            input_lengths,\n            target_lengths,\n            self.blank,\n            self.reduction,\n            self.zero_infinity,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.PoissonNLLLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 278,
      "end_line": 361,
      "code": "class PoissonNLLLoss(_Loss):\n    __constants__ = [\"log_input\", \"full\", \"eps\", \"reduction\"]\n    log_input: bool\n    full: bool\n    eps: float\n\n    def __init__(\n        self,\n        log_input: bool = True,\n        full: bool = False,\n        size_average=None,\n        eps: float = 1e-8,\n        reduce=None,\n        reduction: str = \"mean\",\n    ) -> None:\n        super().__init__(size_average, reduce, reduction)\n        self.log_input = log_input\n        self.full = full\n        self.eps = eps\n\n    def forward(self, log_input: Tensor, target: Tensor) -> Tensor:\n        return F.poisson_nll_loss(\n            log_input,\n            target,\n            log_input=self.log_input,\n            full=self.full,\n            eps=self.eps,\n            reduction=self.reduction,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.GaussianNLLLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 364,
      "end_line": 444,
      "code": "class GaussianNLLLoss(_Loss):\n    __constants__ = [\"full\", \"eps\", \"reduction\"]\n    full: bool\n    eps: float\n\n    def __init__(\n        self, *, full: bool = False, eps: float = 1e-6, reduction: str = \"mean\"\n    ) -> None:\n        super().__init__(None, None, reduction)\n        self.full = full\n        self.eps = eps\n\n    def forward(self, input: Tensor, target: Tensor, var: Tensor) -> Tensor:\n        return F.gaussian_nll_loss(\n            input, target, var, full=self.full, eps=self.eps, reduction=self.reduction\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.KLDivLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 447,
      "end_line": 543,
      "code": "class KLDivLoss(_Loss):\n    __constants__ = [\"reduction\"]\n\n    def __init__(\n        self,\n        size_average=None,\n        reduce=None,\n        reduction: str = \"mean\",\n        log_target: bool = False,\n    ) -> None:\n        super().__init__(size_average, reduce, reduction)\n        self.log_target = log_target\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.kl_div(\n            input, target, reduction=self.reduction, log_target=self.log_target\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.BCELoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 611,
      "end_line": 699,
      "code": "class BCELoss(_WeightedLoss):\n    __constants__ = [\"reduction\"]\n\n    def __init__(\n        self,\n        weight: Optional[Tensor] = None,\n        size_average=None,\n        reduce=None,\n        reduction: str = \"mean\",\n    ) -> None:\n        super().__init__(weight, size_average, reduce, reduction)\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.binary_cross_entropy(\n            input, target, weight=self.weight, reduction=self.reduction\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.BCEWithLogitsLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 702,
      "end_line": 825,
      "code": "class BCEWithLogitsLoss(_Loss):\n\n    def __init__(\n        self,\n        weight: Optional[Tensor] = None,\n        size_average=None,\n        reduce=None,\n        reduction: str = \"mean\",\n        pos_weight: Optional[Tensor] = None,\n    ) -> None:\n        super().__init__(size_average, reduce, reduction)\n        self.register_buffer(\"weight\", weight)\n        self.register_buffer(\"pos_weight\", pos_weight)\n        self.weight: Optional[Tensor]\n        self.pos_weight: Optional[Tensor]\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.binary_cross_entropy_with_logits(\n            input,\n            target,\n            self.weight,\n            pos_weight=self.pos_weight,\n            reduction=self.reduction,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MarginRankingLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 1428,
      "end_line": 1490,
      "code": "class MarginRankingLoss(_Loss):\n    __constants__ = [\"margin\", \"reduction\"]\n    margin: float\n\n    def __init__(\n        self,\n        margin: float = 0.0,\n        size_average=None,\n        reduce=None,\n        reduction: str = \"mean\",\n    ) -> None:\n        super().__init__(size_average, reduce, reduction)\n        self.margin = margin\n\n    def forward(self, input1: Tensor, input2: Tensor, target: Tensor) -> Tensor:\n        return F.margin_ranking_loss(\n            input1, input2, target, margin=self.margin, reduction=self.reduction\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.HingeEmbeddingLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 828,
      "end_line": 893,
      "code": "class HingeEmbeddingLoss(_Loss):\n    __constants__ = [\"margin\", \"reduction\"]\n    margin: float\n\n    def __init__(\n        self,\n        margin: float = 1.0,\n        size_average=None,\n        reduce=None,\n        reduction: str = \"mean\",\n    ) -> None:\n        super().__init__(size_average, reduce, reduction)\n        self.margin = margin\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.hinge_embedding_loss(\n            input, target, margin=self.margin, reduction=self.reduction\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MultiLabelMarginLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 896,
      "end_line": 957,
      "code": "class MultiLabelMarginLoss(_Loss):\n    __constants__ = [\"reduction\"]\n\n    def __init__(self, size_average=None, reduce=None, reduction: str = \"mean\") -> None:\n        super().__init__(size_average, reduce, reduction)\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.multilabel_margin_loss(input, target, reduction=self.reduction)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.SmoothL1Loss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 960,
      "end_line": 1040,
      "code": "class SmoothL1Loss(_Loss):\n    __constants__ = [\"reduction\"]\n\n    def __init__(\n        self, size_average=None, reduce=None, reduction: str = \"mean\", beta: float = 1.0\n    ) -> None:\n        super().__init__(size_average, reduce, reduction)\n        self.beta = beta\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.SoftMarginLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 1103,
      "end_line": 1141,
      "code": "class SoftMarginLoss(_Loss):\n    __constants__ = [\"reduction\"]\n\n    def __init__(self, size_average=None, reduce=None, reduction: str = \"mean\") -> None:\n        super().__init__(size_average, reduce, reduction)\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.soft_margin_loss(input, target, reduction=self.reduction)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MultiLabelSoftMarginLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 1303,
      "end_line": 1355,
      "code": "class MultiLabelSoftMarginLoss(_WeightedLoss):\n    __constants__ = [\"reduction\"]\n\n    def __init__(\n        self,\n        weight: Optional[Tensor] = None,\n        size_average=None,\n        reduce=None,\n        reduction: str = \"mean\",\n    ) -> None:\n        super().__init__(weight, size_average, reduce, reduction)\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.multilabel_soft_margin_loss(\n            input, target, weight=self.weight, reduction=self.reduction\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.CosineEmbeddingLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 1358,
      "end_line": 1425,
      "code": "class CosineEmbeddingLoss(_Loss):\n    __constants__ = [\"margin\", \"reduction\"]\n    margin: float\n\n    def __init__(\n        self,\n        margin: float = 0.0,\n        size_average=None,\n        reduce=None,\n        reduction: str = \"mean\",\n    ) -> None:\n        super().__init__(size_average, reduce, reduction)\n        self.margin = margin\n\n    def forward(self, input1: Tensor, input2: Tensor, target: Tensor) -> Tensor:\n        return F.cosine_embedding_loss(\n            input1, input2, target, margin=self.margin, reduction=self.reduction\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.MultiMarginLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 1493,
      "end_line": 1584,
      "code": "class MultiMarginLoss(_WeightedLoss):\n    __constants__ = [\"p\", \"margin\", \"reduction\"]\n    margin: float\n    p: int\n\n    def __init__(\n        self,\n        p: int = 1,\n        margin: float = 1.0,\n        weight: Optional[Tensor] = None,\n        size_average=None,\n        reduce=None,\n        reduction: str = \"mean\",\n    ) -> None:\n        super().__init__(weight, size_average, reduce, reduction)\n        if p != 1 and p != 2:\n            raise ValueError(\"only p == 1 and p == 2 supported\")\n        if weight is not None and weight.dim() != 1:\n            raise ValueError(\n                f\"MultiMarginLoss: expected weight to be None or 1D tensor, got {weight.dim()}D instead\"\n            )\n        self.p = p\n        self.margin = margin\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n        return F.multi_margin_loss(\n            input,\n            target,\n            p=self.p,\n            margin=self.margin,\n            weight=self.weight,\n            reduction=self.reduction,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.TripletMarginLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 1587,
      "end_line": 1692,
      "code": "class TripletMarginLoss(_Loss):\n    __constants__ = [\"margin\", \"p\", \"eps\", \"swap\", \"reduction\"]\n    margin: float\n    p: float\n    eps: float\n    swap: bool\n\n    def __init__(\n        self,\n        margin: float = 1.0,\n        p: float = 2.0,\n        eps: float = 1e-6,\n        swap: bool = False,\n        size_average=None,\n        reduce=None,\n        reduction: str = \"mean\",\n    ):\n        super().__init__(size_average, reduce, reduction)\n        if margin <= 0:\n            raise ValueError(\n                f\"TripletMarginLoss: expected margin to be greater than 0, got {margin} instead\"\n            )\n        self.margin = margin\n        self.p = p\n        self.eps = eps\n        self.swap = swap\n\n    def forward(self, anchor: Tensor, positive: Tensor, negative: Tensor) -> Tensor:\n        return F.triplet_margin_loss(\n            anchor,\n            positive,\n            negative,\n            margin=self.margin,\n            p=self.p,\n            eps=self.eps,\n            swap=self.swap,\n            reduction=self.reduction,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.TripletMarginWithDistanceLoss": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\loss.py",
      "start_line": 1695,
      "end_line": 1825,
      "code": "class TripletMarginWithDistanceLoss(_Loss):\n    __constants__ = [\"margin\", \"swap\", \"reduction\"]\n    margin: float\n    swap: bool\n\n    def __init__(\n        self,\n        *,\n        distance_function: Optional[Callable[[Tensor, Tensor], Tensor]] = None,\n        margin: float = 1.0,\n        swap: bool = False,\n        reduction: str = \"mean\",\n    ):\n        super().__init__(size_average=None, reduce=None, reduction=reduction)\n        if margin <= 0:\n            raise ValueError(\n                f\"TripletMarginWithDistanceLoss: expected margin to be greater than 0, got {margin} instead\"\n            )\n        self.distance_function: Optional[Callable[[Tensor, Tensor], Tensor]] = (\n            distance_function if distance_function is not None else PairwiseDistance()\n        )\n        self.margin = margin\n        self.swap = swap\n\n    def forward(self, anchor: Tensor, positive: Tensor, negative: Tensor) -> Tensor:\n        return F.triplet_margin_with_distance_loss(\n            anchor,\n            positive,\n            negative,\n            distance_function=self.distance_function,\n            margin=self.margin,\n            swap=self.swap,\n            reduction=self.reduction,\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.PixelShuffle": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pixelshuffle.py",
      "start_line": 10,
      "end_line": 62,
      "code": "class PixelShuffle(Module):\n\n    __constants__ = [\"upscale_factor\"]\n    upscale_factor: int\n\n    def __init__(self, upscale_factor: int) -> None:\n        super().__init__()\n        self.upscale_factor = upscale_factor\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.pixel_shuffle(input, self.upscale_factor)\n\n    def extra_repr(self) -> str:\n        return f\"upscale_factor={self.upscale_factor}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.PixelUnshuffle": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\pixelshuffle.py",
      "start_line": 65,
      "end_line": 115,
      "code": "class PixelUnshuffle(Module):\n\n    __constants__ = [\"downscale_factor\"]\n    downscale_factor: int\n\n    def __init__(self, downscale_factor: int) -> None:\n        super().__init__()\n        self.downscale_factor = downscale_factor\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.pixel_unshuffle(input, self.downscale_factor)\n\n    def extra_repr(self) -> str:\n        return f\"downscale_factor={self.downscale_factor}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Upsample": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\upsampling.py",
      "start_line": 14,
      "end_line": 193,
      "code": "class Upsample(Module):\n\n    __constants__ = [\n        \"size\",\n        \"scale_factor\",\n        \"mode\",\n        \"align_corners\",\n        \"name\",\n        \"recompute_scale_factor\",\n    ]\n    name: str\n    size: Optional[_size_any_t]\n    scale_factor: Optional[_ratio_any_t]\n    mode: str\n    align_corners: Optional[bool]\n    recompute_scale_factor: Optional[bool]\n\n    def __init__(\n        self,\n        size: Optional[_size_any_t] = None,\n        scale_factor: Optional[_ratio_any_t] = None,\n        mode: str = \"nearest\",\n        align_corners: Optional[bool] = None,\n        recompute_scale_factor: Optional[bool] = None,\n    ) -> None:\n        super().__init__()\n        self.name = type(self).__name__\n        self.size = size\n        if isinstance(scale_factor, tuple):\n            self.scale_factor = tuple(float(factor) for factor in scale_factor)\n        else:\n            self.scale_factor = float(scale_factor) if scale_factor else None\n        self.mode = mode\n        self.align_corners = align_corners\n        self.recompute_scale_factor = recompute_scale_factor\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.interpolate(\n            input,\n            self.size,\n            self.scale_factor,\n            self.mode,\n            self.align_corners,\n            recompute_scale_factor=self.recompute_scale_factor,\n        )\n\n    def __setstate__(self, state):\n        if \"recompute_scale_factor\" not in state:\n            state[\"recompute_scale_factor\"] = True\n\n        super().__setstate__(state)\n\n    def extra_repr(self) -> str:\n        if self.scale_factor is not None:\n            info = \"scale_factor=\" + repr(self.scale_factor)\n        else:\n            info = \"size=\" + repr(self.size)\n        info += \", mode=\" + repr(self.mode)\n        return info\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.UpsamplingNearest2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\upsampling.py",
      "start_line": 196,
      "end_line": 242,
      "code": "class UpsamplingNearest2d(Upsample):\n\n    def __init__(\n        self,\n        size: Optional[_size_2_t] = None,\n        scale_factor: Optional[_ratio_2_t] = None,\n    ) -> None:\n        super().__init__(size, scale_factor, mode=\"nearest\")\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.UpsamplingBilinear2d": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\upsampling.py",
      "start_line": 245,
      "end_line": 293,
      "code": "class UpsamplingBilinear2d(Upsample):\n\n    def __init__(\n        self,\n        size: Optional[_size_2_t] = None,\n        scale_factor: Optional[_ratio_2_t] = None,\n    ) -> None:\n        super().__init__(size, scale_factor, mode=\"bilinear\", align_corners=True)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.ChannelShuffle": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\channelshuffle.py",
      "start_line": 10,
      "end_line": 56,
      "code": "class ChannelShuffle(Module):\n\n    __constants__ = [\"groups\"]\n    groups: int\n\n    def __init__(self, groups: int) -> None:\n        super().__init__()\n        self.groups = groups\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.channel_shuffle(input, self.groups)\n\n    def extra_repr(self) -> str:\n        return f\"groups={self.groups}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.DataParallel": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py",
      "start_line": 52,
      "end_line": 217,
      "code": "class DataParallel(Module, Generic[T]):\n\n    # TODO: update notes/cuda.rst when this class handles 8+ GPUs well\n\n    def __init__(\n        self,\n        module: T,\n        device_ids: Optional[Sequence[Union[int, torch.device]]] = None,\n        output_device: Optional[Union[int, torch.device]] = None,\n        dim: int = 0,\n    ) -> None:\n        super().__init__()\n        torch._C._log_api_usage_once(\"torch.nn.parallel.DataParallel\")\n        device_type = _get_available_device_type()\n        if device_type is None:\n            self.module = module\n            self.device_ids = []\n            return\n\n        if device_ids is None:\n            device_ids = _get_all_device_indices()\n\n        if device_ids is None:\n            raise RuntimeError(\"no available devices were found\")\n\n        if output_device is None:\n            output_device = device_ids[0]\n\n        self.dim = dim\n        self.module = module\n        self.device_ids = [_get_device_index(x, True) for x in device_ids]\n        self.output_device = _get_device_index(output_device, True)\n        self.src_device_obj = torch.device(device_type, self.device_ids[0])\n\n        if device_type == \"cuda\":\n            _check_balance(self.device_ids)\n\n        if len(self.device_ids) == 1:\n            self.module.to(self.src_device_obj)\n\n    def forward(self, *inputs: Any, **kwargs: Any) -> Any:\n        with torch.autograd.profiler.record_function(\"DataParallel.forward\"):\n            if not self.device_ids:\n                return self.module(*inputs, **kwargs)\n\n            for t in chain(self.module.parameters(), self.module.buffers()):\n                if t.device != self.src_device_obj:\n                    raise RuntimeError(\n                        \"module must have its parameters and buffers \"\n                        f\"on device {self.src_device_obj} (device_ids[0]) but found one of \"\n                        f\"them on device: {t.device}\"\n                    )\n\n            inputs, module_kwargs = self.scatter(inputs, kwargs, self.device_ids)\n            # for forward function without any inputs, empty list and dict will be created\n            # so the module can be executed on one device which is the first one in device_ids\n            if not inputs and not module_kwargs:\n                inputs = ((),)\n                module_kwargs = ({},)\n\n            if len(self.device_ids) == 1:\n                return self.module(*inputs[0], **module_kwargs[0])\n            replicas = self.replicate(self.module, self.device_ids[: len(inputs)])\n            outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n            return self.gather(outputs, self.output_device)\n\n    def replicate(\n        self, module: T, device_ids: Sequence[Union[int, torch.device]]\n    ) -> List[T]:\n        return replicate(module, device_ids, not torch.is_grad_enabled())\n\n    def scatter(\n        self,\n        inputs: Tuple[Any, ...],\n        kwargs: Optional[Dict[str, Any]],\n        device_ids: Sequence[Union[int, torch.device]],\n    ) -> Any:\n        return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)\n\n    def parallel_apply(\n        self, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any\n    ) -> List[Any]:\n        return parallel_apply(\n            replicas, inputs, kwargs, self.device_ids[: len(replicas)]\n        )\n\n    def gather(self, outputs: Any, output_device: Union[int, torch.device]) -> Any:\n        return gather(outputs, output_device, dim=self.dim)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.parallel.DistributedDataParallel": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\parallel\\distributed.py",
      "start_line": 326,
      "end_line": 2406,
      "code": "class DistributedDataParallel(Module, Joinable):\n\n    # used to track whether the given thread is inside ddp forward for torchdynamo purposes\n    _active_ddp_module: Optional[\"DistributedDataParallel\"] = None\n\n    def __init__(\n        self,\n        module,\n        device_ids=None,\n        output_device=None,\n        dim=0,\n        broadcast_buffers=True,\n        process_group=None,\n        bucket_cap_mb=None,\n        find_unused_parameters=False,\n        check_reduction=False,\n        gradient_as_bucket_view=False,\n        static_graph=False,\n        delay_all_reduce_named_params=None,\n        param_to_hook_all_reduce=None,\n        mixed_precision: Optional[_MixedPrecision] = None,\n        device_mesh=None,\n    ):\n        super().__init__()\n        Joinable.__init__(self)\n        self.logger: Optional[dist.Logger] = None\n        if bool(delay_all_reduce_named_params is not None) != bool(\n            param_to_hook_all_reduce is not None\n        ):\n            self._log_and_throw(\n                ValueError,\n                \"delay_all_reduce_named_params and param_to_hook_all_reduce \"\n                \"need to be set at the same time.\",\n            )\n\n        if process_group and device_mesh is not None:\n            raise RuntimeError(\n                \"Cannot specify both process_group and device_mesh arguments.\"\n            )\n        elif process_group is None and device_mesh is None:\n            self.process_group = _get_default_group()\n        elif device_mesh is None:\n            self.process_group = process_group\n        else:\n            if device_mesh.ndim != 1:\n                raise RuntimeError(\n                    f\"Only 1D device mesh is supported, but got {device_mesh}.\"\n                )\n            self.device_mesh = device_mesh\n            self.process_group = device_mesh.get_group(mesh_dim=0)\n            from torch.distributed.device_mesh import _mesh_resources\n\n            root_mesh = _mesh_resources.get_root_mesh(device_mesh)\n            # if a root mesh is not the same as device_mesh,\n            # meaning the device_mesh is sliced out from the root mesh.\n            if root_mesh != device_mesh:\n                # TODO: This is a temporary work around to enable DDP + TP.\n                # We should do the logic in DDP so that the 2D implementation is\n                # sound and the state_dict works out of the box.\n                # This has to be done before check UninitializedParameter.\n                from torch.distributed.tensor.parallel.ddp import (\n                    _pre_dp_module_transform,\n                )\n\n                _pre_dp_module_transform(module)\n\n        self._delay_all_reduce_params = []\n        if hasattr(module, \"_ddp_params_and_buffers_to_ignore\"):\n            self.parameters_to_ignore = set(module._ddp_params_and_buffers_to_ignore)\n        else:\n            self.parameters_to_ignore = set()\n        if delay_all_reduce_named_params is not None:\n            for name, param in delay_all_reduce_named_params:\n                self.parameters_to_ignore.add(name)\n                self._delay_all_reduce_params.append(param)\n\n        self._module_parameters = [\n            p\n            for n, p in module.named_parameters()\n            if n not in self.parameters_to_ignore\n        ]\n        if not any(p.requires_grad for p in self._module_parameters):\n            if len(self._delay_all_reduce_params):\n                logger.info(\"Delay the AllReduce of all parameters.\")\n            else:\n                self._log_and_throw(\n                    RuntimeError,\n                    \"DistributedDataParallel is not needed when a module \"\n                    \"doesn't have any parameter that requires a gradient.\",\n                )\n\n        if device_ids is not None and len(device_ids) > 1:\n            self._log_and_throw(\n                ValueError,\n                \"device_ids can only be None or contain a single element.\",\n            )\n\n        self.is_multi_device_module = (\n            len({p.device for p in self._module_parameters}) > 1\n        )\n        distinct_device_types = {\n            p.device.type for p in self._module_parameters if p.device is not None\n        }\n        if len(distinct_device_types) != 1:\n            self._log_and_throw(\n                ValueError,\n                \"DistributedDataParallel's input module must be on \"\n                f\"the same type of devices, but input module parameters locate in {distinct_device_types}.\",\n            )\n\n        self.device_type = next(iter(distinct_device_types))\n\n        if (\n            device_ids is None\n            or len(device_ids) == 0  # For backward compatibility.\n            or self.device_type == \"cpu\"\n            or self.is_multi_device_module\n        ):\n            if device_ids or output_device:\n                self._log_and_throw(\n                    ValueError,\n                    \"DistributedDataParallel device_ids and output_device arguments \"\n                    \"only work with single-device/multiple-device GPU modules or CPU modules, \"\n                    f\"but got device_ids {device_ids}, output_device {output_device}, \"\n                    f\"and module parameters {({p.device for p in self._module_parameters})}.\",\n                )\n\n            self.device_ids = None\n            self.output_device = None\n        else:\n            self.device_ids = [_get_device_index(x, True) for x in device_ids]\n\n            if output_device is None:\n                output_device = device_ids[0]\n\n            self.output_device = _get_device_index(output_device, True)\n\n        self.static_graph = False\n        self.dim = dim\n        self.module = module\n        self.device = next(iter(self._module_parameters)).device\n        self.broadcast_buffers = broadcast_buffers\n        self.find_unused_parameters = find_unused_parameters\n        self.require_backward_grad_sync = True\n        self.require_forward_param_sync = True\n        self.gradient_as_bucket_view = gradient_as_bucket_view\n        self.mixed_precision = mixed_precision\n        if self.mixed_precision is not None:\n            logger.warning(\"Received mixed precision config %s\", self.mixed_precision)\n\n        if check_reduction:\n            # This argument is no longer used since the reducer\n            # will ensure reduction completes even if some parameters\n            # do not receive gradients.\n            warnings.warn(\n                \"The `check_reduction` argument in `DistributedDataParallel` \"\n                \"module is deprecated. Please avoid using it.\",\n                FutureWarning,\n                stacklevel=2,\n            )\n\n        # Check that a module does not have Uninitialized parameters\n        for param in self._module_parameters:\n            if isinstance(param, torch.nn.parameter.UninitializedParameter):\n                self._log_and_throw(\n                    RuntimeError,\n                    \"Modules with uninitialized parameters can't be used with `DistributedDataParallel`. \"\n                    \"Run a dummy forward pass to correctly initialize the modules\",\n                )\n        # used for intra-node param sync and inter-node sync as well\n        self.broadcast_bucket_size = int(250 * 1024 * 1024)\n\n        # reduction bucket size\n        if bucket_cap_mb is None:\n            # default case (bucket cap is 25 MiB)\n            bucket_cap_mb = 25\n            self.bucket_bytes_cap_default = True\n        else:\n            self.bucket_bytes_cap_default = False\n        self.bucket_bytes_cap = int(bucket_cap_mb * 1024 * 1024)\n\n        # Whether to perform input tensor CPU to GPU copies on a side-stream\n        self.use_side_stream_for_tensor_copies = (\n            os.environ.get(\"PYTORCH_DDP_USE_SIDE_STREAM\", \"1\") == \"1\"\n        )\n\n        # Initialize gradient buffers and register all reduce hook\n        self._delay_grad_buffer: Optional[torch.Tensor] = None\n        self._delay_grad_views: List[torch.Tensor] = []\n        self._delay_all_reduce_all_params = False\n        if len(self._delay_all_reduce_params) != 0:\n            self._register_delay_all_reduce_hook(\n                bucket_cap_mb=bucket_cap_mb,\n                param_to_hook_all_reduce=param_to_hook_all_reduce,\n                device_ids=device_ids,\n            )\n            if self._delay_all_reduce_all_params:\n                return\n\n        # Build parameters for reducer.\n        parameters, expect_sparse_gradient = self._build_params_for_reducer()\n        # Verify model equivalence.\n        _verify_param_shape_across_processes(self.process_group, parameters)\n        # Sync params and buffers. Ensures all DDP models start off at the same value.\n        _sync_module_states(\n            module=self.module,\n            process_group=self.process_group,\n            broadcast_bucket_size=self.broadcast_bucket_size,\n            src=0,\n            params_and_buffers_to_ignore=self.parameters_to_ignore,\n            broadcast_buffers=self.broadcast_buffers,\n        )\n        # In debug mode, build a mapping of parameter index -> parameter.\n        param_to_name_mapping = self._build_debug_param_to_name_mapping(parameters)\n\n        # Builds reducer.\n        self._ddp_init_helper(\n            parameters,\n            expect_sparse_gradient,\n            param_to_name_mapping,\n            static_graph,\n        )\n        self._comm_hooks: List[Tuple[Callable, object]] = []\n\n        if self.mixed_precision is not None:\n            _setup_mixed_precision_params(self.mixed_precision, self.module)\n            _cast_buffers(self.mixed_precision, self.module)\n            # Stream used for async low precision copies.\n            self._mp_stream = torch.cuda.Stream()\n            self._submodule_to_event = defaultdict(deque)  # type: ignore[var-annotated]\n            # Add forward pre-hook to root module to kick off copies to lower\n            # precision.\n            self.module.register_forward_pre_hook(\n                self._root_copy_hook, prepend=False, with_kwargs=True\n            )\n            # Add forward pre hook to all submodules to wait for copy events\n            # before running computation.\n            for module in self.module.modules():\n                module.register_forward_pre_hook(\n                    self._module_wait_for_copy_hook,\n                    prepend=False,\n                    with_kwargs=True,\n                )\n            # Set up callbacks in backward to upcast and use full precision\n            # params. TODO (rohan-varma): Make this compose with general\n            # comm hooks and apply_optimizer_in_backward. Importing inline to\n            # avoid circular import issue.\n            from torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks import (\n                _AllreduceUpcastHookState,\n                _reducer_allreduce_and_upcast_hook,\n            )\n\n            upcast_hook_state = _AllreduceUpcastHookState(\n                ddp_weakref=weakref.ref(self),\n                upcast_stream=torch.cuda.Stream(),\n            )\n            self.register_comm_hook(\n                upcast_hook_state,\n                _reducer_allreduce_and_upcast_hook,\n            )\n            # Inform reducer of reduced precision param dtype for correctness\n            # of type checks between gradient and bucket.\n            self.reducer._set_mixed_precision_param_dtype(  # type: ignore[attr-defined]\n                self.mixed_precision.param_dtype\n            )\n\n        self._has_rebuilt_buckets = False\n\n        if static_graph:\n            self._set_static_graph()\n\n        self._lazy_init_ran = False\n\n        # Register the AccumulateGrad post hooks if optimize_ddp is\n        # True. The hooks will be deregistered if compiled_autograd is not\n        # enabled.\n        self._accum_grad_hooks: List[RemovableHandle] = []\n        optimize_ddp = torch._dynamo.config._get_optimize_ddp_mode()\n        self._use_python_reducer = optimize_ddp in (\n            \"python_reducer\",\n            \"python_reducer_without_compiled_forward\",\n        )\n        if self._use_python_reducer:\n            torch._inductor.config._fuse_ddp_communication = True\n            torch._inductor.config._fuse_ddp_bucket_size = bucket_cap_mb\n            # Directly adding this to the trace rule will disturb the users\n            # who are using DDPOptimizer.\n            torch._dynamo.trace_rules.LEGACY_MOD_INLINELIST.add(\n                \"torch.nn.parallel.distributed\"\n            )\n            torch._dynamo.trace_rules.get_legacy_mod_inlinelist.cache_clear()\n        self._force_to_disable_cpp_reducer = (\n            optimize_ddp == \"python_reducer_without_compiled_forward\"\n        )\n        if self._use_python_reducer:\n            self._register_accum_grad_hook()\n\n        # Whether or not DDPSink performs a clone.\n        self._ddp_sink_clone = True\n\n    def _register_accum_grad_hook(self):\n        import torch.distributed._functional_collectives as fcol\n\n        def compiled_accum_grad_hook(\n            param,\n            *,\n            param_index: int,\n        ):\n            if not self.require_backward_grad_sync:\n                return\n\n            if param.grad is None:\n                return\n\n            if self._comm_hooks:\n                for hook, state in self._comm_hooks:\n                    hook(state, (param.grad, param))\n            else:\n                gradient = param.grad / self.process_group.size()\n                gradient = fcol.all_reduce(gradient, \"sum\", self.process_group)\n                param.grad.copy_(gradient)\n\n        for index, param in enumerate(self._module_parameters):\n            if not param.requires_grad:\n                continue\n            self._accum_grad_hooks.append(\n                param.register_post_accumulate_grad_hook(\n                    functools.partial(\n                        compiled_accum_grad_hook,\n                        param_index=index,\n                    )\n                )\n            )\n\n    def _delayed_all_reduce_hook(self, grad):\n        world_size = dist.get_world_size(self.process_group)\n\n        self._delay_grad_buffer.div_(world_size)  # type: ignore[union-attr]\n        _ = dist.all_reduce(\n            self._delay_grad_buffer, group=self.process_group, async_op=True\n        )\n        return grad\n\n    def _register_delay_all_reduce_hook(\n        self,\n        bucket_cap_mb,\n        param_to_hook_all_reduce,\n        device_ids,\n    ):\n        # 1. Create gradient buffer\n        device = torch.device(\"cpu\") if device_ids is None else device_ids[0]\n        self._delay_grad_buffer = torch.zeros(\n            sum(p.numel() for p in self._delay_all_reduce_params),\n            device=device,\n        )\n\n        # 2. Broadcast the parameters\n        detached_params = [p.detach() for p in self._delay_all_reduce_params]\n        dist._broadcast_coalesced(self.process_group, detached_params, bucket_cap_mb, 0)\n\n        # 3. Hook all reduce to the specified parameter\n        param_to_hook_all_reduce.register_hook(self._delayed_all_reduce_hook)\n\n        # 4. Build tensor views for gradients\n        offset = 0\n        for param in self._delay_all_reduce_params:\n            grad_view = self._delay_grad_buffer[offset : (offset + param.numel())].view(\n                param.shape\n            )\n            self._delay_grad_views.append(grad_view)\n            offset = offset + param.numel()\n\n        # 5. Check whether the all reduce of all params requiring grad is delayed.\n        for module_name, module in self.module.named_modules():\n            for param_name, param in module.named_parameters(recurse=False):\n                if param.requires_grad:\n                    full_name = f\"{module_name}.{param_name}\"\n                    if full_name not in self.parameters_to_ignore:\n                        # There is at least a param whose all reduce will not be delayed.\n                        # In this case, we should not set self._delay_all_reduce_all_params\n                        # to True.\n                        return\n        self._delay_all_reduce_all_params = True\n\n    def _setup_in_backward_optimizers(self):\n        # Check if user has used apply_optim_in_backward to overlap optimizer\n        # step + DDP backward. Current constraints:\n        # 1. Only allreduce is supported at the moment, no custom communication.\n        # 2. For DDP-managed parameters that have their optimizer run in\n        # backward, their gradients are set to ``None``. If your use case\n        # requires DDP parameters grad not to be set to ``None`` after their\n        # in-backward optimizer runs, please ping\n        # https://github.com/pytorch/pytorch/issues/90052.\n        # NOTE: we use self._module_parameters instead of .parameters() since\n        # the former excludes ignored (non-DDP managed) parameters.\n        if any(hasattr(p, \"_in_backward_optimizers\") for p in self._module_parameters):\n            torch._C._log_api_usage_once(\"ddp.optimizer_in_backward\")\n            # Remove hooks that apply_optim_in_backward had registered because\n            # DDP customizes how optimizer is overlapped with backward due to\n            # the allreduce.\n            param_to_handle_map = (\n                dist.optim.apply_optimizer_in_backward.param_to_optim_hook_handle_map\n            )\n            for p in self._module_parameters:\n                for handle in param_to_handle_map.get(p, []):\n                    handle.remove()\n\n            # Need a weakref to DDP instance to run all_reduce (from reducer)\n            # and get managed DDP parameters.\n            ddp_weakref = weakref.ref(self)\n            # Note: importing in function, otherwise this will cause a circular\n            # import.\n            from torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks import (\n                _apply_optim_in_backward_hook,\n            )\n\n            self.register_comm_hook(\n                ddp_weakref,\n                _apply_optim_in_backward_hook(\n                    gradient_is_bucket_view=self.gradient_as_bucket_view\n                ),\n            )\n\n            self.reducer._set_optimizer_in_backward()  # type: ignore[attr-defined]\n\n    def _fire_reducer_autograd_hook(self, idx, *unused):\n        \"\"\"\n        Fire the reducer's autograd hook to allreduce params in a Reducer bucket.\n\n        Note that this is only used during mixed precision training as the\n        Reducer's hooks installed during construction time would not be called\n        as we're working in the low precision parameter setting.\n        \"\"\"\n        self.reducer._autograd_hook(idx)  # type: ignore[attr-defined]\n\n    def _root_copy_hook(self, *args: Any, **kwargs: Any) -> None:\n        \"\"\"\n        For DDP mixed precision, put low precision copies on separate stream and create events to wait for them.\n\n        When training with DDP mixed precision, this root pre-forward hook kicks\n        off low precision copies on a separate stream and creates respective\n        events to wait for them.\n        \"\"\"\n        # Clear out previous iteration submodule to event. This is because we\n        # may have populated some events for modules that didn't end up being\n        # used.\n        self._submodule_to_event = defaultdict(deque)  # type: ignore[var-annotated]\n        with torch.cuda.stream(self._mp_stream):\n            for submodule in self.module.modules():\n                for param in submodule.parameters(recurse=False):\n                    # Do not cast DDP ignored parameters.\n                    if hasattr(param, \"_ddp_ignored\") and param._ddp_ignored:\n                        continue\n                    _alloc_storage(param._mp_param, param.size())\n                    # copy() implicitly casts to low precision\n                    with torch.no_grad():\n                        param._mp_param.copy_(param.data)\n                        # TODO: when zero_grad(set_to_none=False) or in grad\n                        # accumulation case, accumulated grads can be in fp32\n                        # which can cause errors when running DDP backwards due\n                        # to mismatched incoming and accumulated gradient types.\n                        # So we manually cast the accumulated grad down for now,\n                        # in the future we may shift to FSDP style gradient\n                        # accumulation management where the accumulated gradient\n                        # is saved and .grad field is set to None, bypassing\n                        # this issue.\n                        if param.grad is not None:\n                            param.grad.data = param.grad.to(\n                                self.mixed_precision.param_dtype  # type: ignore[union-attr]\n                            )\n                    param.data = param._mp_param\n                copy_event = torch.cuda.Event()\n                copy_event.record()\n                self._submodule_to_event[submodule].append(copy_event)\n\n    def _module_wait_for_copy_hook(\n        self,\n        module,\n        *args: Any,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Before carrying out computation, wait on the appropriate event to ensure low precision copies have finished.\"\"\"\n        try:\n            event = self._submodule_to_event[module].popleft()\n        except IndexError:\n            # copy event has already been waited on\n            return\n\n        event.wait(stream=torch.cuda.current_stream())\n        for p in module.parameters(recurse=False):\n            # Don't register hooks if param does not require grad\n            if not p.requires_grad or (hasattr(p, \"_ddp_ignored\") and p._ddp_ignored):\n                continue\n            # We need to register autograd hook here instead of DDP's ctor\n            # since we're working with the low precision param. Register them\n            # via obtaining the gradient accumulator.\n            tmp = p.expand_as(p)\n            grad_acc = tmp.grad_fn.next_functions[0][0]\n\n            hook = grad_acc.register_hook(\n                functools.partial(self._fire_reducer_autograd_hook, p._idx)\n            )\n            p._ddp_mp_hook_state = (grad_acc, hook)\n\n    def _log_and_throw(self, err_type, err_msg):\n        if self.logger is not None:\n            self.logger.set_error_and_log(f\"{str(err_type)}: {err_msg}\")\n        raise err_type(err_msg)\n\n    def _ddp_init_helper(\n        self,\n        parameters,\n        expect_sparse_gradient,\n        param_to_name_mapping,\n        static_graph,\n    ):\n        \"\"\"\n        DDP init helper function to manage parameters, grad hooks, logging, and SyncBatchNorm.\n\n        Initialization helper function that does the following:\n        (1) bucketing the parameters for reductions\n        (2) resetting the bucketing states\n        (3) registering the grad hooks\n        (4) Logging construction-time DDP logging data\n        (5) passing a handle of DDP to SyncBatchNorm Layer\n        \"\"\"\n        # Notice, the parameters order is not in the order in which they are used,\n        # especially in models with control flow.\n        #\n        # Alongside parameters are not presented in the real execution order,\n        # if a certain model happens to also\n        #   1) have other collectives comm ops in its backward graph.\n        #   2) have unused parameter in subset ranks of the whole world.\n        # bucketing could insert ALL-REDUCE comm op too early on the rank with unused parameter,\n        # matching up with other collectives comm ops on other ranks unexpectedly.\n        #\n        # In order to handle this corner case, when the parameters are not in the real execution order,\n        # we don't do bucketing, thus only one ALL-REDUCE is inserted after all the gradients\n        # of the whole graph are computed.\n        #\n        # Notice, here we only disable bucketing for the first iteration.\n        # After the first iteration, it's OK to rebuild buckets,\n        # because \"bucket rebuild\" bucketizes parameters based on its real execution order in backward graph.\n\n        # Can remove this branching once #73732 is landed.\n        if static_graph is True or self.find_unused_parameters is False:\n            bucket_size_limits = [sys.maxsize]\n        else:\n            if self.bucket_bytes_cap_default:\n                bucket_size_limits = [\n                    dist._DEFAULT_FIRST_BUCKET_BYTES,\n                    self.bucket_bytes_cap,\n                ]\n            else:\n                bucket_size_limits = [self.bucket_bytes_cap]\n        (\n            bucket_indices,\n            per_bucket_size_limits,\n        ) = dist._compute_bucket_assignment_by_size(\n            parameters,\n            bucket_size_limits,\n            expect_sparse_gradient,\n        )\n\n        # Remember index for parameters if we are in mixed precision, as we\n        # need to pass in index to Reducer's autograd hook via python.\n        if self.mixed_precision is not None:\n            for i, p in enumerate(parameters):\n                p._idx = i\n\n        # Note: reverse list of buckets because we want to approximate the\n        # order in which their gradients are produced, and assume they\n        # are used in the forward pass in the order they are defined.\n        self.reducer = dist.Reducer(\n            parameters,\n            list(reversed(bucket_indices)),\n            list(reversed(per_bucket_size_limits)),\n            self.process_group,\n            expect_sparse_gradient,\n            # The bucket size limit is specified in the constructor.\n            # Additionally, we allow for a single small bucket for parameters\n            # that are defined first, such that their gradients don't spill into\n            # a much larger bucket, adding unnecessary latency after gradient\n            # computation finishes. Experiments showed 1MB is a reasonable value.\n            self.bucket_bytes_cap,\n            self.find_unused_parameters,\n            self.gradient_as_bucket_view,\n            param_to_name_mapping,\n            # User can set dist._DEFAULT_FIRST_BUCKET_BYTES to tune DDP first\n            # bucket.\n            (\n                dist._DEFAULT_FIRST_BUCKET_BYTES\n                if self.bucket_bytes_cap_default\n                else self.bucket_bytes_cap\n            ),\n        )\n\n        self.logger = dist.Logger(self.reducer)\n        # Set as a weak reference to avoid reference cycle between\n        # logger and reducer.\n        self.reducer.set_logger(self.logger)\n\n        has_sync_bn = False\n        for submodule in self.module.modules():\n            if isinstance(submodule, torch.nn.SyncBatchNorm):\n                has_sync_bn = True\n                break\n\n        # Set logging data that can be got during construction time.\n        self.logger.set_construction_data_and_log(\n            self.module.__class__.__name__,\n            [] if self.device_ids is None else self.device_ids,\n            -1 if self.output_device is None else self.output_device,\n            self.broadcast_buffers,\n            has_sync_bn,\n            static_graph,\n        )\n\n        # passing a handle to torch.nn.SyncBatchNorm layer\n        self._passing_sync_batchnorm_handle(self.module)\n\n    def __getstate__(self):\n        self._check_default_group()\n        attrs = copy.copy(self.__dict__)\n        del attrs[\"process_group\"]\n        del attrs[\"reducer\"]\n        del attrs[\"logger\"]\n        return attrs\n\n    def __setstate__(self, state):\n        # If serializable, then the process group should be the default one\n        self.process_group = _get_default_group()\n        super().__setstate__(state)\n        self.__dict__.setdefault(\"require_forward_param_sync\", True)\n        self.__dict__.setdefault(\"require_backward_grad_sync\", True)\n        parameters, expect_sparse_gradient = self._build_params_for_reducer()\n        # In debug mode, build a mapping of parameter index -> parameter.\n        param_to_name_mapping = self._build_debug_param_to_name_mapping(parameters)\n        # Builds reducer.\n        self._ddp_init_helper(\n            parameters,\n            expect_sparse_gradient,\n            param_to_name_mapping,\n            self.static_graph,\n        )\n        if self.static_graph:\n            self.reducer._set_static_graph()\n            assert self.logger is not None\n            self.logger._set_static_graph()\n\n    def _build_params_for_reducer(self):\n        # Build tuple of (module, parameter) for all parameters that require grads.\n        modules_and_parameters = [\n            (module, parameter)\n            for module_name, module in self.module.named_modules()\n            for parameter in [\n                param\n                # Note that we access module.named_parameters instead of\n                # parameters(module). parameters(module) is only needed in the\n                # single-process multi device case, where it accesses replicated\n                # parameters through _former_parameters.\n                for param_name, param in module.named_parameters(recurse=False)\n                if param.requires_grad\n                and f\"{module_name}.{param_name}\" not in self.parameters_to_ignore\n            ]\n        ]\n\n        # Deduplicate any parameters that might be shared across child modules.\n        memo = set()\n        modules_and_parameters = [\n            # \"p not in memo\" is the deduplication check.\n            # \"not memo.add(p)\" is always True, and it's only there to cause \"add(p)\" if needed.\n            (m, p)\n            for m, p in modules_and_parameters\n            if p not in memo and not memo.add(p)  # type: ignore[func-returns-value]\n        ]\n\n        # Build list of parameters.\n        parameters = [parameter for _, parameter in modules_and_parameters]\n\n        # Checks if a module will produce a sparse gradient.\n        def produces_sparse_gradient(module):\n            if isinstance(module, (torch.nn.Embedding, torch.nn.EmbeddingBag)):\n                return module.sparse\n            return False\n\n        # Build list of booleans indicating whether or not to expect sparse\n        # gradients for the corresponding parameters.\n        expect_sparse_gradient = [\n            produces_sparse_gradient(module) for module, _ in modules_and_parameters\n        ]\n\n        self._assign_modules_buffers()\n\n        return parameters, expect_sparse_gradient\n\n    def _assign_modules_buffers(self):\n        \"\"\"\n        Assign self.module.named_buffers to self.modules_buffers.\n\n        Assigns module buffers to self.modules_buffers which are then used to\n        broadcast across ranks when broadcast_buffers=True. Note that this\n        must be called every time buffers need to be synced because buffers can\n        be reassigned by user module,\n        see https://github.com/pytorch/pytorch/issues/63916.\n        \"\"\"\n        # Collect buffers for modules, filtering out buffers that should be ignored.\n        named_module_buffers = [\n            (buffer, buffer_name)\n            for buffer_name, buffer in self.module.named_buffers()\n            if buffer_name not in self.parameters_to_ignore\n        ]\n        self.modules_buffers = [\n            buffer for (buffer, buffer_name) in named_module_buffers\n        ]\n        # Dict[str, tensor] representing module buffers not ignored by DDP.\n        self.named_module_buffers = {\n            buffer_name: buffer for (buffer, buffer_name) in named_module_buffers\n        }\n\n    def _build_debug_param_to_name_mapping(self, parameters):\n        param_to_param_index = {parameters[i]: i for i in range(len(parameters))}\n        param_set = set(parameters)\n        param_index_to_param_fqn = {}\n        for module_name, module in self.module.named_modules():\n            for param_name, param in module.named_parameters(recurse=False):\n                fqn = f\"{module_name}.{param_name}\"\n                # Bypass ignored parameters since those are not reduced by DDP\n                # to begin with.\n                if fqn not in self.parameters_to_ignore and param.requires_grad:\n                    if param not in param_set:\n                        self._log_and_throw(\n                            ValueError,\n                            f\"Param with name {fqn} found in module parameters, but not DDP parameters.\"\n                            \" This indicates a bug in DDP, please report an issue to PyTorch.\",\n                        )\n                    param_index = param_to_param_index[param]\n                    param_index_to_param_fqn[param_index] = fqn\n\n        # Ensure we covered all parameters\n        if len(param_set) != len(param_index_to_param_fqn):\n            self._log_and_throw(\n                ValueError,\n                (\n                    \"Expected param to name mapping to cover all parameters, but\"\n                    f\" got conflicting lengths: {len(param_set)} vs \"\n                    f\"{len(param_index_to_param_fqn)}. This indicates a bug in DDP\"\n                    \", please report an issue to PyTorch.\"\n                ),\n            )\n\n        return param_index_to_param_fqn\n\n    def _get_parameters(self, m, recurse=True):\n        \"\"\"Return a generator of module parameters.\"\"\"\n\n        def model_parameters(m):\n            ps = (\n                m._former_parameters.values()\n                if hasattr(m, \"_former_parameters\")\n                else m.parameters(recurse=False)\n            )\n            yield from ps\n\n        for mod in m.modules() if recurse else [m]:\n            yield from model_parameters(mod)\n\n    def _check_default_group(self):\n        pickle_not_supported = False\n        try:\n            if self.process_group != _get_default_group():\n                pickle_not_supported = True\n        except RuntimeError:\n            pickle_not_supported = True\n\n        if pickle_not_supported:\n            self._log_and_throw(\n                RuntimeError,\n                \"DDP Pickling/Unpickling are only supported \"\n                \"when using DDP with the default process \"\n                \"group. That is, when you have called \"\n                \"init_process_group and have not passed \"\n                \"process_group argument to DDP constructor\",\n            )\n\n    @contextmanager\n    def no_sync(self):\n        r\"\"\"\n        Context manager to disable gradient synchronizations across DDP processes.\n\n        Within this context, gradients will be accumulated on module\n        variables, which will later be synchronized in the first\n        forward-backward pass exiting the context.\n\n        Example::\n\n            >>> # xdoctest: +SKIP(\"undefined variables\")\n            >>> ddp = torch.nn.parallel.DistributedDataParallel(model, pg)\n            >>> with ddp.no_sync():\n            >>>     for input in inputs:\n            >>>         ddp(input).backward()  # no synchronization, accumulate grads\n            >>> ddp(another_input).backward()  # synchronize grads\n\n        .. warning::\n            The forward pass should be included inside the context manager, or\n            else gradients will still be synchronized.\n        \"\"\"\n        old_require_backward_grad_sync = self.require_backward_grad_sync\n        self.require_backward_grad_sync = False\n        try:\n            yield\n        finally:\n            self.require_backward_grad_sync = old_require_backward_grad_sync\n\n    @classmethod\n    def _get_active_ddp_module(cls):\n        \"\"\"`TorchDynamo` requires DDP's status and module for cooperative optimization.\"\"\"\n        return cls._active_ddp_module\n\n    # note, this ctxmgr function is marked 'skip' in torchdynamo, so dynamo only kicks in\n    # for the 'module_to_run' underneath\n    # see torch._dynamo/eval_frame.py TorchPatcher.patch for more details\n    @contextmanager\n    @torch._disable_dynamo(recursive=False)\n    def _inside_ddp_forward(self):\n        DistributedDataParallel._active_ddp_module = self\n        try:\n            yield\n        finally:\n            DistributedDataParallel._active_ddp_module = None\n\n    def _run_ddp_forward(self, *inputs, **kwargs):\n        if self._use_python_reducer:\n            return self.module(*inputs, **kwargs)  # type: ignore[index]\n        else:\n            with self._inside_ddp_forward():\n                return self.module(*inputs, **kwargs)  # type: ignore[index]\n\n    def _clear_grad_buffer(self):\n        # Making param.grad points to the grad buffers before backward is based on the\n        # assumption that the grad accumulation is done in place in autograd engine,\n        # for some edge cases, if the grad accumulation in autograd engine is not in\n        # place, then the param.grad and grad buffers are detached.\n        if self._delay_grad_buffer is not None:\n            # We batch zero_grad for all params by resetting the whole grad\n            # buffer when the grad of all params is set to None.\n            all_param_grad_none = all(\n                param.grad is None for param in self._delay_all_reduce_params\n            )\n\n            for index, param in enumerate(self._delay_all_reduce_params):\n                if param.grad is None:\n                    param.grad = self._delay_grad_views[index]\n                    if not all_param_grad_none:\n                        param.grad.zero_()\n\n            if all_param_grad_none:\n                self._delay_grad_buffer.zero_()\n\n    def _lazy_init(self):\n        # Initialization for DDP that occurs after construction, but lazily\n        # before the first forward pass.\n        self._setup_in_backward_optimizers()\n        self._lazy_init_ran = True\n\n    def _should_disable_cpp_reducer(self) -> bool:\n        return self._use_python_reducer and (\n            torch._utils.is_compiling() or self._force_to_disable_cpp_reducer\n        )\n\n    def _pre_forward(self, *inputs, **kwargs):\n        if self._should_disable_cpp_reducer():\n            return inputs, kwargs\n\n        # Disable the python reducer if compiled_autograd is not enabled.\n        if self._accum_grad_hooks:\n            for index, h in enumerate(self._accum_grad_hooks):\n                h.remove()\n            self._accum_grad_hooks.clear()\n\n        if not self._lazy_init_ran and not torch._utils.is_compiling():\n            self._lazy_init()\n\n        if self._delay_all_reduce_all_params:\n            return inputs, kwargs\n\n        if torch.is_grad_enabled() and self.require_backward_grad_sync:\n            assert self.logger is not None\n            self.logger.set_runtime_stats_and_log()\n            self.reducer.prepare_for_forward()\n\n        # Notify the join context that this process has not joined, if\n        # needed\n        work = Join.notify_join_context(self)\n        if work:\n            self.reducer._set_forward_pass_work_handle(\n                work, self._divide_by_initial_world_size  # type: ignore[arg-type]\n            )\n\n        # Calling _rebuild_buckets before forward computation,\n        # It may allocate new buckets before deallocating old buckets\n        # inside _rebuild_buckets. To save peak memory usage,\n        # call _rebuild_buckets before the peak memory usage increases\n        # during forward computation.\n        # This should be called only once during whole training period.\n        if torch.is_grad_enabled() and self.reducer._rebuild_buckets():\n            logger.info(\"Reducer buckets have been rebuilt in this iteration.\")\n            self._has_rebuilt_buckets = True\n\n        # sync params according to location (before/after forward) user\n        # specified as part of hook, if hook was specified.\n        if self._check_sync_bufs_pre_fwd():\n            self._sync_buffers()\n\n        if self._join_config.enable:\n            # Notify joined ranks whether they should sync in backwards pass or not.\n            self._check_global_requires_backward_grad_sync(is_joined_rank=False)\n\n        if self.device_ids:\n            moved_inputs, moved_kwargs = _to_kwargs(\n                inputs,\n                kwargs,\n                torch.device(self.device_type, self.device_ids[0]),\n                self.use_side_stream_for_tensor_copies,\n            )\n            args, kwargs = moved_inputs[0], moved_kwargs[0]\n            # Cast inputs to reduced precision if needed.\n            if self.mixed_precision is not None:\n                args, kwargs = _cast_forward_inputs(\n                    self.mixed_precision.param_dtype,\n                    *args,\n                    **kwargs,\n                )\n            return args, kwargs\n        else:\n            # Cast inputs to reduced precision if needed.\n            # TODO (rohan-varma) test this codepath.\n            if self.mixed_precision is not None:\n                inputs, kwargs = _cast_forward_inputs(\n                    self.mixed_precision.param_dtype,\n                    *inputs,\n                    **kwargs,\n                )\n            return inputs, kwargs\n\n    def _post_forward(self, output):\n        if self._should_disable_cpp_reducer():\n            return output\n\n        if self._delay_all_reduce_all_params:\n            self._clear_grad_buffer()\n            return output\n\n        # sync params according to location (before/after forward) user\n        # specified as part of hook, if hook was specified.\n        if self._check_sync_bufs_post_fwd():\n            self._sync_buffers()\n\n        if torch.is_grad_enabled() and self.require_backward_grad_sync:\n            self.require_forward_param_sync = True\n            # We'll return the output object verbatim since it is a freeform\n            # object. We need to find any tensors in this object, though,\n            # because we need to figure out which parameters were used during\n            # this forward pass, to ensure we short circuit reduction for any\n            # unused parameters. Only if `find_unused_parameters` is set.\n            if self.find_unused_parameters and not self.static_graph:\n                # Do not need to populate this for static graph.\n                self.reducer.prepare_for_backward(list(_find_tensors(output)))\n            else:\n                self.reducer.prepare_for_backward([])\n        else:\n            self.require_forward_param_sync = False\n\n        # TODO: DDPSink is currently enabled for unused parameter detection and\n        # static graph training for first iteration.\n        if (self.find_unused_parameters and not self.static_graph) or (\n            self.static_graph and not self._static_graph_delay_allreduce_enqueued\n        ):\n            (\n                output_tensor_list,\n                treespec,\n                output_is_rref,\n            ) = _tree_flatten_with_rref(output)\n            output_placeholders: List[Optional[torch.Tensor]] = [\n                None for _ in range(len(output_tensor_list))\n            ]\n            # Do not touch tensors that have no grad_fn, which can cause issues\n            # such as https://github.com/pytorch/pytorch/issues/60733\n            for i, output in enumerate(output_tensor_list):\n                if torch.is_tensor(output) and output.grad_fn is None:\n                    output_placeholders[i] = output\n\n            # When find_unused_parameters=True, makes tensors which require grad\n            # run through the DDPSink backward pass. When not all outputs are\n            # used in loss, this makes those corresponding tensors receive\n            # undefined gradient which the reducer then handles to ensure\n            # param.grad field is not touched and we don't error out.\n            passthrough_tensor_list = _DDPSink.apply(\n                weakref.ref(self),\n                *output_tensor_list,\n            )\n            for i in range(len(output_placeholders)):\n                if output_placeholders[i] is None:\n                    output_placeholders[i] = passthrough_tensor_list[i]\n\n            # Reconstruct output data structure.\n            output = _tree_unflatten_with_rref(\n                output_placeholders, treespec, output_is_rref\n            )\n\n        # At the end of the forward pass, reset the grad buffer and grad views\n        self._clear_grad_buffer()\n        return output\n\n    def forward(self, *inputs, **kwargs):\n        with torch.autograd.profiler.record_function(\"DistributedDataParallel.forward\"):\n            inputs, kwargs = self._pre_forward(*inputs, **kwargs)\n            output = (\n                self.module.forward(*inputs, **kwargs)\n                if self._delay_all_reduce_all_params\n                else self._run_ddp_forward(*inputs, **kwargs)\n            )\n            return self._post_forward(output)\n\n    def scatter(self, inputs, kwargs, device_ids):\n        return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)\n\n    def to_kwargs(self, inputs, kwargs, device_id):\n        # Kept for BC\n        return _to_kwargs(\n            inputs,\n            kwargs,\n            torch.device(self.device_type, device_id),\n            self.use_side_stream_for_tensor_copies,\n        )\n\n    def gather(self, outputs, output_device):\n        return gather(outputs, output_device, dim=self.dim)\n\n    def train(self, mode=True):\n        super().train(mode)\n        return self\n\n    # When running in join mode, schedules an allreduce to notify joined ranks\n    # of whether backwards pass synchronization will run this iteration or not.\n    def _check_global_requires_backward_grad_sync(self, is_joined_rank):\n        if not is_joined_rank and self.require_backward_grad_sync:\n            requires_sync_tensor = torch.ones(1, device=self.device)\n        else:\n            requires_sync_tensor = torch.zeros(1, device=self.device)\n\n        work = dist.all_reduce(\n            requires_sync_tensor, group=self.process_group, async_op=True\n        )\n\n        # (kwen2501) This if condition is a plain translation of previous\n        # behavior, i.e. in the `is_joined_rank=False` case, `work.wait()`\n        # is not called and it doesn't care about the result. I am guessing\n        # that it just wants to fire a matching all-reduce and does not want\n        # the main stream to wait.\n        if is_joined_rank:\n            work.wait()\n            should_sync_backwards = requires_sync_tensor.item() != 0\n            return should_sync_backwards\n        else:\n            return None  # Return value is not/should not be used.\n\n    # When running in join mode, checks and performs sync of module buffers if\n    # the models have buffers that should be synchronized in the forward pass.\n    def _check_and_sync_module_buffers(self):\n        if self._check_sync_bufs_pre_fwd():\n            authoritative_rank = self._find_common_rank(self._distributed_rank, False)\n            self._sync_module_buffers(authoritative_rank)\n\n    # When running in join model, agrees upon a common rank and broadcast model\n    # parameters to all other ranks.\n    def _sync_final_model(self, is_last_joiner):\n        # Agree upon the process that will be the authoritative model copy.\n        # The current rank is a candidate for being the authoritative copy if\n        # is_last_joiner=True. We break ties via picking the larger rank.\n        self._authoritative_rank = self._find_common_rank(\n            self._distributed_rank, is_last_joiner\n        )\n        _sync_module_states(\n            module=self.module,\n            process_group=self.process_group,\n            broadcast_bucket_size=self.broadcast_bucket_size,\n            src=self._authoritative_rank,\n            params_and_buffers_to_ignore=self.parameters_to_ignore,\n            broadcast_buffers=self.broadcast_buffers,\n        )\n\n    # Schedule comm ops to match those scheduled in the reducer's backward\n    # pass.\n    def _match_all_reduce_for_bwd_pass(self):\n        comm_work = []\n        # Schedule comm in the same order as Reducer schedules them, i.e.\n        # the order of the buckets. Retrieving the bucket order from the reducer\n        # ensures that we keep the same order in join mode, such as when bucket\n        # order is rebuilt dynamically.\n\n        # Returns grad_buckets in order, but real tensors are substituted with\n        # zero tensors of the same shape.\n        grad_buckets = self.reducer._get_zeros_like_grad_buckets()\n        for grad_bucket in grad_buckets:\n            # Joined processes contribute zero gradient. In the case that\n            # divide_by_initial_world_size=True, we divide grads by the static\n            # world size, if not, the dividing factor is reduced by the number\n            # of joined processes.\n            work = self.reducer._run_comm_hook(grad_bucket)\n            comm_work.append(work)\n        for work in comm_work:\n            work.wait()\n\n    # Allreduces the used parameter mapping across ranks.\n    def _match_unused_params_allreduce(self):\n        locally_used_param_map = self.reducer._get_local_used_map()\n        self.process_group.allreduce(locally_used_param_map)\n\n    def join(\n        self,\n        divide_by_initial_world_size: bool = True,\n        enable: bool = True,\n        throw_on_early_termination: bool = False,\n    ):\n        r\"\"\"\n        Context manager for training with uneven inputs across processes in DDP.\n\n        This context manager will keep track of already-joined DDP processes,\n        and \"shadow\" the forward and backward passes by inserting collective\n        communication operations to match with the ones created by non-joined\n        DDP processes. This will ensure each collective call has a corresponding\n        call by already-joined DDP processes, preventing hangs or errors that\n        would otherwise happen when training with uneven inputs across\n        processes. Alternatively, if the flag ``throw_on_early_termination`` is\n        specified to be ``True``, all trainers will throw an error once one rank\n        runs out of inputs, allowing these errors to be caught and handled\n        according to application logic.\n\n        Once all DDP processes have joined, the context manager will broadcast\n        the model corresponding to the last joined process to all processes to\n        ensure the model is the same across all processes\n        (which is guaranteed by DDP).\n\n        To use this to enable training with uneven inputs across processes,\n        simply wrap this context manager around your training loop. No further\n        modifications to the model or data loading is required.\n\n        .. warning::\n            If the model or training loop this context manager is wrapped around\n            has additional distributed collective operations, such as\n            ``SyncBatchNorm`` in the model's forward pass, then the flag\n            ``throw_on_early_termination`` must be enabled. This is because this\n            context manager is not aware of non-DDP collective communication.\n            This flag will cause all ranks to throw when any one rank\n            exhausts inputs, allowing these errors to be caught and recovered\n            from across all ranks.\n\n        Args:\n            divide_by_initial_world_size (bool): If ``True``, will divide\n                gradients by the initial ``world_size`` DDP training was launched\n                with. If ``False``, will compute the effective world size\n                (number of ranks that have not depleted their inputs yet) and\n                divide gradients by that during allreduce. Set\n                ``divide_by_initial_world_size=True`` to ensure every input\n                sample including the uneven inputs have equal weight in terms of\n                how much they contribute to the global gradient. This is\n                achieved by always dividing the gradient by the initial\n                ``world_size`` even when we encounter uneven inputs. If you set\n                this to ``False``, we divide the gradient by the remaining\n                number of nodes. This ensures parity with training on a smaller\n                ``world_size`` although it also means the uneven inputs would\n                contribute more towards the global gradient. Typically, you\n                would want to set this to ``True`` for cases where the last few\n                inputs of your training job are uneven. In extreme cases, where\n                there is a large discrepancy in the number of inputs, setting\n                this to ``False`` might provide better results.\n            enable (bool): Whether to enable uneven input detection or not. Pass\n                in ``enable=False`` to disable in cases where you know that\n                inputs are even across participating processes. Default is\n                ``True``.\n            throw_on_early_termination (bool): Whether to throw an error\n                or continue training when at least one rank has exhausted\n                inputs. If ``True``, will throw upon the first rank reaching end\n                of data. If ``False``, will continue training with a smaller\n                effective world size until all ranks are joined. Note that if\n                this flag is specified, then the flag\n                ``divide_by_initial_world_size`` would be ignored. Default\n                is ``False``.\n\n\n        Example::\n\n            >>> # xdoctest: +SKIP(\"Distributed\")\n            >>> import torch\n            >>> import torch.distributed as dist\n            >>> import os\n            >>> import torch.multiprocessing as mp\n            >>> import torch.nn as nn\n            >>> # On each spawned worker\n            >>> def worker(rank):\n            >>>     dist.init_process_group(\"nccl\", rank=rank, world_size=2)\n            >>>     torch.cuda.set_device(rank)\n            >>>     model = nn.Linear(1, 1, bias=False).to(rank)\n            >>>     model = torch.nn.parallel.DistributedDataParallel(\n            >>>         model, device_ids=[rank], output_device=rank\n            >>>     )\n            >>>     # Rank 1 gets one more input than rank 0.\n            >>>     inputs = [torch.tensor([1]).float() for _ in range(10 + rank)]\n            >>>     with model.join():\n            >>>         for _ in range(5):\n            >>>             for inp in inputs:\n            >>>                 loss = model(inp).sum()\n            >>>                 loss.backward()\n            >>>     # Without the join() API, the below synchronization will hang\n            >>>     # blocking for rank 1's allreduce to complete.\n            >>>     torch.cuda.synchronize(device=rank)\n        \"\"\"\n        return Join(\n            [self],\n            enable,\n            throw_on_early_termination,\n            divide_by_initial_world_size=divide_by_initial_world_size,\n        )\n\n    def join_hook(\n        self,\n        **kwargs,\n    ):\n        r\"\"\"\n        DDP join hook enables training on uneven inputs by mirroring communications in forward and backward passes.\n\n        Arguments:\n            kwargs (dict): a :class:`dict` containing any keyword arguments\n                to modify the behavior of the join hook at run time; all\n                :class:`Joinable` instances sharing the same join context\n                manager are forwarded the same value for ``kwargs``.\n\n        The hook supports the following keyword arguments:\n            divide_by_initial_world_size (bool, optional):\n                If ``True``, then gradients are divided by the initial world\n                size that DDP was launched with.\n                If ``False``, then gradients are divided by the effective world\n                size (i.e. the number of non-joined processes), meaning that\n                the uneven inputs contribute more toward the global gradient.\n                Typically, this should be set to ``True`` if the degree of\n                unevenness is small but can be set to ``False`` in extreme\n                cases for possibly better results.\n                Default is ``True``.\n        \"\"\"\n        divide_by_initial_world_size = kwargs.get(\"divide_by_initial_world_size\", True)\n        return _DDPJoinHook(\n            self, divide_by_initial_world_size=divide_by_initial_world_size\n        )\n\n    @property\n    def join_device(self):\n        return self.device\n\n    @property\n    def join_process_group(self):\n        return self.process_group\n\n    def _register_buffer_comm_hook(\n        self,\n        state,\n        hook: Callable,\n        comm_hook_location=_BufferCommHookLocation.POST_FORWARD,\n    ):\n        r\"\"\"\n        Allow custom registration of hooks that define how buffer are synchronized across ranks.\n\n        The hook takes in an optional state and is passed in a Dict[str, Tensor]\n        corresponding to buffer names and the buffers, and can run arbitrary reductions\n        on buffers as opposed to DDP's default broadcast from rank 0. This is useful for\n        example if a counter needs to be summed or averaged across ranks every iteration.\n\n        Args:\n            state (Any): Optional state that is passed to the hook.\n            hook (Callable): Callable with the following signature:\n                         ``hook(state: object, bucket: dist.GradBucket) -> torch.futures.Future[torch.Tensor]``\n            comm_hook_location (_BufferCommHookLocation): Enum value indicating\n                            where to run the hook.\n                            _BufferCommHookLocation.PRE_FORWARD means that the\n                            hook will run _before_ the forward pass, and\n                            _BufferCommHookLocation.POST_FORWARD means that the\n                            hook will run _after_ the forward pass.\n\n            NOTE: To maximize performance, users can return a\n                List[torch.futures.Future] from their hook, and DDP will\n                install and await these hooks appropriately at the end of\n                the backward pass. This will ensure all buffers are\n                synchronized by the end of the backward pass. If this\n                setting is used, it is recommended to pass\n                comm_hook_location=_BufferCommHookLocation.POST_FORWARD,\n                which will trigger the hook after the forward pass.\n                If _BufferCommHookLocation.PRE_FORWARD is used, users must\n                ensure appropriate synchronization when manipulating GPU\n                buffers in the forward pass.\n        \"\"\"\n        assert callable(hook)\n        self.buffer_hook = _BufferCommHook(\n            buffer_comm_hook=hook,\n            buffer_comm_hook_state=state,\n            buffer_comm_hook_location=comm_hook_location,\n        )\n\n    def register_comm_hook(self, state: object, hook: Callable):\n        r\"\"\"\n        Register communication hook for user-defined DDP aggregation of gradients across multiple workers.\n\n        This hook would be very useful for researchers to try out new ideas. For\n        example, this hook can be used to implement several algorithms like GossipGrad\n        and gradient compression which involve different communication strategies for\n        parameter syncs while running Distributed DataParallel training.\n\n        Args:\n            state (object): Passed to the hook to maintain any state information during the training process.\n                            Examples include error feedback in gradient compression,\n                            peers to communicate with next in GossipGrad, etc.\n\n                            It is locally stored by each worker\n                            and shared by all the gradient tensors on the worker.\n            hook (Callable): Callable with the following signature:\n                             ``hook(state: object, bucket: dist.GradBucket) -> torch.futures.Future[torch.Tensor]``:\n\n                             This function is called once the bucket is ready. The\n                             hook can perform whatever processing is needed and return\n                             a Future indicating completion of any async work (ex: allreduce).\n                             If the hook doesn't perform any communication, it still\n                             must return a completed Future. The Future should hold the\n                             new value of grad bucket's tensors. Once a bucket is ready,\n                             c10d reducer would call this hook and use the tensors returned\n                             by the Future and copy grads to individual parameters.\n                             Note that the future's return type must be a single tensor.\n\n                             We also provide an API called ``get_future`` to retrieve a\n                             Future associated with the completion of ``c10d.ProcessGroup.Work``.\n                             ``get_future`` is currently supported for NCCL and also supported for most\n                             operations on GLOO and MPI, except for peer to peer operations (send/recv).\n\n        .. warning ::\n            Grad bucket's tensors will not be predivided by world_size. User is responsible\n            to divide by the world_size in case of operations like allreduce.\n\n        .. warning ::\n            DDP communication hook can only be registered once and should be registered\n            before calling backward.\n\n        .. warning ::\n            The Future object that hook returns should contain a single tensor\n            that has the same shape with the tensors inside grad bucket.\n\n        .. warning ::\n            ``get_future`` API supports NCCL, and partially GLOO and MPI backends (no support\n            for peer-to-peer operations like send/recv) and will return a ``torch.futures.Future``.\n\n        Example::\n            Below is an example of a noop hook that returns the same tensor.\n\n            >>> # xdoctest: +SKIP('undefined name')\n            >>> def noop(state: object, bucket: dist.GradBucket) -> torch.futures.Future[torch.Tensor]:\n            >>>     fut = torch.futures.Future()\n            >>>     fut.set_result(bucket.buffer())\n            >>>     return fut\n            >>> ddp.register_comm_hook(state=None, hook=noop)\n\n        Example::\n            Below is an example of a Parallel SGD algorithm where gradients are encoded before\n            allreduce, and then decoded after allreduce.\n\n            >>> # xdoctest: +SKIP('undefined name')\n            >>> def encode_and_decode(state: object, bucket: dist.GradBucket) -> torch.futures.Future[torch.Tensor]:\n            >>>     encoded_tensor = encode(bucket.buffer())  # encode gradients\n            >>>     fut = torch.distributed.all_reduce(encoded_tensor).get_future()\n            >>>     # Define the then callback to decode.\n            >>>     def decode(fut):\n            >>>         decoded_tensor = decode(fut.value()[0])  # decode gradients\n            >>>         return decoded_tensor\n            >>>     return fut.then(decode)\n            >>> ddp.register_comm_hook(state=None, hook=encode_and_decode)\n        \"\"\"\n        self._check_comm_hook(hook)\n        assert self.logger is not None\n        self.logger._set_comm_hook_name(hook.__qualname__)\n        self._comm_hooks.append((hook, state))\n        dist._register_comm_hook(self.reducer, state, hook)\n\n    def _register_builtin_comm_hook(self, comm_hook_type):\n        r\"\"\"\n        Register a built-in communication hook that specifies how DDP aggregates gradients across multiple workers.\n\n        The built-in hooks aim to provide efficient C++ implementations for certain hooks,\n        which might not be as efficient if implemented in Python using a Python communication hook.\n\n        Args:\n            comm_hook_type (dist.BuiltinCommHookType): type of communication hook, such as ALLREDUCE, FP16_COMPRESS, etc.\n\n        .. warning ::\n            DDP communication hook can only be registered once and should be registered\n            before calling backward.\n\n        Example::\n            Below is an example of a FP16 compression where gradients are\n            compressed into 16-bit floating-point numbers before allreduce, and\n            then decompressed after allreduce.\n\n            >>> # xdoctest: +SKIP('undefined name')\n            >>> ddp._register_builtin_comm_hook(dist.BuiltinCommHookType.FP16_COMPRESS)\n\n        \"\"\"\n        assert self.logger is not None\n        self.logger._set_comm_hook_name(str(comm_hook_type))\n        dist._register_builtin_comm_hook(self.reducer, comm_hook_type)\n\n    def _register_fused_optim(self, optim: Type, *args, optim_params=None, **kwargs):\n        r\"\"\"\n        Register an optimizer in DDP to optimize parameter immediately after its gradient reduction.\n\n        Registers an optimizer with DDP such that the optimization for a\n        parameter will run immediately when that parameter's gradient is\n        finished with reduction, instead of waiting for all parameters'\n        gradients to finish reduction. This can result in a training speedup\n        depending on your workload since the optimizer can run while gradient\n        reduction for other parameters are still ongoing. In addition, this has\n        the potential to reduce peak memory consumption during training, as it\n        only needs to load the per-parameter optimizer states of a single\n        parameter at a time, instead of loading all per-parameter optimizer\n        states at once.\n\n        Args:\n            optim (Type): a ``torch.optim.Optimizer`` class to be registered\n            as a fused optimizer.\n            *args (Sequence[Any]): Arguments to forward to `optim`.\n            optim_params (Optional[Iterable[torch.Tensor]]): Set of parameters\n            to optimize, similar to `params` argument of traditional `torch.optim`\n            Optimizers. If this is omitted, all DDP model parameters will be\n            optimized.\n            **kwargs: (Dict[str, Any]): Keyword arguments to forward to `optim`.\n\n        .. warning ::\n            _register_fused_optim should only be called once on a DDP instance,\n            and registering multiple fused optimizers for the same DDP model\n            is not currently supported. Please ping\n            https://github.com/pytorch/pytorch/issues/71595 if this is necessary\n            for your use case.\n\n        .. warning ::\n            _register_fused_optim and register_comm_hook currently do not\n            compose together, meaning that custom DDP communication hooks are\n            not supported with overlapped optimizers. Please ping\n            https://github.com/pytorch/pytorch/issues/71595 if this is necessary\n            for your use case.\n\n        .. warning ::\n            Gradient accumulation and DDP `no_sync` are currently not supported\n            with overlapped optimizer. Please ping\n            https://github.com/pytorch/pytorch/issues/71595 if this is necessary\n            for your use case.\n\n        Example::\n\n            >>> # xdoctest: +SKIP(\"No rendezvous handler\")\n            >>> torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...')\n            >>> net = torch.nn.parallel.DistributedDataParallel(model, pg)\n            >>> lr = 1e-2\n            >>> betas = (0.9, 0.99)\n            >>> eps = 1e-6\n            >>> net._register_fused_optim(torch.optim.Adam, lr, betas=betas, eps=eps)\n            >>> # Example with subset of parameters\n            >>> params_to_opt = [list(net.parameters())[0]]\n            >>> net._register_fused_optim(\n            ...   torch.optim.Adam, lr, optim_params=params_to_opt,  betas=betas, eps=eps\n            ... )\n        \"\"\"\n        # Note: importing in function, otherwise this will cause a circular\n        # import as optimizer_overlap module needs to import DistributedDataParallel.\n        from torch.distributed.algorithms._optimizer_overlap import _as_overlapped_optim\n\n        overlapped_optim = _as_overlapped_optim(optim, optim_params, *args, **kwargs)\n        try:\n            overlapped_optim.register_ddp(self)\n        except NotImplementedError as e:\n            raise RuntimeError(\n                f\"{optim} does not support overlapped DDP. Please file an issue to PyTorch or the respective owner of {optim}.\"\n            ) from e\n\n    def _distributed_broadcast_coalesced(\n        self, tensors, buffer_size, authoritative_rank=0\n    ):\n        dist._broadcast_coalesced(\n            self.process_group, tensors, buffer_size, authoritative_rank\n        )\n\n    def _check_sync_bufs_post_fwd(self):\n        return (\n            self.will_sync_module_buffers()\n            and hasattr(self, \"buffer_hook\")\n            and self.buffer_hook.buffer_comm_hook_location\n            == _BufferCommHookLocation.POST_FORWARD\n        )\n\n    def _check_sync_bufs_pre_fwd(self):\n        return self.will_sync_module_buffers() and (\n            not hasattr(self, \"buffer_hook\")\n            or self.buffer_hook.buffer_comm_hook_location\n            == _BufferCommHookLocation.PRE_FORWARD\n        )\n\n    def will_sync_module_buffers(self):\n        return (\n            self.require_forward_param_sync\n            and self.broadcast_buffers\n            and len(self.modules_buffers) > 0\n        )\n\n    def _find_common_rank(self, input_rank, rank_cond):\n        # -1 indicates that this rank is not under consideration to be the\n        # common_rank\n        rank_to_use = torch.tensor(\n            [input_rank if rank_cond else -1],\n            device=self.device,\n        )\n        dist.all_reduce(rank_to_use, op=ReduceOp.MAX, group=self.process_group)\n        if rank_to_use.item() == -1:\n            self._log_and_throw(\n                ValueError,\n                \"BUG! Expected rank_cond to be true for at least one process.\"\n                \" This indicates a bug in PyTorch, please report an issue.\",\n            )\n        return rank_to_use.item()\n\n    def _sync_buffers(self):\n        with torch.no_grad():\n            # module buffer sync\n            # Synchronize buffers across processes.\n            # If we are running DDP with the join manager, we have to agree\n            # upon a rank to sync module buffers from, since rank 0 may\n            # already have been joined and have stale module buffers.\n            if self._join_config.enable:\n                authoritative_rank = self._find_common_rank(\n                    self._distributed_rank, True\n                )\n            else:\n                # The process with rank 0 is considered the authoritative copy.\n                authoritative_rank = 0\n            # Update self.modules_buffers incase any buffers were\n            # reassigned.\n            self._assign_modules_buffers()\n            self._sync_module_buffers(authoritative_rank)\n\n    def _sync_module_buffers(self, authoritative_rank):\n        if not hasattr(self, \"buffer_hook\"):\n            self._default_broadcast_coalesced(authoritative_rank=authoritative_rank)\n        else:\n            hook = self.buffer_hook.buffer_comm_hook\n            state = self.buffer_hook.buffer_comm_hook_state\n            futs = hook(state, self.named_module_buffers)\n            if futs is not None:\n                self.reducer._install_post_backward_futures(futs)\n\n    def _default_broadcast_coalesced(\n        self, bufs=None, bucket_size=None, authoritative_rank=0\n    ):\n        \"\"\"\n        Broadcasts buffers from rank 0 to rest of workers.\n\n        If bufs, bucket_size are None, default values self.modules_buffers\n        and self.broadcast_bucket_size are used instead.\n        \"\"\"\n        if bufs is None:\n            bufs = self.modules_buffers\n        if bucket_size is None:\n            bucket_size = self.broadcast_bucket_size\n\n        self._distributed_broadcast_coalesced(bufs, bucket_size, authoritative_rank)\n\n    def _passing_sync_batchnorm_handle(self, module):\n        for layer in module.modules():\n            if isinstance(layer, torch.nn.modules.SyncBatchNorm):\n                if self.device_type == \"cpu\":\n                    self._log_and_throw(\n                        ValueError,\n                        \"SyncBatchNorm layers only work with GPU modules\",\n                    )\n\n    def _check_comm_hook(self, hook):\n        if not callable(hook):\n            self._log_and_throw(TypeError, \"Communication hook must be callable.\")\n\n        sig = inspect.signature(hook)\n        if (\n            sig.parameters[\"bucket\"].annotation != inspect._empty\n            and sig.parameters[\"bucket\"].annotation != dist.GradBucket\n        ):\n            self._log_and_throw(\n                ValueError,\n                \"Communication hook: bucket annotation should be dist.GradBucket.\",\n            )\n\n        if (\n            sig.return_annotation != inspect._empty\n            and sig.return_annotation != torch.futures.Future[torch.Tensor]\n        ):\n            self._log_and_throw(\n                ValueError,\n                \"Communication hook: return annotation should be torch.futures.Future[torch.Tensor].\",\n            )\n\n        if hook.__name__ in [\n            \"bf16_compress_hook\",\n            \"bf16_compress_wrapper_hook\",\n        ] and (\n            (torch.version.cuda is None and torch.version.hip is None)\n            or (\n                torch.version.cuda is not None\n                and int(torch.version.cuda.split(\".\")[0]) < 11\n            )\n            or not dist.is_available()\n            or not dist.is_nccl_available()\n            or torch.cuda.nccl.version() < (2, 10)\n        ):\n            self._log_and_throw(\n                TypeError,\n                \"BF16 all reduce communication hook required CUDA 11+ and NCCL 2.10+.\",\n            )\n\n    @property\n    def _distributed_rank(self):\n        return dist.get_rank(self.process_group)\n\n    @staticmethod\n    def _get_data_parallel_params(module, named_params=False):\n        \"\"\"Return a generator of parameters managed by a given DDP unit.\"\"\"\n        for param in (\n            module.parameters() if not named_params else module.named_parameters()\n        ):\n            if not hasattr(param, \"_ddp_ignored\"):\n                yield param\n\n    @staticmethod\n    def _set_params_and_buffers_to_ignore_for_model(\n        module, params_and_buffers_to_ignore\n    ):\n        \"\"\"\n        Set parameters and buffers to be ignored by DDP.\n\n        Expected format for parameters is the fully qualified name: {module_name}.{param_name}, and\n        similarly, {module_name}.{buffer_name} for buffers. For example:\n        params_to_ignore = []\n        # NB: model here is vanilla PyTorch module, not yet wrapped with DDP.\n        for module_name, module in model.named_modules():\n            for param_name, param in module.named_parameters(recurse=False):\n                if should_ignore(param):\n                    # Create expected format\n                    fqn = f\"{module_name}.{param_name}\"\n                    params_to_ignore.append(fqn)\n        torch.nn.parallel.DistributedDataParallel._set_params_and_buffers_to_ignore_for_model(\n            model,\n            params_to_ignore\n        )\n        \"\"\"\n        # This is a workaround to set parameters and buffers DDP should ignore\n        # during synchronization. It will be removed when the API is finalized\n        # as part of addressing https://github.com/pytorch/pytorch/issues/43690.\n        module._ddp_params_and_buffers_to_ignore = params_and_buffers_to_ignore\n        for name, param in module.named_parameters():\n            if name in params_and_buffers_to_ignore:\n                param._ddp_ignored = True\n        for name, buffer in module.named_buffers():\n            if name in params_and_buffers_to_ignore:\n                buffer._ddp_ignored = True\n\n    def _get_ddp_logging_data(self):\n        r\"\"\"\n        Return a dictionary of logging data for debugging and analysis.\n\n        This interface can be called after DistributedDataParallel() is\n        constructed. It returns a dictionary of logging data. It could help\n        for debugging and analysis. The logging data includes DistributedDataParallel\n        constructor input parameters, some internal states of DistributedDataParallel\n        and performance metrics. Simply print the dictionary and see what\n        these metrics are.\n        This is a prototype interface and subject to change in the future.\n        \"\"\"\n        assert self.logger is not None\n        ddp_logging_data = self.logger._get_ddp_logging_data()\n        return {**ddp_logging_data.strs_map, **ddp_logging_data.ints_map}\n\n    def _set_ddp_runtime_logging_sample_rate(self, sample_rate):\n        r\"\"\"\n        Set sample_rate of collecting runtime stats.\n\n        This interface allows users to set sample_rate of collecting\n        runtime stats. The runtime stats will be recorded for the\n        first 10 iterations, after 10 iterations runtime stats will be\n        recorded once every \"sample_rate\" training iterations. In\n        default, runtime stats are recorded for the first 10 iterations,\n        after 10 iterations runtime stats are recorded once every\n        \"kDDPRuntimeLoggingSampleRate=100\" training iterations.\n        This is a prototype interface and subject to change in the future.\n        \"\"\"\n        if sample_rate < 1:\n            self._log_and_throw(\n                ValueError,\n                \"DDP runtime logging sample rate should be equal or greater than 1\",\n            )\n        self.reducer._set_ddp_runtime_logging_sample_rate(sample_rate)\n\n    def _set_static_graph(self):\n        \"\"\"\n        Set static graph for DDP.\n\n        It is recommended to set static graph in the DDP constructor, which will\n        call this private API internally.\n        \"\"\"\n        # If self.static_graph has been set, no need to set it again\n        if self.static_graph:\n            warnings.warn(\n                \"You've set static_graph to be True, no need to set it again.\"\n            )\n            return\n        self.static_graph = True\n        self._static_graph_delay_allreduce_enqueued = False\n        self.reducer._set_static_graph()\n        assert self.logger is not None\n        self.logger._set_static_graph()\n        if self.find_unused_parameters:\n            warnings.warn(\n                \"You passed find_unused_parameters=true to DistributedDataParallel, \"\n                \"`_set_static_graph` will detect unused parameters automatically, so \"\n                \"you do not need to set find_unused_parameters=true, just be sure these \"\n                \"unused parameters will not change during training loop while calling \"\n                \"`_set_static_graph`.\"\n            )\n\n    def _remove_autograd_hooks(self):\n        \"\"\"Remove autograd hooks registered by the reducer on the model parameters.\"\"\"\n        self.reducer._remove_autograd_hooks()\n\n    def _check_reducer_finalized(self):\n        \"\"\"\n        Check if the reducer has processed all buckets and finalized the backward appropriately.\n\n        It is useful to call this method after calling .backward() in your training loop\n        in order to avoid subsequent hard to debug errors down the road due to the\n        reducer not finalizing backward.\n        \"\"\"\n        self.reducer._check_reducer_finalized()\n\n    def _set_sparse_metadata(self, global_unique_ids):\n        self.reducer._set_sparse_metadata(global_unique_ids)\n\n    def _update_process_group(self, new_process_group):\n        \"\"\"\n        Dynamically updates the process group for DDP so that we can shrink/expand DDP\n        world size without having to reinitialize DDP.\n\n        NOTE: If you are using custom communications hooks via, register_comm_hook,\n        you need to update the process groups for those hooks separately.\n        \"\"\"\n        # Force a rebuild of buckets for a new process group. This ensures all ranks\n        # are synchronized in terms of when they will rebuild buckets and also\n        # re-evaluates previous assumptions of buckets given the world size might have\n        # changed.\n        self._has_rebuilt_buckets = False\n        self.reducer._reset_state()\n\n        if not _rank_not_in_group(new_process_group):\n            self.process_group = new_process_group\n            self.reducer._update_process_group(new_process_group)\n\n    def _set_ddp_sink_clone(self, val: bool):\n        \"\"\"\n        Sets whether or not DDPSink should clone the output tensors or not.\n        The default is True since if the loss is modified in place we run\n        into the view is modified in-place error.\n\n        Although, cloning the tensors can add significant memory and\n        performance hit if the number and size of tensors are large. As\n        a result, this can be set to False if you are not modifying the\n        loss in place.\n        \"\"\"\n        self._ddp_sink_clone = val\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.utils.clip_grad_norm_": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py",
      "start_line": 36,
      "end_line": 124,
      "code": "@_no_grad\ndef clip_grad_norm_(\n    parameters: _tensor_or_tensors,\n    max_norm: float,\n    norm_type: float = 2.0,\n    error_if_nonfinite: bool = False,\n    foreach: Optional[bool] = None,\n) -> torch.Tensor:\n    if isinstance(parameters, torch.Tensor):\n        parameters = [parameters]\n    grads = [p.grad for p in parameters if p.grad is not None]\n    max_norm = float(max_norm)\n    norm_type = float(norm_type)\n    if len(grads) == 0:\n        return torch.tensor(0.0)\n    first_device = grads[0].device\n    grouped_grads: Dict[\n        Tuple[torch.device, torch.dtype], Tuple[List[List[Tensor]], List[int]]\n    ] = _group_tensors_by_device_and_dtype(\n        [grads]\n    )  # type: ignore[assignment]\n\n    norms: List[Tensor] = []\n    for (device, _), ([device_grads], _) in grouped_grads.items():  # type: ignore[assignment]\n        if (foreach is None and _has_foreach_support(device_grads, device)) or (\n            foreach and _device_has_foreach_support(device)\n        ):\n            norms.extend(torch._foreach_norm(device_grads, norm_type))\n        elif foreach:\n            raise RuntimeError(\n                f\"foreach=True was passed, but can't use the foreach API on {device.type} tensors\"\n            )\n        else:\n            norms.extend([torch.linalg.vector_norm(g, norm_type) for g in device_grads])\n\n    total_norm = torch.linalg.vector_norm(\n        torch.stack([norm.to(first_device) for norm in norms]), norm_type\n    )\n\n    if error_if_nonfinite and torch.logical_or(total_norm.isnan(), total_norm.isinf()):\n        raise RuntimeError(\n            f\"The total norm of order {norm_type} for gradients from \"\n            \"`parameters` is non-finite, so it cannot be clipped. To disable \"\n            \"this error and scale the gradients by the non-finite norm anyway, \"\n            \"set `error_if_nonfinite=False`\"\n        )\n    clip_coef = max_norm / (total_norm + 1e-6)\n    # Note: multiplying by the clamped coef is redundant when the coef is clamped to 1, but doing so\n    # avoids a `if clip_coef < 1:` conditional which can require a CPU <=> device synchronization\n    # when the gradients do not reside in CPU memory.\n    clip_coef_clamped = torch.clamp(clip_coef, max=1.0)\n    for (device, _), ([device_grads], _) in grouped_grads.items():  # type: ignore[assignment]\n        if (foreach is None and _has_foreach_support(device_grads, device)) or (\n            foreach and _device_has_foreach_support(device)\n        ):\n            torch._foreach_mul_(device_grads, clip_coef_clamped.to(device))\n        elif foreach:\n            raise RuntimeError(\n                f\"foreach=True was passed, but can't use the foreach API on {device.type} tensors\"\n            )\n        else:\n            clip_coef_clamped_device = clip_coef_clamped.to(device)\n            for g in device_grads:\n                g.mul_(clip_coef_clamped_device)\n\n    return total_norm\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.utils.parameters_to_vector": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\utils\\convert_parameters.py",
      "start_line": 6,
      "end_line": 25,
      "code": "def parameters_to_vector(parameters: Iterable[torch.Tensor]) -> torch.Tensor:\n    # Flag for the device where the parameter is located\n    param_device = None\n\n    vec = []\n    for param in parameters:\n        # Ensure the parameters are located in the same device\n        param_device = _check_param_device(param, param_device)\n\n        vec.append(param.view(-1))\n    return torch.cat(vec)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.utils.vector_to_parameters": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\utils\\convert_parameters.py",
      "start_line": 28,
      "end_line": 54,
      "code": "def vector_to_parameters(vec: torch.Tensor, parameters: Iterable[torch.Tensor]) -> None:\n    # Ensure vec of type Tensor\n    if not isinstance(vec, torch.Tensor):\n        raise TypeError(f\"expected torch.Tensor, but got: {torch.typename(vec)}\")\n    # Flag for the device where the parameter is located\n    param_device = None\n\n    # Pointer for slicing the vector for each parameter\n    pointer = 0\n    for param in parameters:\n        # Ensure the parameters are located in the same device\n        param_device = _check_param_device(param, param_device)\n\n        # The length of the parameter\n        num_param = param.numel()\n        # Slice the vector, reshape it, and replace the old data of the parameter\n        param.data = vec[pointer : pointer + num_param].view_as(param).data\n\n        # Increment the pointer\n        pointer += num_param\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.utils.weight_norm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py",
      "start_line": 83,
      "end_line": 144,
      "code": "def weight_norm(module: T_module, name: str = \"weight\", dim: int = 0) -> T_module:\n    WeightNorm.apply(module, name, dim)\n    return module\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.utils.remove_weight_norm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py",
      "start_line": 147,
      "end_line": 164,
      "code": "def remove_weight_norm(module: T_module, name: str = \"weight\") -> T_module:\n    for k, hook in module._forward_pre_hooks.items():\n        if isinstance(hook, WeightNorm) and hook.name == name:\n            hook.remove(module)\n            del module._forward_pre_hooks[k]\n            return module\n\n    raise ValueError(f\"weight_norm of '{name}' not found in {module}\")\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.utils.spectral_norm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\utils\\spectral_norm.py",
      "start_line": 265,
      "end_line": 334,
      "code": "def spectral_norm(\n    module: T_module,\n    name: str = \"weight\",\n    n_power_iterations: int = 1,\n    eps: float = 1e-12,\n    dim: Optional[int] = None,\n) -> T_module:\n    if dim is None:\n        if isinstance(\n            module,\n            (\n                torch.nn.ConvTranspose1d,\n                torch.nn.ConvTranspose2d,\n                torch.nn.ConvTranspose3d,\n            ),\n        ):\n            dim = 1\n        else:\n            dim = 0\n    SpectralNorm.apply(module, name, n_power_iterations, dim, eps)\n    return module\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.utils.remove_spectral_norm": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\utils\\spectral_norm.py",
      "start_line": 337,
      "end_line": 366,
      "code": "def remove_spectral_norm(module: T_module, name: str = \"weight\") -> T_module:\n    for k, hook in module._forward_pre_hooks.items():\n        if isinstance(hook, SpectralNorm) and hook.name == name:\n            hook.remove(module)\n            del module._forward_pre_hooks[k]\n            break\n    else:\n        raise ValueError(f\"spectral_norm of '{name}' not found in {module}\")\n\n    for k, hook in module._state_dict_hooks.items():\n        if isinstance(hook, SpectralNormStateDictHook) and hook.fn.name == name:\n            del module._state_dict_hooks[k]\n            break\n\n    for k, hook in module._load_state_dict_pre_hooks.items():\n        if isinstance(hook, SpectralNormLoadStateDictPreHook) and hook.fn.name == name:\n            del module._load_state_dict_pre_hooks[k]\n            break\n\n    return module\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.utils.rnn.pack_padded_sequence": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\utils\\rnn.py",
      "start_line": 280,
      "end_line": 339,
      "code": "def pack_padded_sequence(\n    input: Tensor,\n    lengths: Union[Tensor, List[int]],\n    batch_first: bool = False,\n    enforce_sorted: bool = True,\n) -> PackedSequence:\n    if not isinstance(lengths, torch.Tensor):\n        if torch._C._get_tracing_state():\n            warnings.warn(\n                \"pack_padded_sequence has been called with a Python list of \"\n                \"sequence lengths. The tracer cannot track the data flow of Python \"\n                \"values, and it will treat them as constants, likely rendering \"\n                \"the trace incorrect for any other combination of lengths.\",\n                stacklevel=2,\n            )\n        lengths = torch.as_tensor(lengths, dtype=torch.int64, device=\"cpu\")\n    else:\n        lengths = lengths.to(dtype=torch.int64)\n\n    if enforce_sorted:\n        sorted_indices = None\n    else:\n        lengths, sorted_indices = torch.sort(lengths, descending=True)\n        sorted_indices = sorted_indices.to(input.device)\n        batch_dim = 0 if batch_first else 1\n        input = input.index_select(batch_dim, sorted_indices)\n\n    data, batch_sizes = _VF._pack_padded_sequence(input, lengths, batch_first)\n    return _packed_sequence_init(data, batch_sizes, sorted_indices, None)\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.utils.rnn.pad_packed_sequence": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\utils\\rnn.py",
      "start_line": 342,
      "end_line": 414,
      "code": "def pad_packed_sequence(\n    sequence: PackedSequence,\n    batch_first: bool = False,\n    padding_value: float = 0.0,\n    total_length: Optional[int] = None,\n) -> Tuple[Tensor, Tensor]:\n    max_seq_length = sequence.batch_sizes.size(0)\n    if total_length is not None:\n        if total_length < max_seq_length:\n            raise ValueError(\n                \"Expected total_length to be at least the length \"\n                \"of the longest sequence in input, but got \"\n                f\"total_length={total_length} and max sequence length being {max_seq_length}\"\n            )\n        max_seq_length = total_length\n    padded_output, lengths = _VF._pad_packed_sequence(\n        sequence.data, sequence.batch_sizes, batch_first, padding_value, max_seq_length\n    )\n    unsorted_indices = sequence.unsorted_indices\n    if unsorted_indices is not None:\n        batch_dim = 0 if batch_first else 1\n        return (\n            padded_output.index_select(batch_dim, unsorted_indices),\n            lengths[unsorted_indices.cpu()],\n        )\n    return padded_output, lengths\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.utils.rnn.pad_sequence": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\utils\\rnn.py",
      "start_line": 418,
      "end_line": 480,
      "code": "def pad_sequence(\n    sequences: Union[Tensor, List[Tensor]],\n    batch_first: bool = False,\n    padding_value: float = 0.0,\n    padding_side: str = \"right\",\n) -> Tensor:\n    if not (torch.jit.is_tracing() or torch.jit.is_scripting()):\n        # JIT doesn't support `Iterable`\n        if not isinstance(sequences, Iterable):\n            msg = (\n                \"pad_sequence: Expected iterable for input sequences, but got arg of type: \"\n                f\"{type(sequences)}\"\n            )\n            raise RuntimeError(msg)\n\n        # In JIT context this leads to,\n        # RuntimeError: cannot statically infer the expected size of a list in this context\n        sequences = tuple(sequences)  # type: ignore[assignment]\n    else:\n        # For JIT, we only support Union[Tensor, Tuple[Tensor]]\n        if isinstance(sequences, torch.Tensor):\n            sequences = sequences.unbind(0)  # type: ignore[assignment]\n\n    # assuming trailing dimensions and type of all the Tensors\n    # in sequences are same and fetching those from sequences[0]\n    return torch._C._nn.pad_sequence(\n        sequences, batch_first, padding_value, padding_side  # type: ignore[arg-type]\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.utils.rnn.pack_sequence": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\utils\\rnn.py",
      "start_line": 532,
      "end_line": 568,
      "code": "def pack_sequence(\n    sequences: List[Tensor],\n    enforce_sorted: bool = True,\n) -> PackedSequence:\n    lengths = torch.as_tensor([v.size(0) for v in sequences])\n    return pack_padded_sequence(\n        pad_sequence(sequences), lengths, enforce_sorted=enforce_sorted\n    )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Flatten": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\flatten.py",
      "start_line": 13,
      "end_line": 56,
      "code": "class Flatten(Module):\n\n    __constants__ = [\"start_dim\", \"end_dim\"]\n    start_dim: int\n    end_dim: int\n\n    def __init__(self, start_dim: int = 1, end_dim: int = -1) -> None:\n        super().__init__()\n        self.start_dim = start_dim\n        self.end_dim = end_dim\n\n    def forward(self, input: Tensor) -> Tensor:\n        return input.flatten(self.start_dim, self.end_dim)\n\n    def extra_repr(self) -> str:\n        return f\"start_dim={self.start_dim}, end_dim={self.end_dim}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.Unflatten": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\flatten.py",
      "start_line": 59,
      "end_line": 158,
      "code": "class Unflatten(Module):\n\n    NamedShape = Tuple[Tuple[str, int]]\n\n    __constants__ = [\"dim\", \"unflattened_size\"]\n    dim: Union[int, str]\n    unflattened_size: Union[_size, NamedShape]\n\n    def __init__(\n        self, dim: Union[int, str], unflattened_size: Union[_size, NamedShape]\n    ) -> None:\n        super().__init__()\n\n        if isinstance(dim, int):\n            self._require_tuple_int(unflattened_size)\n        elif isinstance(dim, str):\n            self._require_tuple_tuple(unflattened_size)\n        else:\n            raise TypeError(\"invalid argument type for dim parameter\")\n\n        self.dim = dim\n        self.unflattened_size = unflattened_size\n\n    def _require_tuple_tuple(self, input):\n        if isinstance(input, tuple):\n            for idx, elem in enumerate(input):\n                if not isinstance(elem, tuple):\n                    raise TypeError(\n                        \"unflattened_size must be tuple of tuples, \"\n                        + f\"but found element of type {type(elem).__name__} at pos {idx}\"\n                    )\n            return\n        raise TypeError(\n            \"unflattened_size must be a tuple of tuples, \"\n            + f\"but found type {type(input).__name__}\"\n        )\n\n    def _require_tuple_int(self, input):\n        if isinstance(input, (tuple, list)):\n            for idx, elem in enumerate(input):\n                if not isinstance(elem, int):\n                    raise TypeError(\n                        \"unflattened_size must be tuple of ints, \"\n                        + f\"but found element of type {type(elem).__name__} at pos {idx}\"\n                    )\n            return\n        raise TypeError(\n            f\"unflattened_size must be a tuple of ints, but found type {type(input).__name__}\"\n        )\n\n    def forward(self, input: Tensor) -> Tensor:\n        return input.unflatten(self.dim, self.unflattened_size)\n\n    def extra_repr(self) -> str:\n        return f\"dim={self.dim}, unflattened_size={self.unflattened_size}\"\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  },
  "torch.nn.modules.lazy.LazyModuleMixin": {
    "python": {
      "file": "..\\..\\..\\..\\..\\..\\ProgramData\\anaconda3\\envs\\momo_test\\Lib\\site-packages\\torch\\nn\\modules\\lazy.py",
      "start_line": 63,
      "end_line": 289,
      "code": "class LazyModuleMixin:\n\n    # modules inheriting from this will change their __class__ to the specified\n    # one after they are fully initialized\n    cls_to_become: Optional[Type[Any]] = None\n\n    def __init__(self: _LazyProtocol, *args, **kwargs):\n        # Mypy doesnt like this super call in a mixin\n        super().__init__(*args, **kwargs)  # type: ignore[misc]\n        self._load_hook = self._register_load_state_dict_pre_hook(self._lazy_load_hook)\n        self._initialize_hook = self.register_forward_pre_hook(\n            self._infer_parameters, with_kwargs=True\n        )\n\n    def _save_to_state_dict(self: _LazyProtocol, destination, prefix, keep_vars):\n        # This should be ideally implemented as a hook,\n        # but we should override `detach` in the UninitializedParameter to return itself\n        # which is not clean\n        for name, param in self._parameters.items():\n            if param is not None:\n                if not (is_lazy(param) or keep_vars):\n                    param = param.detach()\n                destination[prefix + name] = param\n        for name, buf in self._buffers.items():\n            if buf is not None and name not in self._non_persistent_buffers_set:\n                if not (is_lazy(buf) or keep_vars):\n                    buf = buf.detach()\n                destination[prefix + name] = buf\n\n    def _lazy_load_hook(\n        self: _LazyProtocol,\n        state_dict,\n        prefix,\n        local_metadata,\n        strict,\n        missing_keys,\n        unexpected_keys,\n        error_msgs,\n    ):\n        \"\"\"load_state_dict pre-hook function for lazy buffers and parameters.\n\n        The purpose of this hook is to adjust the current state and/or\n        ``state_dict`` being loaded so that a module instance serialized in\n        both un/initialized state can be deserialized onto both un/initialized\n        module instance.\n        See comment in ``torch.nn.Module._register_load_state_dict_pre_hook``\n        for the details of the hook specification.\n        \"\"\"\n        for name, param in itertools.chain(\n            self._parameters.items(), self._buffers.items()\n        ):\n            key = prefix + name\n            if key in state_dict and param is not None:\n                input_param = state_dict[key]\n                if is_lazy(param):\n                    # The current parameter is not initialized but the one being loaded one is\n                    # create a new parameter based on the uninitialized one\n                    if not is_lazy(input_param):\n                        with torch.no_grad():\n                            param.materialize(input_param.shape)\n\n    def initialize_parameters(self: _LazyProtocol, *args, **kwargs):\n        r\"\"\"Initialize parameters according to the input batch properties.\n\n        This adds an interface to isolate parameter initialization from the\n        forward pass when doing parameter shape inference.\n        \"\"\"\n        raise NotImplementedError(\n            f\"initialize_parameters is not implemented for {self.__class__.__name__}\"\n        )\n\n    def has_uninitialized_params(self: _LazyProtocol):\n        r\"\"\"Check if a module has parameters that are not initialized.\"\"\"\n        # This is to avoid the JIT to track this parameter and force\n        # custom modules __setstate__ to add it\n        params = self._parameters.values()\n        buffers = self._buffers.values()\n        for param in itertools.chain(params, buffers):\n            if is_lazy(param):\n                return True\n        return False\n\n    # torchrec tests the code consistency with the following code\n    # fmt: off\n    def _infer_parameters(self: _LazyProtocol, module, args, kwargs=None):\n        r\"\"\"Infers the size and initializes the parameters according to the provided input batch.\n\n        Given a module that contains parameters that were declared inferrable\n        using :class:`torch.nn.parameter.ParameterMode.Infer`, runs a forward pass\n        in the complete module using the provided input to initialize all the parameters\n        as needed.\n        The module is set into evaluation mode before running the forward pass in order\n        to avoid saving statistics or calculating gradients\n        \"\"\"\n        kwargs = kwargs if kwargs else {}\n        module.initialize_parameters(*args, **kwargs)\n        if module.has_uninitialized_params():\n            raise RuntimeError(f'module {self._get_name()} has not been fully initialized')\n        module._initialize_hook.remove()\n        module._load_hook.remove()\n        delattr(module, '_initialize_hook')\n        delattr(module, '_load_hook')\n        if module.cls_to_become is not None:\n            module.__class__ = module.cls_to_become\n    # fmt: on\n\n    def _replicate_for_data_parallel(self: _LazyProtocol):\n        raise RuntimeError(\n            \"Modules with uninitialized parameters can't be used with `DataParallel`. \"\n            \"Run a dummy forward pass to correctly initialize the modules\"\n        )\n"
    },
    "cpp": {
      "function": null,
      "file": null,
      "start_line": null,
      "end_line": null,
      "code": ""
    }
  }
}